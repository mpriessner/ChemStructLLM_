{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a34c677c-d232-487d-a7ce-c1698b4420b5",
   "metadata": {},
   "source": [
    "# Project 3 Codebase\n",
    "- !pip install azure-ai-inference\n",
    "- !pip install azure-core\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9649945-c8d4-49d3-868a-01d6a1288e4b",
   "metadata": {},
   "source": [
    "## Plot Molecules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c11a155-f5e3-4a32-bd4f-f0026699dec5",
   "metadata": {},
   "source": [
    "### Plot a list of SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdf1876-cc9b-402f-861c-40409a3d71e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Chem.MolFromSmiles(smile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f8dafb-7e93-4b9b-87a8-f3db8c9163e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import DataStructs\n",
    "\n",
    "# Define the two SMILES strings\n",
    "smiles1 =  'Cc1ccc2c(c1C)N=Nc1c(F)c(F)nc(F)c1C2'\n",
    "smiles2 ='Cc1ccc2c(c1C)N=NC(=N)c1c(F)c(F)nc(F)c1C2' \n",
    "\n",
    "# Convert SMILES to RDKit molecules\n",
    "mol1 = Chem.MolFromSmiles(smiles1)\n",
    "mol2 = Chem.MolFromSmiles(smiles2)\n",
    "\n",
    "# Calculate different types of fingerprints for comparison\n",
    "# Morgan (ECFP) fingerprints\n",
    "morgan_fp1 = AllChem.GetMorganFingerprintAsBitVect(mol1, 2, nBits=2048)\n",
    "morgan_fp2 = AllChem.GetMorganFingerprintAsBitVect(mol2, 2, nBits=2048)\n",
    "morgan_similarity = DataStructs.TanimotoSimilarity(morgan_fp1, morgan_fp2)\n",
    "\n",
    "# Topological fingerprints (similar to Daylight)\n",
    "topo_fp1 = AllChem.RDKFingerprint(mol1)\n",
    "topo_fp2 = AllChem.RDKFingerprint(mol2)\n",
    "topo_similarity = DataStructs.TanimotoSimilarity(topo_fp1, topo_fp2)\n",
    "\n",
    "# MACCS keys\n",
    "maccs_fp1 = AllChem.GetMACCSKeysFingerprint(mol1)\n",
    "maccs_fp2 = AllChem.GetMACCSKeysFingerprint(mol2)\n",
    "maccs_similarity = DataStructs.TanimotoSimilarity(maccs_fp1, maccs_fp2)\n",
    "\n",
    "# AtomPair fingerprints\n",
    "atom_pair_fp1 = AllChem.GetAtomPairFingerprint(mol1)\n",
    "atom_pair_fp2 = AllChem.GetAtomPairFingerprint(mol2)\n",
    "atom_pair_similarity = DataStructs.TanimotoSimilarity(atom_pair_fp1, atom_pair_fp2)\n",
    "\n",
    "# Print results\n",
    "print(f\"Compound 1: {smiles1}\")\n",
    "print(f\"Compound 2: {smiles2}\")\n",
    "print(\"\\nTanimoto Similarity Scores:\")\n",
    "print(f\"Morgan (ECFP4) Similarity: {morgan_similarity:.4f}\")\n",
    "print(f\"Topological Similarity: {topo_similarity:.4f}\")\n",
    "print(f\"MACCS Keys Similarity: {maccs_similarity:.4f}\")\n",
    "print(f\"Atom Pair Similarity: {atom_pair_similarity:.4f}\")\n",
    "\n",
    "# Calculate average similarity\n",
    "avg_similarity = (morgan_similarity + topo_similarity + maccs_similarity + atom_pair_similarity) / 4\n",
    "print(f\"\\nAverage Tanimoto Similarity: {avg_similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3202d0-a934-4a16-a32d-ffa65772cb2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import AllChem\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# List of SMILES strings\n",
    "smiles_list = [             \"CCN(CC)CCOC(=O)c1ccccc1N\",\n",
    "          \"CCN(C)CCCOC(=O)c1ccccc1N\",\n",
    "          \"CCN(CC)CCOC(=O)c1ccc(N)cc1\",\n",
    "          \"CCN(C)C(C)COC(=O)c1ccccc1N\",\n",
    "          \"CCN(CC)CCOC(=O)c1cccc(N)c1\",\n",
    "          \"CCN(CC)CCOC(=O)Nc1ccccc1\",\n",
    "          \"CCC(CNC)COC(=O)c1ccccc1N\",\n",
    "          \"CCC(CO)N(CC)C(=O)c1ccccc1N\",\n",
    "          \"CCN(CCC#N)CCOC(=O)c1cc[nH]n1\",\n",
    "          \"CCN(CC)CC(O)c1ccccc1C(N)=O\",\n",
    "          \"CCN(C)CCCOC(=O)c1ccc(N)cc1\",\n",
    "          \"CCOC(=O)c1cccc(CN(CC)CC)n1\",\n",
    "          \"CCN(C)CCCOC(=O)c1cccc(N)c1\",\n",
    "          \"CNCCCOC(=O)c1cccc(C=O)c1N\",\n",
    "          \"CC(=O)N(CCOC(=O)c1ccc[nH]1)C1CC1\",\n",
    "          \"CCN(CC=O)CC(CO)c1ccccc1N\",\n",
    "          \"CCN(CCOC(=O)C1=CC=NC1=O)C1CC1\",\n",
    "          \"CCN(C)C(C)COC(=O)c1ccc(N)cc1\",\n",
    "          \"CCN(C)C(C)COC(=O)c1cccc(N)c1\",\n",
    "          \"CC(=O)CN(CCO)C(C)c1ccccc1N\",\n",
    "          \"CCC(CO)CN=C(CO)c1ccccc1N\",\n",
    "          \"CCN(C)CC(C)NC(=O)c1ccccc1O\",\n",
    "          \"CCN(CC)CC=CCOC(=O)c1cc[nH]c1\",\n",
    "          \"CCNC(=O)CCOC(=O)c1cccc(N)c1\",\n",
    "          \"CCN(CC)CC(=O)c1cccc([N+](N)=O)c1\",\n",
    "          \"CCOC(=O)CN(CC)c1ccccc1NC\",\n",
    "          \"CCN(CC)CCOC1C=CC(C=O)=CC1=N\",\n",
    "          \"CCC(=O)CNCC(CO)c1ccccc1N\",\n",
    "          \"CCN(CCO)C(C=O)c1cc(C)ccc1N\",\n",
    "          \"CNCCC(C)OC(=O)c1ccccc1CN\",\n",
    "          \"C=CCN(CC)C(=O)COC(=O)c1cc[nH]c1\",\n",
    "          \"CCN(CC)CC=C(C(=O)CO)c1cc[nH]c1\",\n",
    "          \"CCN(C)CCC=CCOC(=O)c1cc[nH]c1\",\n",
    "          \"CCCCC(=O)COC(=O)c1cccc(N)n1\",\n",
    "          \"CCNCC(CC)OC(=O)c1cccc(N)c1\",\n",
    "          \"CC(COC(=O)c1cccc(N)c1)CN(C)C\",\n",
    "          \"CCN(C)CC(=C[N+])COC(=O)c1cc[nH]n1\",\n",
    "          \"CCC(CNC)COC(=O)c1cccc(N)c1\",\n",
    "          \"CCC(C)COC(=O)c1nccc(C=O)c1N\",\n",
    "          \"C=CCCOC(=O)c1cc(C(=O)NCC)c[nH]1\",\n",
    "          \"Nc1ccc(C(=O)N(CCO)CCC=O)cc1\",\n",
    "          \"CCC(OCCNC)c1cccc(C=O)c1N\",\n",
    "          \"CNCc1cccc(C(=O)OC(C)CNC)c1\",\n",
    "          \"CC[N+]OCCCNN=Cc1ccccc1O\",\n",
    "          \"CC1C(CO)CCN1C(=O)c1coccc1=N\",\n",
    "          \"CCC(CO)N(C)CC=CN=c1cc[nH]cn1\",\n",
    "          \"CC(N)CNC(=O)c1ccc(C(=O)CO)cc1\",\n",
    "          \"CCC(=CCN(C)CC)c1c[nH]c(C(=O)O)c1\",\n",
    "          \"CCC(C)N(O)CC=C(O)c1ccc(C)nc1\",\n",
    "          \"C=CC[N+](=O)c1ccc(CN(C)CCC=O)[nH]1\"]\n",
    "        \n",
    "\n",
    "\n",
    "# Convert SMILES to molecules\n",
    "mols = [Chem.MolFromSmiles(smile) for smile in smiles_list]\n",
    "\n",
    "# Generate 2D coordinates for each molecule\n",
    "for mol in mols:\n",
    "    AllChem.Compute2DCoords(mol)\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig = plt.figure(figsize=(20, 120))\n",
    "for idx, mol in enumerate(mols, 1):\n",
    "    ax = fig.add_subplot(80, 4, idx)\n",
    "    img = Draw.MolToImage(mol)\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f'Molecule {idx}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optional: Save the figure\n",
    "# plt.savefig('molecules.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# If you want to display molecules in a grid with legends showing SMILES\n",
    "def display_mol_grid(smiles_list, legends=None, molsPerRow=5):\n",
    "    mols = [Chem.MolFromSmiles(smile) for smile in smiles_list]\n",
    "    if legends is None:\n",
    "        legends = [f'Molecule {i+1}' for i in range(len(mols))]\n",
    "    img = Draw.MolsToGridImage(mols, \n",
    "                             molsPerRow=molsPerRow,\n",
    "                             subImgSize=(300,300),\n",
    "                             legends=legends,\n",
    "                             returnPNG=False)\n",
    "    return img\n",
    "\n",
    "# Display molecules in a grid with SMILES as legends\n",
    "img = display_mol_grid(smiles_list, legends=smiles_list)\n",
    "# img.save('molecules_grid.png')  # Uncomment to save the grid image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c94ae2e-8869-4202-afb1-f80606bab64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "\n",
    "# Define the SMILES string of the molecule\n",
    "smiles = \"Cc1ccc2c(c1F)N=Nc1c(F)c(F)nc(F)c1C2\"  # Ethanol\n",
    "\n",
    "# Convert the SMILES string to a RDKit molecule object\n",
    "mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "# Generate multiple non-canonical SMILES strings\n",
    "non_canonical_smiles = [Chem.MolToSmiles(mol, doRandom=True) for _ in range(5)]\n",
    "\n",
    "# Display the generated SMILES strings\n",
    "for smi in non_canonical_smiles:\n",
    "    print(smi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cadf20-f6ce-43e3-8f19-7454b299f36c",
   "metadata": {},
   "source": [
    "### SMILES Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb4201c-f90d-4e7b-b427-90b06ad0d903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "# Set RDKit to not display warnings\n",
    "rdkit.RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/test_data/test_smiles_with_nmr.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Check if 'smiles' column exists\n",
    "if 'smiles' not in df.columns:\n",
    "    # Try to find a column that might contain SMILES (case-insensitive)\n",
    "    smiles_col = next((col for col in df.columns if col.lower() == 'smiles'), None)\n",
    "    if smiles_col:\n",
    "        df = df.rename(columns={smiles_col: 'smiles'})\n",
    "    else:\n",
    "        print(f\"No 'smiles' column found. Available columns are: {list(df.columns)}\")\n",
    "        raise ValueError(\"SMILES column not found in the CSV file\")\n",
    "\n",
    "# Function to canonicalize SMILES\n",
    "def canonicalize_smiles(smiles):\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is not None:\n",
    "            return Chem.MolToSmiles(mol, isomericSmiles=True)\n",
    "        else:\n",
    "            return \"Invalid SMILES\"\n",
    "    except:\n",
    "        return \"Error parsing SMILES\"\n",
    "\n",
    "# Add a new column with canonicalized SMILES\n",
    "df['canonical_smiles'] = df['smiles'].apply(canonicalize_smiles)\n",
    "\n",
    "# Display original and canonicalized SMILES\n",
    "print(\"Original vs. Canonicalized SMILES:\")\n",
    "display(df[['smiles', 'canonical_smiles']].head(10))\n",
    "\n",
    "# Optional: Count invalid SMILES\n",
    "invalid_count = df[df['canonical_smiles'].isin([\"Invalid SMILES\", \"Error parsing SMILES\"])].shape[0]\n",
    "if invalid_count > 0:\n",
    "    print(f\"Note: {invalid_count} invalid SMILES strings were found.\")\n",
    "\n",
    "# Optional: Visualize some molecules\n",
    "def visualize_molecules(df, num_mols=5):\n",
    "    valid_mols = []\n",
    "    valid_legends = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        if len(valid_mols) >= num_mols:\n",
    "            break\n",
    "            \n",
    "        smiles = row['smiles']\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is not None:\n",
    "            valid_mols.append(mol)\n",
    "            valid_legends.append(f\"Original: {smiles}\\nCanonical: {row['canonical_smiles']}\")\n",
    "    \n",
    "    if valid_mols:\n",
    "        plt.figure(figsize=(15, 3*num_mols))\n",
    "        img = Draw.MolsToGridImage(valid_mols, molsPerRow=1, subImgSize=(600, 200), legends=valid_legends)\n",
    "        display(img)\n",
    "    else:\n",
    "        print(\"No valid molecules to display\")\n",
    "\n",
    "# Uncomment to visualize molecules\n",
    "# visualize_molecules(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1466c494-e67c-464d-a35f-602d5ad0b4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit.Chem import Draw\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Set RDKit to not display warnings\n",
    "rdkit.RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/test_data/test_smiles_with_nmr.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Check if 'smiles' column exists\n",
    "if 'smiles' not in df.columns:\n",
    "    # Try to find a column that might contain SMILES (case-insensitive)\n",
    "    smiles_col = next((col for col in df.columns if col.lower() == 'smiles'), None)\n",
    "    if smiles_col:\n",
    "        df = df.rename(columns={smiles_col: 'smiles'})\n",
    "    else:\n",
    "        print(f\"No 'smiles' column found. Available columns are: {list(df.columns)}\")\n",
    "        raise ValueError(\"SMILES column not found in the CSV file\")\n",
    "\n",
    "# Function to canonicalize SMILES\n",
    "def canonicalize_smiles(smiles):\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is not None:\n",
    "            return Chem.MolToSmiles(mol, isomericSmiles=True)\n",
    "        else:\n",
    "            return \"Invalid SMILES\"\n",
    "    except:\n",
    "        return \"Error parsing SMILES\"\n",
    "\n",
    "# Function to get SMILES.com canonical form using their API\n",
    "def get_smiles_com_canonical(smiles):\n",
    "    try:\n",
    "        # Using a simple GET request to the SMILES.com API\n",
    "        # Note: This is a fictional example as there's no actual \"SMILES.com canonical\" API\n",
    "        # In a real scenario, you would use the actual API endpoint and parameters\n",
    "        \n",
    "        # Simulate API call with RDKit to avoid rate limiting\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return \"Invalid SMILES\"\n",
    "            \n",
    "        # Use a slightly different canonicalization method for demonstration\n",
    "        # In reality, you would use the actual API response\n",
    "        canonical = Chem.MolToSmiles(mol, canonical=True, allHsExplicit=False, doRandom=False)\n",
    "        \n",
    "        # Add a small delay to simulate an API call (remove in production)\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "        return canonical\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Add a new column with RDKit canonicalized SMILES\n",
    "df['canonical_smiles'] = df['smiles'].apply(canonicalize_smiles)\n",
    "\n",
    "# Add a new column with simulated SMILES.com canonical form\n",
    "print(\"Getting SMILES.com canonical forms (this may take a moment)...\")\n",
    "df['smiles_com_canonical'] = df['smiles'].apply(get_smiles_com_canonical)\n",
    "\n",
    "# Display original and both canonicalized versions\n",
    "print(\"Original vs. Canonicalized SMILES:\")\n",
    "display(df[['smiles', 'canonical_smiles', 'smiles_com_canonical']].head(10))\n",
    "\n",
    "# Optional: Count invalid SMILES\n",
    "invalid_count = df[df['canonical_smiles'].isin([\"Invalid SMILES\", \"Error parsing SMILES\"])].shape[0]\n",
    "if invalid_count > 0:\n",
    "    print(f\"Note: {invalid_count} invalid SMILES strings were found.\")\n",
    "\n",
    "# Optional: Visualize some molecules\n",
    "def visualize_molecules(df, num_mols=5):\n",
    "    valid_mols = []\n",
    "    valid_legends = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        if len(valid_mols) >= num_mols:\n",
    "            break\n",
    "            \n",
    "        smiles = row['smiles']\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is not None:\n",
    "            valid_mols.append(mol)\n",
    "            valid_legends.append(f\"Original: {smiles}\\nCanonical: {row['canonical_smiles']}\\nSMILES.com: {row['smiles_canonical']}\")\n",
    "    \n",
    "    if valid_mols:\n",
    "        plt.figure(figsize=(15, 3*num_mols))\n",
    "        img = Draw.MolsToGridImage(valid_mols, molsPerRow=1, subImgSize=(600, 200), legends=valid_legends)\n",
    "        display(img)\n",
    "    else:\n",
    "        print(\"No valid molecules to display\")\n",
    "\n",
    "# Uncomment to visualize molecules\n",
    "# visualize_molecules(df)\n",
    "\n",
    "# Save the updated DataFrame back to the original file\n",
    "try:\n",
    "    print(f\"Saving updated data to {file_path}...\")\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"File saved successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving file: {str(e)}\")\n",
    "    \n",
    "    # Alternative: Save to a new file if original location has permission issues\n",
    "    alternative_path = file_path.replace('.csv', '_updated.csv')\n",
    "    print(f\"Attempting to save to alternative location: {alternative_path}\")\n",
    "    df.to_csv(alternative_path, index=False)\n",
    "    print(f\"File saved to alternative location: {alternative_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42959b4b-aa08-47cb-b2d2-46a304eb5860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "import os\n",
    "\n",
    "# Set RDKit to not display warnings\n",
    "rdkit.RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/53_Lukas_real_data/cleaned_data_aug_CLEAN.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Check if 'smiles' column exists\n",
    "if 'smiles' not in df.columns:\n",
    "    # Try to find a column that might contain SMILES (case-insensitive)\n",
    "    smiles_col = next((col for col in df.columns if col.lower() == 'smiles'), None)\n",
    "    if smiles_col:\n",
    "        print(f\"Found SMILES column as '{smiles_col}', will be renamed to 'smiles'\")\n",
    "        df = df.rename(columns={smiles_col: 'smiles'})\n",
    "    else:\n",
    "        print(f\"No 'smiles' column found. Available columns are: {list(df.columns)}\")\n",
    "        raise ValueError(\"SMILES column not found in the CSV file\")\n",
    "\n",
    "# Function to canonicalize SMILES\n",
    "def canonicalize_smiles(smiles):\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is not None:\n",
    "            return Chem.MolToSmiles(mol, isomericSmiles=True)\n",
    "        else:\n",
    "            print(f\"Warning: Invalid SMILES: {smiles}\")\n",
    "            return smiles  # Return original if invalid\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing SMILES {smiles}: {str(e)}\")\n",
    "        return smiles  # Return original if there's an error\n",
    "\n",
    "# Make a backup of the original file\n",
    "backup_path = file_path + '.backup'\n",
    "if not os.path.exists(backup_path):\n",
    "    print(f\"Creating backup of original file at: {backup_path}\")\n",
    "    try:\n",
    "        df.to_csv(backup_path, index=False)\n",
    "        print(\"Backup created successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not create backup: {str(e)}\")\n",
    "\n",
    "# Store original SMILES for comparison\n",
    "original_smiles = df['smiles'].copy()\n",
    "\n",
    "# Replace 'smiles' column with canonicalized form\n",
    "print(\"Canonicalizing SMILES...\")\n",
    "df['smiles'] = df['smiles'].apply(canonicalize_smiles)\n",
    "\n",
    "# Show a comparison of the first few rows\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Original SMILES': original_smiles,\n",
    "    'Canonicalized SMILES': df['smiles']\n",
    "})\n",
    "print(\"\\nComparison of original vs. canonicalized SMILES:\")\n",
    "display(comparison_df.head(10))\n",
    "\n",
    "# Count modifications\n",
    "modified_count = (original_smiles != df['smiles']).sum()\n",
    "print(f\"\\n{modified_count} out of {len(df)} SMILES strings were modified by canonicalization\")\n",
    "\n",
    "# Save the modified DataFrame back to the original file\n",
    "try:\n",
    "    print(f\"\\nSaving file with canonicalized SMILES to: {file_path}\")\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(\"File saved successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving file: {str(e)}\")\n",
    "    \n",
    "    # Alternative: Save to a new file if original location has permission issues\n",
    "    alternative_path = file_path.replace('.csv', '_canonicalized.csv')\n",
    "    print(f\"Attempting to save to alternative location: {alternative_path}\")\n",
    "    df.to_csv(alternative_path, index=False)\n",
    "    print(f\"File saved to alternative location: {alternative_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373ed82c-6e08-411c-8533-3f47451eb637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981d2115-3f8e-48b5-8d7e-ad30255e349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # smiles_variation_generator.py\n",
    "    import random\n",
    "    from rdkit import Chem\n",
    "    from rdkit.Chem import AllChem\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    # Disable RDKit logging\n",
    "    import rdkit\n",
    "    rdkit.RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "    class SmilesVariationGenerator:\n",
    "        \"\"\"\n",
    "        A class to generate non-canonical SMILES variations for molecules.\n",
    "\n",
    "        This can be used to augment training data for the MST model by providing\n",
    "        multiple non-canonical representations of the same molecule.\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self, seed=42):\n",
    "            \"\"\"\n",
    "            Initialize the SMILES variation generator.\n",
    "\n",
    "            Args:\n",
    "                seed (int): Random seed for reproducibility\n",
    "            \"\"\"\n",
    "            self.seed = seed\n",
    "            random.seed(seed)\n",
    "\n",
    "        def generate_variations(self, smiles, num_variations=20, max_attempts=1000):\n",
    "            \"\"\"\n",
    "            Generate different non-canonical SMILES representations of the same molecule.\n",
    "\n",
    "            Args:\n",
    "                smiles (str): Input SMILES string\n",
    "                num_variations (int): Number of different SMILES strings to generate\n",
    "\n",
    "            Returns:\n",
    "                list: List of different SMILES representations\n",
    "            \"\"\"\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol is None:\n",
    "                return [\"Invalid SMILES input\"]\n",
    "\n",
    "            # Get the canonical form for reference\n",
    "            canonical_smiles = Chem.MolToSmiles(mol, isomericSmiles=True)\n",
    "\n",
    "            variations = set()\n",
    "            variations.add(canonical_smiles)  # Include the canonical form\n",
    "\n",
    "            # Method 1: Use random SMILES generation\n",
    "            for i in range(num_variations * 3):  # Try more times than needed as some might be duplicates\n",
    "                if len(variations) >= num_variations:\n",
    "                    break\n",
    "                random.seed(self.seed + i)  # Change seed for each attempt\n",
    "                random_smiles = Chem.MolToSmiles(mol, doRandom=True, canonical=False, allBondsExplicit=False)\n",
    "                variations.add(random_smiles)\n",
    "\n",
    "            # Method 2: Change atom ordering\n",
    "            for i in range(min(5, num_variations)):\n",
    "                if len(variations) >= num_variations:\n",
    "                    break\n",
    "                random.seed(self.seed + i + 100)  # Different seed range\n",
    "                mol = Chem.MolFromSmiles(smiles)\n",
    "                atoms = list(range(mol.GetNumAtoms()))\n",
    "                random.shuffle(atoms)\n",
    "                random_mol = Chem.RenumberAtoms(mol, atoms)\n",
    "                variations.add(Chem.MolToSmiles(random_mol, canonical=False, allBondsExplicit=False))\n",
    "\n",
    "            # Method 3: Change starting atom and bond representation\n",
    "            for i in range(min(5, num_variations)):\n",
    "                if len(variations) >= num_variations:\n",
    "                    break\n",
    "                random.seed(self.seed + i + 200)  # Different seed range\n",
    "                mol = Chem.MolFromSmiles(smiles)\n",
    "                start_atom = random.randint(0, mol.GetNumAtoms()-1)\n",
    "                random_smiles = Chem.MolToSmiles(mol, rootedAtAtom=start_atom, canonical=False, \n",
    "                                                 allBondsExplicit=bool(i % 2))\n",
    "                variations.add(random_smiles)\n",
    "\n",
    "            # Method 4: Generate SMARTS with different features\n",
    "            smarts_options = [\n",
    "                (True, True, True, True),    # kekuleSmiles, allBondsExplicit, allHsExplicit, isomericSmiles\n",
    "                (False, True, False, True),  # Different combination\n",
    "                (True, False, True, True),   # Different combination\n",
    "                (False, False, False, True), # Different combination\n",
    "            ]\n",
    "\n",
    "            for i, options in enumerate(smarts_options):\n",
    "                if len(variations) >= num_variations:\n",
    "                    break\n",
    "                kekule, allBonds, allHs, isomeric = options\n",
    "                try:\n",
    "                    variant = Chem.MolToSmiles(mol, kekuleSmiles=kekule, allBondsExplicit=allBonds, \n",
    "                                              allHsExplicit=allHs, isomericSmiles=isomeric, canonical=False)\n",
    "                    variations.add(variant)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            # Convert set to list and ensure we have the requested number of variations\n",
    "            result = list(variations)\n",
    "\n",
    "            # If we need more variations, generate some with truly randomized atom ordering\n",
    "            attempts = 0\n",
    "            max_remaining_attempts = max_attempts // 4  # Reserve 1/4 of max attempts for this method\n",
    "\n",
    "            while len(result) < num_variations and attempts < max_remaining_attempts:\n",
    "                try:\n",
    "                    attempts += 1\n",
    "                    random.seed(len(result) + self.seed + 500 + attempts)  # Different seed\n",
    "                    mol = Chem.MolFromSmiles(smiles)\n",
    "                    atoms = list(range(mol.GetNumAtoms()))\n",
    "                    random.shuffle(atoms)\n",
    "                    random_mol = Chem.RenumberAtoms(mol, atoms)\n",
    "                    new_smiles = Chem.MolToSmiles(random_mol, doRandom=True, canonical=False, \n",
    "                                                 allBondsExplicit=bool(random.randint(0, 1)))\n",
    "                    if new_smiles not in result:\n",
    "                        result.append(new_smiles)\n",
    "                except:\n",
    "                    # If we encounter an error, just continue to the next attempt\n",
    "                    continue\n",
    "\n",
    "            return result[:num_variations]\n",
    "\n",
    "        def augment_dataset(self, df, smiles_column='SMILES', num_variations=20, expand=True):\n",
    "            \"\"\"\n",
    "            Augment a dataset by generating non-canonical SMILES variations.\n",
    "\n",
    "            Args:\n",
    "                df (pd.DataFrame): Input dataframe containing SMILES\n",
    "                smiles_column (str): Name of the column containing SMILES strings\n",
    "                num_variations (int): Number of variations to generate per molecule\n",
    "                expand (bool): If True, expands the dataset with all variations\n",
    "                               If False, adds variations as a new column\n",
    "\n",
    "            Returns:\n",
    "                pd.DataFrame: Augmented dataframe\n",
    "            \"\"\"\n",
    "            if expand:\n",
    "                # Create an expanded dataframe with all variations\n",
    "                expanded_rows = []\n",
    "\n",
    "                for _, row in df.iterrows():\n",
    "                    smiles = row[smiles_column]\n",
    "                    variations = self.generate_variations(smiles, num_variations)\n",
    "\n",
    "                    # Create a new row for each variation\n",
    "                    for var in variations:\n",
    "                        new_row = row.copy()\n",
    "                        new_row[smiles_column] = var\n",
    "                        expanded_rows.append(new_row)\n",
    "\n",
    "                return pd.DataFrame(expanded_rows)\n",
    "            else:\n",
    "                # Add variations as a new column\n",
    "                variations_list = []\n",
    "\n",
    "                for _, row in df.iterrows():\n",
    "                    smiles = row[smiles_column]\n",
    "                    variations = self.generate_variations(smiles, num_variations)\n",
    "                    variations_list.append(variations)\n",
    "\n",
    "                df_copy = df.copy()\n",
    "                df_copy['smiles_variations'] = variations_list\n",
    "                return df_copy\n",
    "\n",
    "    # Example usage\n",
    "    if __name__ == \"__main__\":\n",
    "        # Example SMILES - aspirin\n",
    "        test_smiles = \"CC(=O)OC1=CC=CC=C1C(=O)O\"\n",
    "\n",
    "        # Create generator\n",
    "        generator = SmilesVariationGenerator(seed=42)\n",
    "\n",
    "        # Generate variations\n",
    "        variations = generator.generate_variations(test_smiles, num_variations=30)\n",
    "\n",
    "        # Display results\n",
    "        print(f\"Original SMILES: {test_smiles}\")\n",
    "        print(f\"Generated {len(variations)} different SMILES representations:\")\n",
    "        for i, var in enumerate(variations):\n",
    "            print(f\"{i+1}. {var}\")\n",
    "\n",
    "        # Create a sample dataframe\n",
    "        df = pd.DataFrame({\n",
    "            'SMILES': [test_smiles, \"CCO\", \"c1ccccc1\"],\n",
    "            'Name': ['Aspirin', 'Ethanol', 'Benzene']\n",
    "        })\n",
    "\n",
    "        # Augment the dataframe\n",
    "        augmented_df = generator.augment_dataset(df, num_variations=5)\n",
    "\n",
    "        # Display the augmented dataframe\n",
    "        print(\"\\nAugmented DataFrame:\")\n",
    "        print(f\"Original size: {len(df)}, Augmented size: {len(augmented_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0644a4e-0598-45e9-8bf4-010ce519ff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import the SMILES variation generator\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(\"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/utils_MMT\")\n",
    "from smiles_variation_generator import SmilesVariationGenerator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cb3fe0-0956-4a11-a8b0-190c1e2375ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plot Target + Starting Material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537f0429-c452-4d3c-a725-5db02bfff4d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "# --- Step 1: Load your JSON data ---\n",
    "# Replace with your actual file path.\n",
    "json_filepath = \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/data/molecular_data/archive/molecular_data_20250206_124830.json\"\n",
    "with open(json_filepath, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# --- Step 2: Loop over each sample and visualize ---\n",
    "for sample_id, sample in data.items():\n",
    "    # Extract the target SMILES and create an RDKit molecule.\n",
    "    target_smiles = sample[\"molecule_data\"][\"smiles\"]\n",
    "    target_mol = Chem.MolFromSmiles(target_smiles)\n",
    "    \n",
    "    # Extract the list of starting SMILES.\n",
    "    starting_smiles_list = sample[\"molecule_data\"][\"starting_smiles\"]\n",
    "    \n",
    "    # --- Step 2a: Canonicalize and remove duplicates ---\n",
    "    unique_starting_smiles = []\n",
    "    unique_starting_mols = []\n",
    "    for smi in starting_smiles_list:\n",
    "        mol = Chem.MolFromSmiles(smi)\n",
    "        if mol is None:\n",
    "            continue  # skip if invalid\n",
    "        # Get the canonical SMILES string (this standardizes atom ordering etc.)\n",
    "        canon_smi = Chem.MolToSmiles(mol, canonical=True)\n",
    "        if canon_smi not in unique_starting_smiles:\n",
    "            unique_starting_smiles.append(canon_smi)\n",
    "            unique_starting_mols.append(mol)\n",
    "    n_start = len(unique_starting_mols)\n",
    "\n",
    "    # --- Step 3: Set up the Matplotlib grid ---\n",
    "    # Top row: target molecule spanning all columns.\n",
    "    # Bottom row: each unique starting material in its own subplot.\n",
    "    fig = plt.figure(figsize=(3 * max(n_start, 1), 6))\n",
    "    gs = gridspec.GridSpec(2, n_start if n_start > 0 else 1, height_ratios=[1, 1])\n",
    "    \n",
    "    # Plot the target molecule in the first (top) row, spanning all columns.\n",
    "    ax_target = plt.subplot(gs[0, :])\n",
    "    # Increase the image width proportionally to the number of starting materials.\n",
    "    target_img = Draw.MolToImage(target_mol, size=(300 * max(n_start, 1), 300))\n",
    "    ax_target.imshow(target_img)\n",
    "    ax_target.set_title(f\"Target: {target_smiles}\", fontsize=12)\n",
    "    ax_target.axis(\"off\")\n",
    "    \n",
    "    # Plot each unique starting material in the bottom row.\n",
    "    for i, mol in enumerate(unique_starting_mols):\n",
    "        ax = plt.subplot(gs[1, i])\n",
    "        mol_img = Draw.MolToImage(mol, size=(300, 300))\n",
    "        # Use the canonical SMILES in the title to show that duplicates have been removed.\n",
    "        ax.set_title(f\"Starting {i+1}:\\n{unique_starting_smiles[i]}\", fontsize=8)\n",
    "        ax.imshow(mol_img)\n",
    "        ax.axis(\"off\")\n",
    "    \n",
    "    # Add an overall title with the sample ID.\n",
    "    plt.suptitle(f\"Sample {sample_id}\", fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30fbb78-c802-4fba-bba9-ae093fb49ff1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "import logging\n",
    "\n",
    "# Suppress PIL debug logs\n",
    "logging.getLogger(\"PIL.PngImagePlugin\").setLevel(logging.ERROR)\n",
    "\n",
    "# --- Step 1: Load your JSON data ---\n",
    "json_filepath = \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/data/molecular_data/molecular_data.json\"\n",
    "with open(json_filepath, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# --- Step 2: Loop over each sample and visualize ---\n",
    "for sample_id, sample in data.items():\n",
    "    # -------------------------------\n",
    "    # Process the target molecule\n",
    "    # -------------------------------\n",
    "    target_smiles = sample[\"molecule_data\"][\"smiles\"]\n",
    "    target_mol = Chem.MolFromSmiles(target_smiles)\n",
    "    \n",
    "    # -------------------------------\n",
    "    # Process starting materials (deduplicated)\n",
    "    # -------------------------------\n",
    "    starting_smiles_list = sample[\"molecule_data\"].get(\"starting_smiles\", [])\n",
    "    unique_starting_smiles = []\n",
    "    unique_starting_mols = []\n",
    "    for smi in starting_smiles_list:\n",
    "        mol = Chem.MolFromSmiles(smi)\n",
    "        if mol is None:\n",
    "            continue  # skip if invalid\n",
    "        canon_smi = Chem.MolToSmiles(mol, canonical=True)\n",
    "        if canon_smi not in unique_starting_smiles:\n",
    "            unique_starting_smiles.append(canon_smi)\n",
    "            unique_starting_mols.append(mol)\n",
    "    n_start = len(unique_starting_mols)\n",
    "    \n",
    "    # -------------------------------\n",
    "    # Process forward predictions (deduplicated)\n",
    "    # -------------------------------\n",
    "    forward_predictions = sample[\"molecule_data\"].get(\"forward_predictions\", [])\n",
    "    all_forward_smiles = []\n",
    "    all_forward_mols = []\n",
    "    for prediction in forward_predictions:\n",
    "        for pred_smi in prediction.get(\"all_predictions\", []):\n",
    "            mol = Chem.MolFromSmiles(pred_smi)\n",
    "            if mol is None:\n",
    "                continue\n",
    "            canon_smi = Chem.MolToSmiles(mol, canonical=True)\n",
    "            if canon_smi not in all_forward_smiles:\n",
    "                all_forward_smiles.append(canon_smi)\n",
    "                all_forward_mols.append(mol)\n",
    "    n_forward = len(all_forward_mols)\n",
    "    \n",
    "    # -------------------------------\n",
    "    # Plotting Setup: Create a grid with 3 rows\n",
    "    # Row 0: Target molecule (spanning all columns)\n",
    "    # Row 1: Starting materials (one per column)\n",
    "    # Row 2: Forward reaction products (one per column)\n",
    "    # -------------------------------\n",
    "    n_cols = max(n_start, n_forward, 1)  # Ensure at least one column exists.\n",
    "    fig = plt.figure(figsize=(3 * n_cols, 9))\n",
    "    gs = gridspec.GridSpec(3, n_cols, height_ratios=[1, 1, 1])\n",
    "    \n",
    "    # --- Row 0: Plot the target molecule ---\n",
    "    ax_target = plt.subplot(gs[0, :])\n",
    "    # Adjust image size according to number of columns\n",
    "    target_img = Draw.MolToImage(target_mol, size=(300 * n_cols, 300))\n",
    "    ax_target.imshow(target_img)\n",
    "    ax_target.set_title(f\"Target:\\n{target_smiles}\", fontsize=12)\n",
    "    ax_target.axis(\"off\")\n",
    "    \n",
    "    # --- Row 1: Plot starting materials ---\n",
    "    if n_start == 0:\n",
    "        # If no starting materials, leave a note.\n",
    "        ax = plt.subplot(gs[1, 0])\n",
    "        ax.text(0.5, 0.5, \"No starting materials\", ha='center', va='center')\n",
    "        ax.axis(\"off\")\n",
    "    else:\n",
    "        for i, mol in enumerate(unique_starting_mols):\n",
    "            ax = plt.subplot(gs[1, i])\n",
    "            mol_img = Draw.MolToImage(mol, size=(300, 300))\n",
    "            ax.imshow(mol_img)\n",
    "            ax.set_title(f\"Starting {i+1}:\\n{unique_starting_smiles[i]}\", fontsize=8)\n",
    "            ax.axis(\"off\")\n",
    "    \n",
    "    # --- Row 2: Plot forward predictions ---\n",
    "    if n_forward == 0:\n",
    "        ax = plt.subplot(gs[2, 0])\n",
    "        ax.text(0.5, 0.5, \"No forward predictions\", ha='center', va='center')\n",
    "        ax.axis(\"off\")\n",
    "    else:\n",
    "        for i, mol in enumerate(all_forward_mols):\n",
    "            ax = plt.subplot(gs[2, i])\n",
    "            mol_img = Draw.MolToImage(mol, size=(300, 300))\n",
    "            ax.imshow(mol_img)\n",
    "            ax.set_title(f\"Forward {i+1}:\\n{all_forward_smiles[i]}\", fontsize=8)\n",
    "            ax.axis(\"off\")\n",
    "    \n",
    "    plt.suptitle(f\"Sample {sample_id}\", fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.93])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79397d26-1514-4324-b319-98c95588a524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9e40148-17ee-49b6-8bca-80879b7e8c03",
   "metadata": {},
   "source": [
    "## Data Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4490eea-b037-4f82-b7cf-e7e7e7c4bae5",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Merge augmented smiles to master csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be968bc-658f-4f85-bb27-4e43f197afb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "\n",
    "def remove_stereochemistry(smiles):\n",
    "    \"\"\"\n",
    "    Remove stereochemical information from a SMILES string using RDKit.\n",
    "    Returns the canonical SMILES without stereochemistry.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert SMILES to mol object\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return ''\n",
    "        \n",
    "        # Remove all stereochemistry information\n",
    "        Chem.RemoveStereochemistry(mol)\n",
    "        \n",
    "        # Convert back to canonical SMILES\n",
    "        return Chem.MolToSmiles(mol, isomericSmiles=False)\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "def add_regio_isomers(nmr_file_path, regio_file_path, output_path):\n",
    "    \"\"\"\n",
    "    Add regio isomers to NMR data file while maintaining exact order of sample IDs,\n",
    "    removing stereochemistry from SMILES, and placing the SMILES_regio_isomers \n",
    "    column right after the SMILES column.\n",
    "    \n",
    "    Parameters:\n",
    "    nmr_file_path (str): Path to combined_sim_nmr_data_no_stereo.csv\n",
    "    regio_file_path (str): Path to file containing regio isomers\n",
    "    output_path (str): Path for saving the new CSV file\n",
    "    \"\"\"\n",
    "    # Read the files\n",
    "    nmr_df = pd.read_csv(nmr_file_path)\n",
    "    regio_df = pd.read_csv(regio_file_path)\n",
    "    \n",
    "    # Get list of sample IDs from NMR file (maintaining order)\n",
    "    nmr_sample_ids = nmr_df['sample-id'].tolist()\n",
    "    \n",
    "    # Create dictionary for quick lookup of regio isomers\n",
    "    regio_dict = dict(zip(regio_df['sample-id'], regio_df['SMILES_regio_isomers']))\n",
    "    \n",
    "    # Initialize list to store matched regio isomers (without stereochemistry)\n",
    "    regio_isomers_list = []\n",
    "    \n",
    "    # Loop through NMR sample IDs in order and get corresponding regio isomers\n",
    "    for sample_id in nmr_sample_ids:\n",
    "        regio_isomer = regio_dict.get(sample_id, '')\n",
    "        # Remove stereochemistry if SMILES exists\n",
    "        if regio_isomer:\n",
    "            regio_isomer = remove_stereochemistry(regio_isomer)\n",
    "        regio_isomers_list.append(regio_isomer)\n",
    "    \n",
    "    # Add the new column to NMR dataframe\n",
    "    nmr_df['SMILES_regio_isomers'] = regio_isomers_list\n",
    "    \n",
    "    # Reorder columns to put SMILES_regio_isomers after SMILES\n",
    "    columns = list(nmr_df.columns)\n",
    "    smiles_idx = columns.index('SMILES')\n",
    "    columns.remove('SMILES_regio_isomers')\n",
    "    columns.insert(smiles_idx + 1, 'SMILES_regio_isomers')\n",
    "    \n",
    "    # Reorder the dataframe columns\n",
    "    nmr_df = nmr_df[columns]\n",
    "    \n",
    "    # Print statistics\n",
    "    total_matches = sum(1 for x in regio_isomers_list if x != '')\n",
    "    print(f\"Total NMR entries: {len(nmr_sample_ids)}\")\n",
    "    print(f\"Matched regio isomers: {total_matches}\")\n",
    "    print(f\"Match rate: {(total_matches/len(nmr_sample_ids))*100:.2f}%\")\n",
    "    \n",
    "    # Print first few entries to verify stereochemistry removal\n",
    "    print(\"\\nFirst 5 entries with stereochemistry removed:\")\n",
    "    for i in range(min(5, len(nmr_sample_ids))):\n",
    "        if regio_isomers_list[i]:\n",
    "            print(f\"Sample ID: {nmr_sample_ids[i]}\")\n",
    "            print(f\"Original SMILES: {regio_dict[nmr_sample_ids[i]]}\")\n",
    "            print(f\"Without stereochemistry: {regio_isomers_list[i]}\\n\")\n",
    "    \n",
    "    # Save the new file\n",
    "    nmr_df.to_csv(output_path, index=False)\n",
    "    print(f\"\\nSaved new file to: {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    nmr_file = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/ACD_data/combined_acd_nmr_data_no_stereo.csv\"\n",
    "    regio_file = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Sim_ACD_Exp_aug/ACD_1H_with_SN_filtered_v3_regio_aug.csv\"\n",
    "    output_file = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/ACD_data/combined_acd_nmr_data_no_stereo_aug_added.csv\"\n",
    "    \n",
    "    add_regio_isomers(nmr_file, regio_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba714db-628a-4e6a-96a9-c87551e0d94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merge_regio_isomers(\n",
    "    \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/47_Anna_paper_data/Sim_ACD_Exp_aug/ACD_1H_with_SN_filtered_v3_regio_aug.csv\",\n",
    "    \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\",\n",
    "    \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo_aug_added.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11490981-9dc4-4ee1-b1b1-49581014a111",
   "metadata": {},
   "source": [
    "### Combine all code to one file\n",
    "- For AI support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557b9079-f028-47e3-b85c-d5f2906dbbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def generate_directory_structure(root_dir, exclude_dirs):\n",
    "    directory_structure = []\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        # Check if the current directory is in the exclude list\n",
    "        if any(os.path.commonpath([root, os.path.join(root_dir, exclude_dir)]) == os.path.join(root_dir, exclude_dir) for exclude_dir in exclude_dirs):\n",
    "            continue  # Skip this directory and its subdirectories\n",
    "        level = root.replace(root_dir, '').count(os.sep)\n",
    "        indent = ' ' * 4 * (level)\n",
    "        directory_structure.append(f\"{indent}{os.path.basename(root)}/\")\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        for f in files:\n",
    "            directory_structure.append(f\"{subindent}{f}\")\n",
    "    return '\\n'.join(directory_structure)\n",
    "\n",
    "def combine_code_files(root_dir, output_file, exclude_dirs):\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        # Write the directory structure at the beginning\n",
    "        directory_structure = generate_directory_structure(root_dir, exclude_dirs)\n",
    "        outfile.write(f\"Repository Structure:\\n{directory_structure}\\n\\n\")\n",
    "        \n",
    "        # Write the contents of each code file\n",
    "        for root, dirs, files in os.walk(root_dir):\n",
    "            # Check if the current directory is in the exclude list\n",
    "            if any(os.path.commonpath([root, os.path.join(root_dir, exclude_dir)]) == os.path.join(root_dir, exclude_dir) for exclude_dir in exclude_dirs):\n",
    "                continue  # Skip this directory and its subdirectories\n",
    "            for file in files:\n",
    "                if file.endswith('.py'):  # Adjust the extension as needed\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    outfile.write(f'--- {file_path} ---\\n')\n",
    "                    with open(file_path, 'r') as infile:\n",
    "                        outfile.write(infile.read())\n",
    "                    outfile.write('\\n\\n')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    repository_path = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator'  # Replace with your repository path\n",
    "    output_filename = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/combined_code_with_structure.py'\n",
    "    exclude_dirs = [\n",
    "        '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder',\n",
    "        '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/analysis_files',\n",
    "        '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/data/molecular_data/archive',\n",
    "        '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/logs',\n",
    "        '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/uploads',\n",
    "        \n",
    "        # Add more directories as needed\n",
    "    ]\n",
    "    combine_code_files(repository_path, output_filename, exclude_dirs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692aa671-9710-48cf-b8e2-1fe1450b1f94",
   "metadata": {},
   "source": [
    "### Fix KIMI LLM result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5544b23f-f808-4b77-a111-ce4cee29e917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def extract_kimi_json(raw_text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract JSON content from Kimi model output.\n",
    "    \n",
    "    Args:\n",
    "        raw_text: Raw text output from the Kimi model\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing:\n",
    "            - json_content: The parsed JSON content (or raw JSON substring if parsing fails)\n",
    "            - reasoning_content: The reasoning text preceding the JSON\n",
    "    \"\"\"\n",
    "    if not raw_text:\n",
    "        return {'json_content': {}, 'reasoning_content': ''}\n",
    "    \n",
    "    def clean_json_string(json_str: str) -> str:\n",
    "        # Remove invalid control characters\n",
    "        cleaned = re.sub(r'[\\x00-\\x1f]+', \" \", json_str)\n",
    "        cleaned = cleaned.replace('\\\\\"', '\"')\n",
    "\n",
    "        # Normalize boolean and null values\n",
    "        cleaned = (cleaned\n",
    "                .replace(\"True\", \"true\")\n",
    "                .replace(\"False\", \"false\")\n",
    "                .replace(\"None\", \"null\"))\n",
    "                \n",
    "        # Remove trailing commas before closing braces/brackets\n",
    "        cleaned = re.sub(r',(\\s*[}\\]])', r'\\1', cleaned)\n",
    "        \n",
    "        return cleaned.strip()\n",
    "    \n",
    "    def find_json_boundaries(text: str) -> tuple[int, int]:\n",
    "        start = text.find('{')\n",
    "        if start == -1:\n",
    "            return -1, -1\n",
    "            \n",
    "        brace_count = 0\n",
    "        end = -1\n",
    "        \n",
    "        for i, char in enumerate(text[start:], start):\n",
    "            if char == '{':\n",
    "                brace_count += 1\n",
    "            elif char == '}':\n",
    "                brace_count -= 1\n",
    "                if brace_count == 0:\n",
    "                    end = i + 1\n",
    "                    break\n",
    "                    \n",
    "        return start, end\n",
    "    \n",
    "    try:\n",
    "        # First try direct JSON parsing\n",
    "        try:\n",
    "            return {\n",
    "                'json_content': json.loads(clean_json_string(raw_text)),\n",
    "                'reasoning_content': ''\n",
    "            }\n",
    "        except json.JSONDecodeError:\n",
    "            # If direct parsing fails, try to find JSON object in the response\n",
    "            start, end = find_json_boundaries(raw_text)\n",
    "            if start != -1 and end != -1:\n",
    "                json_str = clean_json_string(raw_text[start:end])\n",
    "                try:\n",
    "                    return {\n",
    "                        'json_content': json.loads(json_str),\n",
    "                        'reasoning_content': raw_text[:start].strip()\n",
    "                    }\n",
    "                except json.JSONDecodeError:\n",
    "                    return {\n",
    "                        'json_content': raw_text[start:end],\n",
    "                        'reasoning_content': raw_text[:start].strip()\n",
    "                    }\n",
    "            return {'json_content': {}, 'reasoning_content': raw_text.strip()}\n",
    "            \n",
    "    except Exception as e:\n",
    "        return {'json_content': {}, 'reasoning_content': raw_text.strip()}\n",
    "\n",
    "def clean_content(content: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean the content string by:\n",
    "    1. Decoding unicode escape sequences\n",
    "    2. Replacing escaped quotes\n",
    "    3. Fixing any common formatting issues\n",
    "    \n",
    "    Args:\n",
    "        content: Raw content string from the message\n",
    "        \n",
    "    Returns:\n",
    "        Cleaned content string\n",
    "    \"\"\"\n",
    "    # Decode unicode escape sequences\n",
    "    # Replace escaped quotes\n",
    "    content = content.replace('\\\\\"', '\"')\n",
    "    content = content.replace('\\\\\"', '\"')\n",
    "    \n",
    "    # Remove any remaining escape characters\n",
    "    content = content.replace('\\\\n', ' ')\n",
    "    content = content.replace('\\\\t', ' ')\n",
    "    content = content.replace('\\\\r', ' ')\n",
    "    \n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84798265-8236-40f0-815e-cbc28c226ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files = [\n",
    "    \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/AZ12129293_exp_d1_aug_intermediate.json\"             \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4f51dc-0da0-436b-a3f5-79a1349ded97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load input:\n",
    "\n",
    "for json_path in json_files:\n",
    "    # Load and process each JSON file\n",
    "    print(json_path)\n",
    "    with open(json_path) as f:\n",
    "        data = json.load(f)\n",
    "    test_content = data[\"analysis_results\"][\"final_analysis\"][\"llm_responses\"][\"kimi\"][\"analysis_prompt\"]\n",
    "    #test_content = data[\"analysis_results\"]['final_analysis']['metadata'][\"analysis_prompt\"]\n",
    "\n",
    "    import openai\n",
    "\n",
    "    # Configure OpenAI client with Moonshot details\n",
    "    openai.api_key = \"sk-QWUjltc5N6CWT4FOfjIPl0X8ZhotO88TY0Yk3ncl6iwir222\"\n",
    "    openai.api_base = \"https://api.moonshot.ai/v1\"\n",
    "\n",
    "    # Test content\n",
    "    # test_content = \"what is sin and cos?\"\n",
    "\n",
    "\n",
    "    # Create messages array\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": test_content}\n",
    "    ]\n",
    "\n",
    "    # Set up parameters\n",
    "    params = {\n",
    "        \"model\": \"kimi-k1.5-preview\",\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.3,\n",
    "        \"max_tokens\": 8000,  # Smaller token count for testing\n",
    "        \"stream\": False\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Make the API call\n",
    "        response = openai.ChatCompletion.create(**params)\n",
    "\n",
    "        # # Handle streaming response\n",
    "        # full_response = \"\"\n",
    "        # for chunk in response:\n",
    "        #     if chunk.choices[0].delta.content:\n",
    "        #         content_chunk = chunk.choices[0].delta.content\n",
    "        #         full_response += content_chunk\n",
    "        #         print(content_chunk, end=\"\")\n",
    "\n",
    "        # print(\"\\n\\nFull response:\", full_response)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during API call: {str(e)}\")\n",
    "    raw_text = response['choices'][0]['message']['content']\n",
    "    raw_text_ = clean_content(raw_text)\n",
    "    raw_text__= extract_kimi_json(raw_text_)['json_content']\n",
    "    data[\"analysis_results\"][\"final_analysis\"][\"llm_responses\"][\"kimi\"][\"parsed_results\"] = raw_text__\n",
    "    # Load and process each JSON file\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(data, f,  indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d6bfc8-efc0-413b-992f-9005174803ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"analysis_results\"]['final_analysis']['metadata'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f914f21d-19a7-4fb6-9402-ad9c76c69447",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Test Claude 3.7\n",
    "- Run on Windows environment to add it\n",
    "- pip install anthropic==0.47.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b78a761-258c-4a83-97bb-07127ca14bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"C:\\\\windsurf_repo\\\\data_json\\\\test_folder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207748f8-2856-43b6-a4cf-6ce27fb8d6a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import anthropic\n",
    "import re\n",
    "from typing import Dict, Any, Tuple\n",
    "\n",
    "def extract_json_content(raw_text: str) -> Dict[str, Any]:\n",
    "    \"\"\"Extract JSON content from Claude's response text.\"\"\"\n",
    "    # Find JSON boundaries\n",
    "    def find_json_boundaries(text: str) -> Tuple[int, int]:\n",
    "        start = text.find('{')\n",
    "        if start == -1:\n",
    "            return -1, -1\n",
    "        \n",
    "        brace_count = 0\n",
    "        end = -1\n",
    "        \n",
    "        for i, char in enumerate(text[start:], start):\n",
    "            if char == '{':\n",
    "                brace_count += 1\n",
    "            elif char == '}':\n",
    "                brace_count -= 1\n",
    "                if brace_count == 0:\n",
    "                    end = i + 1\n",
    "                    break\n",
    "        return start, end\n",
    "    \n",
    "    # Clean JSON string\n",
    "    def clean_json_string(json_str: str) -> str:\n",
    "        # Remove control characters\n",
    "        cleaned = re.sub(r'[\\x00-\\x1f]+', \" \", json_str)\n",
    "        \n",
    "        # Normalize boolean and null values\n",
    "        cleaned = (cleaned\n",
    "                .replace(\"True\", \"true\")\n",
    "                .replace(\"False\", \"false\")\n",
    "                .replace(\"None\", \"null\"))\n",
    "        \n",
    "        # Fix trailing commas\n",
    "        cleaned = re.sub(r',(\\s*[}\\]])', r'\\1', cleaned)\n",
    "        \n",
    "        return cleaned.strip()\n",
    "    \n",
    "    # Extract JSON\n",
    "    try:\n",
    "        # Look for JSON marker\n",
    "        json_marker = \"JSON_RESULT =\"\n",
    "        marker_index = raw_text.find(json_marker)\n",
    "        \n",
    "        if marker_index == -1:\n",
    "            # Try case-insensitive \"json\" as fallback\n",
    "            marker_index = raw_text.lower().find(\"json\")\n",
    "            if marker_index != -1:\n",
    "                marker_len = 4  # len(\"json\")\n",
    "            else:\n",
    "                # No marker found, look for raw JSON\n",
    "                start, end = find_json_boundaries(raw_text)\n",
    "                if start != -1 and end != -1:\n",
    "                    reasoning_content = raw_text[:start].strip()\n",
    "                    json_str = clean_json_string(raw_text[start:end])\n",
    "                    try:\n",
    "                        return json.loads(json_str)\n",
    "                    except:\n",
    "                        return {\"raw_json\": json_str}\n",
    "                return {}\n",
    "        else:\n",
    "            marker_len = len(json_marker)\n",
    "        \n",
    "        json_text = raw_text[marker_index + marker_len:].strip()\n",
    "        \n",
    "        # Find and extract the JSON object\n",
    "        start, end = find_json_boundaries(json_text)\n",
    "        if start != -1 and end != -1:\n",
    "            json_str = clean_json_string(json_text[start:end])\n",
    "            \n",
    "            # Try parsing with json.loads\n",
    "            try:\n",
    "                return json.loads(json_str)\n",
    "            except json.JSONDecodeError:\n",
    "                return {\"raw_json\": json_str}\n",
    "        \n",
    "        return {}\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting JSON: {str(e)}\")\n",
    "        return {}\n",
    "\n",
    "def process_json_files(folder_path: str, claude_api_key: str):\n",
    "    # Initialize Anthropic client\n",
    "    client = anthropic.Anthropic(api_key=claude_api_key)\n",
    "    \n",
    "    # Get all JSON files in the folder\n",
    "    json_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.json')]\n",
    "    \n",
    "    for json_path in json_files[:]:\n",
    "        print(f\"Processing: {json_path}\")\n",
    "        \n",
    "        # Load the JSON file\n",
    "        with open(json_path) as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        try:\n",
    "            # Extract the analysis prompt\n",
    "            try:\n",
    "                analysis_prompt = data[\"analysis_results\"][\"final_analysis\"][\"llm_responses\"][\"kimi\"][\"analysis_prompt\"]\n",
    "            except:\n",
    "                analysis_prompt = data[\"analysis_results\"]['final_analysis']['metadata'][\"analysis_prompt\"]\n",
    "\n",
    "            # Send to Claude 3.7\n",
    "            response = client.messages.create(\n",
    "                model=\"claude-3-7-sonnet-20250219\",\n",
    "                max_tokens=20000,\n",
    "                thinking={\n",
    "                    \"type\": \"enabled\",\n",
    "                    \"budget_tokens\": 10000\n",
    "                },\n",
    "                messages=[{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": analysis_prompt\n",
    "                }]\n",
    "            )\n",
    "            \n",
    "            # Extract thinking and normal response\n",
    "            thinking = \"\"\n",
    "            normal_response = \"\"\n",
    "            \n",
    "            for content_block in response.content:\n",
    "                if hasattr(content_block, 'thinking') and content_block.thinking:\n",
    "                    thinking = content_block.thinking\n",
    "                elif hasattr(content_block, 'text') and content_block.text:\n",
    "                    normal_response = content_block.text\n",
    "            \n",
    "            # Extract reasoning content - everything before JSON\n",
    "            json_start = normal_response.find(\"{\")\n",
    "            reasoning_content = normal_response[:json_start].strip() if json_start > 0 else \"\"\n",
    "            \n",
    "            # Extract JSON from normal response\n",
    "            parsed_results = extract_json_content(normal_response)\n",
    "            \n",
    "            # Create Claude entry in llm_responses\n",
    "            claude_results = {\n",
    "                \"raw_response\": normal_response,\n",
    "                \"parsed_results\": parsed_results,\n",
    "                \"reasoning_content\": reasoning_content,\n",
    "                \"thinking\": thinking,\n",
    "                \"analysis_prompt\": analysis_prompt,\n",
    "                \"config\": {\n",
    "                    \"model\": \"claude-3-7-sonnet-20250219\",\n",
    "                    \"system\": \"You are an expert chemist specializing in structure elucidation and spectral analysis. Analyze molecular candidates based on all available evidence and provide detailed scientific assessments.\"\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Add Claude results to the JSON\n",
    "            data[\"analysis_results\"][\"final_analysis\"][\"llm_responses\"][\"claude3-7\"] = claude_results\n",
    "            \n",
    "            # Save the updated JSON\n",
    "            with open(json_path, 'w') as f:\n",
    "                json.dump(data, f, indent=2)\n",
    "                \n",
    "            print(f\"Successfully updated {json_path} with Claude 3.7 results\")\n",
    "            \n",
    "        except KeyError as e:\n",
    "            print(f\"Error: Could not find expected key in {json_path}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {json_path}: {e}\")\n",
    "\n",
    "# Call the function with your folder path and API key\n",
    "folder = \"C:\\\\windsurf_repo\\\\data_json\\\\_run_6.0_exp_d1_aug_finished\"\n",
    "\n",
    "api_key=\"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\"\n",
    "\n",
    "process_json_files(folder, api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63500893-94a9-48de-a80a-77ba33648c9b",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "### Remove redundand data from json - json clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9ec548-9684-40ea-b2ce-ec41d2ff7a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def remove_unwanted_keys(d):\n",
    "    \"\"\"Recursively remove keys containing 'nmr_data', 'peak_matches', or 'matched_peaks'.\"\"\"\n",
    "    if isinstance(d, dict):\n",
    "        # List of keys to remove\n",
    "        keys_to_remove = [key for key in d if 'nmr_data' in key.lower() or 'peak_matches' in key.lower() or 'matched_peaks' in key.lower() or 'generatedSmilesProbabilities'.lower() in key.lower() or 'all_log_likelihoods' in key.lower() or 'spectra_matching' in key.lower() or 'peak_matching_results' in key.lower()]\n",
    "        for key in keys_to_remove:\n",
    "            del d[key]\n",
    "        # Recursively process all values\n",
    "        for key, value in d.items():\n",
    "            remove_unwanted_keys(value)\n",
    "    elif isinstance(d, list):\n",
    "        for item in d:\n",
    "            remove_unwanted_keys(item)\n",
    "\n",
    "def remove_unwanted_data_and_save(input_file_path):\n",
    "    # Load the original JSON data\n",
    "    with open(input_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Remove unwanted keys ('nmr_data', 'peak_matches', 'matched_peaks') recursively\n",
    "    remove_unwanted_keys(data)\n",
    "\n",
    "    # Create the new file name with \"_small\" suffix\n",
    "    base_name, ext = os.path.splitext(input_file_path)\n",
    "    new_file_path = f\"{base_name}_small{ext}\"\n",
    "\n",
    "    # Save the modified data to a new file\n",
    "    with open(new_file_path, 'w') as new_file:\n",
    "        json.dump(data, new_file, indent=4)\n",
    "\n",
    "    print(f\"Saved the modified file as: {new_file_path}\")\n",
    "\n",
    "\n",
    "# Example usage: loop over a list of files\n",
    "file_paths = [\n",
    "\n",
    "]\n",
    "\n",
    "for file_path in file_paths:\n",
    "    remove_unwanted_data_and_save(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913cfbd1-0fcd-489a-85f4-172c55cda644",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def remove_unwanted_keys(d):\n",
    "    \"\"\"Recursively remove keys containing 'nmr_data', 'peak_matches', or 'matched_peaks' etc.\"\"\"\n",
    "    if isinstance(d, dict):\n",
    "        # List of keys to remove\n",
    "        keys_to_remove = [key for key in d if 'nmr_data' in key.lower() or \n",
    "                          'peak_matches' in key.lower() or \n",
    "                          'matched_peaks' in key.lower() or \n",
    "                          'generatedSmilesProbabilities'.lower() in key.lower() or \n",
    "                          'all_log_likelihoods' in key.lower() or \n",
    "                          'spectra_matching' in key.lower() or \n",
    "                          'peak_matching_results' in key.lower()]\n",
    "        for key in keys_to_remove:\n",
    "            del d[key]\n",
    "        # Recursively process all values\n",
    "        for key, value in d.items():\n",
    "            remove_unwanted_keys(value)\n",
    "    elif isinstance(d, list):\n",
    "        for item in d:\n",
    "            remove_unwanted_keys(item)\n",
    "\n",
    "def remove_unwanted_data_and_save(input_file_path, output_file_path):\n",
    "    # Load the original JSON data\n",
    "    with open(input_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Remove unwanted keys ('nmr_data', 'peak_matches', 'matched_peaks') recursively\n",
    "    remove_unwanted_keys(data)\n",
    "\n",
    "    # Create the parent directory for the output file if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(output_file_path), exist_ok=True)\n",
    "\n",
    "    # Save the modified data to a new file\n",
    "    with open(output_file_path, 'w') as new_file:\n",
    "        json.dump(data, new_file, indent=4)\n",
    "\n",
    "    print(f\"Saved the modified file as: {output_file_path}\")\n",
    "\n",
    "def process_all_json_files(input_folder):\n",
    "    \n",
    "    # Get the last part of the folder name (i.e., 'run_noise_3.0_finished')\n",
    "    folder_name = os.path.basename(input_folder)\n",
    "    \n",
    "    # Create the output folder by appending '_clean' to the current folder name\n",
    "    output_folder = os.path.join(os.path.dirname(input_folder), f\"{folder_name}_clean\")\n",
    "    \n",
    "    # Loop over all files in the input folder\n",
    "    for root, dirs, files in os.walk(input_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.json'):\n",
    "                try:\n",
    "                    input_file_path = os.path.join(root, file)\n",
    "                    # Build the output file path by replacing the input folder with the clean folder\n",
    "                    relative_path = os.path.relpath(input_file_path, input_folder)\n",
    "                    output_file_path = os.path.join(output_folder, relative_path)\n",
    "\n",
    "                    # Process the file and save it in the new location\n",
    "                    remove_unwanted_data_and_save(input_file_path, output_file_path)\n",
    "                except:\n",
    "                    print(\"--------------------------------\")\n",
    "                    print(input_file_path)\n",
    "\n",
    "# Example usage: loop over all files in the input folder\n",
    "input_folder = '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_6_exp_d4_finished'  # Add paths to your files here\n",
    "process_all_json_files(input_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa011f1-8e84-473b-b81f-9a104651da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_1_sim_finished',  # Add paths to your files here\n",
    "    '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_2_sim_aug_finished',  # Add paths to your files here\n",
    "    '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_3_sim+noise_finished',  # Add paths to your files here\n",
    "    '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_4_exp_d1_finished',  # Add paths to your files here\n",
    "    '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_5_exp_d1_aug_finished',  # Add paths to your files here\n",
    "    '/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_6_exp_d4_finished',  # Add paths to your files here\n",
    "    # Add more file paths if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9e21db-dbbf-4b65-a234-dbfc7e08ba40",
   "metadata": {},
   "source": [
    "### ADC labs data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a20f0c-ef26-4ccc-960f-a275383d4961",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/9_ZINC_250k/ZINC250_ACD_HSQC_train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d02ac5-25e0-4c40-8a99-be6674c879f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "import seaborn as sns\n",
    "\n",
    "# Path to your CSV file\n",
    "file_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/9_ZINC_250k/ZINC250_ACD_HSQC_train.csv\"\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(\"Column names:\", df.columns.tolist())\n",
    "\n",
    "# 1. Calculate molecular weights from SMILES\n",
    "# Function to calculate molecular weight from SMILES string\n",
    "def calculate_mol_weight(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol:\n",
    "        return Descriptors.MolWt(mol)\n",
    "    return None\n",
    "\n",
    "# Apply function to SMILES column (assuming it's called 'SMILES')\n",
    "df['molecular_weight'] = df['SMILES'].apply(calculate_mol_weight)\n",
    "\n",
    "# 2. Calculate number of peaks from shifts column\n",
    "# Function to count the number of peaks in shifts data\n",
    "def count_peaks(shifts_str):\n",
    "    try:\n",
    "        # Parse the string representation of list into actual Python list\n",
    "        shifts_list = ast.literal_eval(shifts_str)\n",
    "        # Count the number of sublists (peaks)\n",
    "        return len(shifts_list)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# Apply function to shifts column\n",
    "df['peak_count'] = df['shifts'].apply(count_peaks)\n",
    "\n",
    "# Create figure for plots (2 rows, 1 column)\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Plot molecular weight histogram\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.histplot(df['molecular_weight'].dropna(), bins=30, kde=True)\n",
    "plt.title('Distribution of Molecular Weights')\n",
    "plt.xlabel('Molecular Weight (Da)')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Calculate and show statistics\n",
    "mw_mean = df['molecular_weight'].mean()\n",
    "mw_median = df['molecular_weight'].median()\n",
    "mw_std = df['molecular_weight'].std()\n",
    "plt.axvline(mw_mean, color='red', linestyle='--', label=f'Mean: {mw_mean:.2f}')\n",
    "plt.axvline(mw_median, color='green', linestyle='--', label=f'Median: {mw_median:.2f}')\n",
    "plt.legend()\n",
    "\n",
    "# Add statistics as text\n",
    "stats_text = f\"Mean: {mw_mean:.2f}\\nMedian: {mw_median:.2f}\\nStd Dev: {mw_std:.2f}\"\n",
    "plt.annotate(stats_text, xy=(0.05, 0.85), xycoords='axes fraction', \n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"gray\", alpha=0.8))\n",
    "\n",
    "# Plot peak count histogram\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.histplot(df['peak_count'].dropna(), bins=range(min(df['peak_count']), max(df['peak_count'])+2), \n",
    "             kde=False, discrete=True)\n",
    "plt.title('Distribution of NMR Peak Counts')\n",
    "plt.xlabel('Number of Peaks')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Calculate and show statistics\n",
    "pc_mean = df['peak_count'].mean()\n",
    "pc_median = df['peak_count'].median()\n",
    "pc_std = df['peak_count'].std()\n",
    "\n",
    "# Add statistics as text\n",
    "stats_text = f\"Mean: {pc_mean:.2f}\\nMedian: {pc_median:.2f}\\nStd Dev: {pc_std:.2f}\"\n",
    "plt.annotate(stats_text, xy=(0.05, 0.85), xycoords='axes fraction', \n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"gray\", alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('nmr_analysis.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\nMolecular Weight Statistics:\")\n",
    "print(df['molecular_weight'].describe())\n",
    "\n",
    "print(\"\\nPeak Count Statistics:\")\n",
    "print(df['peak_count'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3723d906-166b-4d58-a07c-745f03b2c01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import os\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "import random\n",
    "\n",
    "# Path to your CSV file\n",
    "file_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/9_ZINC_250k/ZINC250_ACD_HSQC_train.csv\"\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"molecule_subsets\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load the data\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_csv(file_path)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Column names: {df.columns.tolist()}\")\n",
    "\n",
    "# Function to count the number of peaks in shifts data\n",
    "def count_peaks(shifts_str):\n",
    "    try:\n",
    "        # Parse the string representation of list into actual Python list\n",
    "        shifts_list = ast.literal_eval(shifts_str)\n",
    "        # Count the number of sublists (peaks)\n",
    "        return len(shifts_list)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing shifts: {e}\")\n",
    "        return 0\n",
    "\n",
    "# Function to canonicalize SMILES without stereochemistry\n",
    "def canonicalize_smiles_no_stereo(smiles):\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol:\n",
    "            return Chem.MolToSmiles(mol, isomericSmiles=False, canonical=True)\n",
    "        else:\n",
    "            print(f\"Warning: Could not parse SMILES: {smiles}\")\n",
    "            return smiles\n",
    "    except Exception as e:\n",
    "        print(f\"Error canonicalizing SMILES {smiles}: {e}\")\n",
    "        return smiles\n",
    "\n",
    "# Calculate number of peaks for each molecule\n",
    "print(\"Calculating peak counts...\")\n",
    "df['peak_count'] = df['shifts'].apply(count_peaks)\n",
    "\n",
    "# Canonicalize SMILES strings without stereochemistry\n",
    "print(\"Canonicalizing SMILES strings without stereochemistry...\")\n",
    "df['SMILES'] = df['SMILES'].apply(canonicalize_smiles_no_stereo)\n",
    "\n",
    "# Define the three peak count ranges\n",
    "peak_ranges = [\n",
    "    (3, 7, \"small\"),    # Small: 3-7 peaks\n",
    "    (8, 16, \"medium\"),  # Medium: 8-16 peaks\n",
    "    (17, 25, \"large\")   # Large: 17-25 peaks\n",
    "]\n",
    "\n",
    "# Process and save each subset\n",
    "for min_peaks, max_peaks, size_label in peak_ranges:\n",
    "    print(f\"\\nProcessing {size_label} molecules (peaks: {min_peaks}-{max_peaks})...\")\n",
    "    \n",
    "    # Filter molecules that have peak counts in the specified range\n",
    "    subset = df[(df['peak_count'] >= min_peaks) & (df['peak_count'] <= max_peaks)]\n",
    "    \n",
    "    # Report how many molecules are in this range\n",
    "    print(f\"Found {len(subset)} molecules with {min_peaks}-{max_peaks} peaks\")\n",
    "    \n",
    "    # If we have more than 100 molecules, randomly sample 100\n",
    "    if len(subset) > 100:\n",
    "        subset = subset.sample(n=100, random_state=42)  # Use random_state for reproducibility\n",
    "        print(f\"Randomly selected 100 molecules from this subset\")\n",
    "    elif len(subset) < 100:\n",
    "        print(f\"WARNING: Only {len(subset)} molecules available in this range (less than 100)\")\n",
    "    \n",
    "    # Check the distribution of peak counts in the selected subset\n",
    "    peak_dist = subset['peak_count'].value_counts().sort_index()\n",
    "    print(f\"Peak count distribution in selected subset:\\n{peak_dist}\")\n",
    "    \n",
    "    # Rename 'shifts' column to 'HSQC' (uppercase)\n",
    "    subset = subset.rename(columns={'shifts': 'HSQC'})\n",
    "    \n",
    "    # Add empty columns for additional NMR data\n",
    "    subset['1H_NMR'] = np.nan\n",
    "    subset['13C_NMR'] = np.nan\n",
    "    subset['COSY'] = np.nan\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_file = os.path.join(output_dir, f\"molecules_{size_label}_peaks.csv\")\n",
    "    subset.to_csv(output_file, index=False)\n",
    "    print(f\"Saved {len(subset)} molecules to {output_file}\")\n",
    "\n",
    "print(\"\\nDone! Created the following files:\")\n",
    "for _, _, size_label in peak_ranges:\n",
    "    print(f\"- molecules_{size_label}_peaks.csv\")\n",
    "\n",
    "# Optional: Generate a summary report\n",
    "summary_file = os.path.join(output_dir, \"subset_summary.txt\")\n",
    "with open(summary_file, 'w') as f:\n",
    "    f.write(\"Molecule Subset Summary\\n\")\n",
    "    f.write(\"======================\\n\\n\")\n",
    "    \n",
    "    for min_peaks, max_peaks, size_label in peak_ranges:\n",
    "        output_file = os.path.join(output_dir, f\"molecules_{size_label}_peaks.csv\")\n",
    "        subset = pd.read_csv(output_file)\n",
    "        \n",
    "        f.write(f\"{size_label.capitalize()} Peak Subset ({min_peaks}-{max_peaks} peaks)\\n\")\n",
    "        f.write(f\"- Number of molecules: {len(subset)}\\n\")\n",
    "        f.write(f\"- Peak count statistics: min={subset['peak_count'].min()}, max={subset['peak_count'].max()}, avg={subset['peak_count'].mean():.2f}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "    \n",
    "    f.write(f\"Original dataset: {df.shape[0]} molecules\\n\")\n",
    "\n",
    "print(f\"\\nSummary report saved to {summary_file}\")\n",
    "\n",
    "# Print column names to verify structure\n",
    "for _, _, size_label in peak_ranges:\n",
    "    output_file = os.path.join(output_dir, f\"molecules_{size_label}_peaks.csv\")\n",
    "    test_df = pd.read_csv(output_file)\n",
    "    print(f\"\\nColumns in {os.path.basename(output_file)}:\")\n",
    "    print(test_df.columns.tolist())molecules_small_peaksmolecules_small_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb834ae-2b1f-4689-8381-d3e5ce1c58bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c223d69-8ce3-454d-b09f-c07798f6caee",
   "metadata": {},
   "source": [
    "### Check for missing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cdf1b4-9a85-4305-8b36-50c9fae0c0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898eef1f-30da-4831-a9d5-042e7f02ec1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.listdir(results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a09623-65f0-444f-90a9-3b280c2852d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Define paths\n",
    "csv_file_path = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/53_Lukas_real_data/cleaned_data_CLEAN.csv\"\n",
    "results_folder = \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/Lukas_aug_3_try_finishes\"\n",
    "\n",
    "# Function to check if a sample ID has corresponding files\n",
    "def check_sample_files(sample_id, folder_path):\n",
    "    # Pattern to match files starting with the sample ID\n",
    "    pattern = os.path.join(folder_path, f\"{sample_id}*\")\n",
    "    \n",
    "    # Find files matching the pattern\n",
    "    matching_files = glob.glob(pattern)\n",
    "    \n",
    "    # Return True if files exist, False otherwise\n",
    "    return len(matching_files) > 0\n",
    "\n",
    "# Main function\n",
    "def find_missing_samples():\n",
    "    print(f\"Loading CSV file: {csv_file_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Load CSV file\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        \n",
    "        # Verify that 'sample-id' column exists\n",
    "        if 'sample-id' not in df.columns:\n",
    "            # Try to find similar column names\n",
    "            possible_cols = [col for col in df.columns if 'id' in col.lower() or 'sample' in col.lower()]\n",
    "            \n",
    "            if possible_cols:\n",
    "                print(f\"Column 'sample-id' not found. Possible ID columns: {possible_cols}\")\n",
    "                # Try to use the first possible column\n",
    "                id_column = possible_cols[0]\n",
    "                print(f\"Using '{id_column}' as the sample ID column\")\n",
    "            else:\n",
    "                # Print all column names if no possible ID column is found\n",
    "                print(f\"Column 'sample-id' not found. Available columns: {df.columns.tolist()}\")\n",
    "                return\n",
    "        else:\n",
    "            id_column = 'sample-id'\n",
    "        \n",
    "        # Get all sample IDs from CSV\n",
    "        all_sample_ids = df[id_column].unique()\n",
    "        print(f\"Found {len(all_sample_ids)} unique sample IDs in the CSV file\")\n",
    "        \n",
    "        # Check if results folder exists\n",
    "        if not os.path.exists(results_folder):\n",
    "            print(f\"Warning: Results folder path does not exist: {os.path.dirname(results_folder)}\")\n",
    "            return\n",
    "        \n",
    "        # List all files in the results folder\n",
    "        all_files = os.listdir(results_folder)\n",
    "        print(f\"Found {len(all_files)} files in the results folder\")\n",
    "        \n",
    "        # Find missing samples\n",
    "        missing_samples = []\n",
    "        for sample_id in all_sample_ids:\n",
    "            if not check_sample_files(sample_id, results_folder):\n",
    "                missing_samples.append(sample_id)\n",
    "        \n",
    "        # Report results\n",
    "        if missing_samples:\n",
    "            print(f\"\\nFound {len(missing_samples)} missing sample IDs:\")\n",
    "            for sample_id in missing_samples:\n",
    "                print(f\"- {sample_id}\")\n",
    "                \n",
    "            # Save missing sample IDs to file\n",
    "            output_file = \"missing_samples.txt\"\n",
    "            with open(output_file, 'w') as f:\n",
    "                for sample_id in missing_samples:\n",
    "                    f.write(f\"{sample_id}\\n\")\n",
    "            print(f\"\\nMissing sample IDs saved to {output_file}\")\n",
    "        else:\n",
    "            print(\"\\nAll sample IDs from the CSV file have corresponding files in the folder.\")\n",
    "            \n",
    "        # Additional useful information\n",
    "        present_count = len(all_sample_ids) - len(missing_samples)\n",
    "        print(f\"\\nSummary:\")\n",
    "        print(f\"- Total unique sample IDs in CSV: {len(all_sample_ids)}\")\n",
    "        print(f\"- Sample IDs with files present: {present_count} ({present_count/len(all_sample_ids)*100:.1f}%)\")\n",
    "        print(f\"- Sample IDs missing files: {len(missing_samples)} ({len(missing_samples)/len(all_sample_ids)*100:.1f}%)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Run the function\n",
    "if __name__ == \"__main__\":\n",
    "    find_missing_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba657f63-e5a4-4049-aa45-5634620c8918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the paths to the two folders\n",
    "folder1 = \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/Lukas_Target_incomplete\"\n",
    "folder2 = \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/Lukas_aug_3_try_finishes\"\n",
    "\n",
    "def get_sample_ids(folder_path):\n",
    "    \"\"\"Extract sample IDs from JSON files in the given folder.\"\"\"\n",
    "    sample_ids = set()\n",
    "    \n",
    "    # Check if the folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Error: Folder {folder_path} does not exist.\")\n",
    "        return sample_ids\n",
    "    \n",
    "    # Get all JSON files in the folder\n",
    "    json_files = [f for f in os.listdir(folder_path) if f.endswith('.json')]\n",
    "    \n",
    "    for filename in json_files:\n",
    "        # Extract sample ID (part before the first underscore)\n",
    "        parts = filename.split('_', 1)\n",
    "        if len(parts) > 1:\n",
    "            sample_id = parts[0]\n",
    "            sample_ids.add(sample_id)\n",
    "    \n",
    "    return sample_ids\n",
    "\n",
    "# Get sample IDs from both folders\n",
    "folder1_ids = get_sample_ids(folder1)\n",
    "folder2_ids = get_sample_ids(folder2)\n",
    "\n",
    "# Print the number of sample IDs in each folder\n",
    "print(f\"Folder 1 (Lukas_Target_incomplete) has {len(folder1_ids)} sample IDs\")\n",
    "print(f\"Folder 2 (Lukas_aug_3_try_finishes) has {len(folder2_ids)} sample IDs\")\n",
    "\n",
    "# Check for mismatches\n",
    "if folder1_ids == folder2_ids:\n",
    "    print(\"Both folders have the same sample IDs.\")\n",
    "else:\n",
    "    print(\"\\nMismatches found:\")\n",
    "    \n",
    "    # Find sample IDs in folder1 but not in folder2\n",
    "    missing_in_folder2 = folder1_ids - folder2_ids\n",
    "    if missing_in_folder2:\n",
    "        print(f\"\\nSample IDs in Folder 1 but missing in Folder 2 ({len(missing_in_folder2)}):\")\n",
    "        for sample_id in sorted(missing_in_folder2):\n",
    "            print(f\"  - {sample_id}\")\n",
    "    \n",
    "    # Find sample IDs in folder2 but not in folder1\n",
    "    missing_in_folder1 = folder2_ids - folder1_ids\n",
    "    if missing_in_folder1:\n",
    "        print(f\"\\nSample IDs in Folder 2 but missing in Folder 1 ({len(missing_in_folder1)}):\")\n",
    "        for sample_id in sorted(missing_in_folder1):\n",
    "            print(f\"  - {sample_id}\")\n",
    "\n",
    "# Print a brief summary\n",
    "if len(folder1_ids) > len(folder2_ids):\n",
    "    print(f\"\\nFolder 1 has {len(folder1_ids) - len(folder2_ids)} more sample IDs than Folder 2\")\n",
    "elif len(folder2_ids) > len(folder1_ids):\n",
    "    print(f\"\\nFolder 2 has {len(folder2_ids) - len(folder1_ids)} more sample IDs than Folder 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f39d67e-3e03-4727-a1eb-9bfab457f940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2df22f-a260-400b-8a9e-505b4ba44598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c621e031-6159-40de-a272-c1e9f5cbcc36",
   "metadata": {},
   "source": [
    "# Analysis Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8faa02-4a6a-4724-a8a4-218ec3b2fe4e",
   "metadata": {},
   "source": [
    "## Look all molecules and sort them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8526f6-8d59-4260-8db3-9b7805487373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "def process_single_json(json_data: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Process a single JSON file's candidate analysis and combine all molecules.\n",
    "    \n",
    "    Args:\n",
    "        json_data: Dictionary containing the JSON data with molecule_data\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries containing combined and processed molecule data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        candidate_analysis = json_data[\"molecule_data\"]['candidate_analysis']\n",
    "    except KeyError as e:\n",
    "        raise KeyError(f\"Missing required key in JSON structure: {e}\")\n",
    "    \n",
    "    all_molecules = []\n",
    "    \n",
    "    # Analysis types to process\n",
    "    analysis_types = ['forward_synthesis', 'mol2mol', 'mmst']\n",
    "    \n",
    "    # Extract molecules from each analysis type\n",
    "    for analysis_type in analysis_types:\n",
    "        if analysis_type in candidate_analysis:\n",
    "            molecules = candidate_analysis[analysis_type].get('molecules', [])\n",
    "            for mol in molecules:\n",
    "                try:\n",
    "                    # Create processed molecule entry with safe access using .get()\n",
    "                    processed_mol = {\n",
    "                        'smiles': mol['smiles'],  # Required field\n",
    "                        'analysis_type': analysis_type,\n",
    "                        'hsqc_score': mol.get('nmr_analysis', {}).get('matching_scores', {}).get('by_spectrum', {}).get('HSQC', None),\n",
    "                        'overall_score': mol.get('nmr_analysis', {}).get('matching_scores', {}).get('overall', None),\n",
    "                        'h_nmr_score': mol.get('nmr_analysis', {}).get('matching_scores', {}).get('by_spectrum', {}).get('1H', None),\n",
    "                        'c_nmr_score': mol.get('nmr_analysis', {}).get('matching_scores', {}).get('by_spectrum', {}).get('13C', None),\n",
    "                        'cosy_score': mol.get('nmr_analysis', {}).get('matching_scores', {}).get('by_spectrum', {}).get('COSY', None)\n",
    "                    }\n",
    "                    \n",
    "                    # Add generation info if available\n",
    "                    gen_info = mol.get('generation_info', {})\n",
    "                    processed_mol.update({\n",
    "                        'source': gen_info.get('source', ''),\n",
    "                        'parent_smiles': gen_info.get('parent_smiles', ''),\n",
    "                        'starting_material': gen_info.get('starting_material', ''),\n",
    "                        'log_likelihood': gen_info.get('log_likelihood', None)\n",
    "                    })\n",
    "                    \n",
    "                    all_molecules.append(processed_mol)\n",
    "                except KeyError as e:\n",
    "                    print(f\"Warning: Skipping molecule due to missing required field: {e}\")\n",
    "                    continue\n",
    "    \n",
    "    # Sort by HSQC score in ascending order (low to high), handling None values\n",
    "    all_molecules.sort(key=lambda x: x['hsqc_score'] if x['hsqc_score'] is not None else float('inf'))\n",
    "    \n",
    "    return all_molecules\n",
    "\n",
    "def analyze_json_file(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analyze a single JSON file and return results as a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the JSON file\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame containing processed molecule data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read and parse JSON file\n",
    "        with open(file_path, 'r') as f:\n",
    "            json_data = json.load(f)\n",
    "        \n",
    "        # Get true molecule data\n",
    "        molecule_data = json_data.get('molecule_data', {})\n",
    "        true_smiles = molecule_data.get('smiles')\n",
    "        sample_id = molecule_data.get('sample_id')\n",
    "        \n",
    "        if not true_smiles or not sample_id:\n",
    "            raise ValueError(\"Missing required molecule_data fields (smiles or sample_id)\")\n",
    "        \n",
    "        # Process molecules\n",
    "        molecules = process_single_json(json_data)\n",
    "        \n",
    "        if not molecules:\n",
    "            print(f\"Warning: No valid molecules found in {file_path}\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(molecules)\n",
    "        \n",
    "        # Add reference information\n",
    "        df['true_smiles'] = true_smiles\n",
    "        df['sample_id'] = sample_id\n",
    "        \n",
    "        # Add match indicator\n",
    "        df['is_match'] = df['smiles'] == true_smiles\n",
    "        \n",
    "        # Reorder columns\n",
    "        column_order = [\n",
    "            'sample_id', 'true_smiles', 'smiles', 'is_match',\n",
    "            'analysis_type', 'hsqc_score', 'overall_score',\n",
    "            'h_nmr_score', 'c_nmr_score', 'cosy_score',\n",
    "            'source', 'parent_smiles', 'starting_material', 'log_likelihood'\n",
    "        ]\n",
    "        df = df[column_order]\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {str(e)}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83105666-f58f-43eb-8da9-e09d6d3e50b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage for a single file\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your JSON file path\n",
    "    file_path = \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_6.0_exp_d1_aug_finished/AZ10421813_exp_d1_aug_intermediate.json\"\n",
    "    \n",
    "    try:\n",
    "        # Process single file\n",
    "        results_df = analyze_json_file(file_path)\n",
    "        \n",
    "        # Display summary\n",
    "        print(\"\\nAnalysis Summary:\")\n",
    "        print(f\"Total candidates: {len(results_df)}\")\n",
    "        print(f\"\\nTop 5 candidates by HSQC score:\")\n",
    "        print(results_df[['smiles', 'analysis_type', 'hsqc_score', 'overall_score', 'is_match']].head(10))\n",
    "        \n",
    "        # Check if correct structure is in top candidates\n",
    "        if results_df['is_match'].any():\n",
    "            match_rank = results_df['is_match'].argmax() + 1\n",
    "            print(f\"\\nTrue structure found at rank {match_rank}\")\n",
    "        else:\n",
    "            print(\"\\nTrue structure not found in candidates\")\n",
    "        \n",
    "        # Save results\n",
    "        output_file = Path(file_path).stem + \"_analysis.csv\"\n",
    "        results_df.to_csv(output_file, index=False)\n",
    "        print(f\"\\nDetailed results saved to: {output_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dc6c67-73a9-483b-abf2-b90731625ab6",
   "metadata": {},
   "source": [
    "## Check which position the target molecule got for correct and incorrect starting guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea130b40-6bed-4376-a86d-d1ffd50461ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any\n",
    "from collections import defaultdict\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def load_reference_data(csv_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load reference data from CSV file containing correct SMILES for each sample ID.\n",
    "    \n",
    "    Args:\n",
    "        csv_path: Path to CSV file with columns 'sample_id' and 'smiles'\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with reference data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ref_df = pd.read_csv(csv_path)\n",
    "        required_columns = ['sample-id', 'SMILES']\n",
    "        \n",
    "        if not all(col in ref_df.columns for col in required_columns):\n",
    "            raise ValueError(f\"Reference CSV must contain columns: {required_columns}\")\n",
    "            \n",
    "        # Create a dictionary for faster lookups, converting column names to match JSON\n",
    "        return ref_df.set_index('sample-id')['SMILES'].to_dict()\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error loading reference data: {str(e)}\")\n",
    "\n",
    "def process_single_json(json_data: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Process a single JSON file's candidate analysis and combine all molecules.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        candidate_analysis = json_data[\"molecule_data\"]['candidate_analysis']\n",
    "    except KeyError as e:\n",
    "        raise KeyError(f\"Missing required key in JSON structure: {e}\")\n",
    "    \n",
    "    all_molecules = []\n",
    "    analysis_types = ['forward_synthesis', 'mol2mol', 'mmst']\n",
    "    \n",
    "    for analysis_type in analysis_types:\n",
    "        if analysis_type in candidate_analysis:\n",
    "            molecules = candidate_analysis[analysis_type].get('molecules', [])\n",
    "            for mol in molecules:\n",
    "                try:\n",
    "                    processed_mol = {\n",
    "                        'smiles': mol['smiles'],\n",
    "                        'analysis_type': analysis_type,\n",
    "                        'hsqc_score': mol.get('nmr_analysis', {}).get('matching_scores', {}).get('by_spectrum', {}).get('HSQC', None),\n",
    "                        'overall_score': mol.get('nmr_analysis', {}).get('matching_scores', {}).get('overall', None),\n",
    "                        'h_nmr_score': mol.get('nmr_analysis', {}).get('matching_scores', {}).get('by_spectrum', {}).get('1H', None),\n",
    "                        'c_nmr_score': mol.get('nmr_analysis', {}).get('matching_scores', {}).get('by_spectrum', {}).get('13C', None),\n",
    "                        'cosy_score': mol.get('nmr_analysis', {}).get('matching_scores', {}).get('by_spectrum', {}).get('COSY', None)\n",
    "                    }\n",
    "                    \n",
    "                    gen_info = mol.get('generation_info', {})\n",
    "                    processed_mol.update({\n",
    "                        'source': gen_info.get('source', ''),\n",
    "                        'parent_smiles': gen_info.get('parent_smiles', ''),\n",
    "                        'starting_material': gen_info.get('starting_material', ''),\n",
    "                        'log_likelihood': gen_info.get('log_likelihood', None)\n",
    "                    })\n",
    "                    \n",
    "                    all_molecules.append(processed_mol)\n",
    "                except KeyError as e:\n",
    "                    print(f\"Warning: Skipping molecule due to missing required field: {e}\")\n",
    "                    continue\n",
    "    \n",
    "    # Sort by HSQC score in ascending order (low to high), handling None values\n",
    "    all_molecules.sort(key=lambda x: x['hsqc_score'] if x['hsqc_score'] is not None else float('inf'))\n",
    "    \n",
    "    return all_molecules\n",
    "\n",
    "def get_base_sample_id(sample_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract the base sample ID (part before the underscore).\n",
    "    \"\"\"\n",
    "    return sample_id.split('_')[0] if sample_id else ''\n",
    "\n",
    "def analyze_json_file(file_path: str, reference_data: Dict[str, str]) -> tuple[pd.DataFrame, dict]:\n",
    "    \"\"\"\n",
    "    Analyze a single JSON file and return results as a DataFrame and stats dictionary.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            json_data = json.load(f)\n",
    "        \n",
    "        molecule_data = json_data.get('molecule_data', {})\n",
    "        sample_id = molecule_data.get('sample_id')\n",
    "        \n",
    "        if not sample_id:\n",
    "            raise ValueError(\"Missing required sample_id in JSON file\")\n",
    "        \n",
    "        # Get base sample ID for matching with reference data\n",
    "        base_sample_id = get_base_sample_id(sample_id)\n",
    "        \n",
    "        # Get correct SMILES from reference data\n",
    "        true_smiles = reference_data.get(base_sample_id)\n",
    "        if true_smiles is None:\n",
    "            print(f\"Warning: No reference SMILES found for sample_id {base_sample_id} (original: {sample_id})\")\n",
    "            return pd.DataFrame(), {}\n",
    "        \n",
    "        molecules = process_single_json(json_data)\n",
    "        \n",
    "        if not molecules:\n",
    "            print(f\"Warning: No valid molecules found in {file_path}\")\n",
    "            return pd.DataFrame(), {}\n",
    "        \n",
    "        df = pd.DataFrame(molecules)\n",
    "        \n",
    "        # Add reference information\n",
    "        df['true_smiles'] = true_smiles\n",
    "        df['sample_id'] = sample_id\n",
    "        df['target_smiles'] = molecule_data.get('smiles', '')  # Original target from JSON\n",
    "        df['is_match'] = df['smiles'] == true_smiles\n",
    "        \n",
    "        # Calculate ranking statistics\n",
    "        stats = {\n",
    "            'sample_id': sample_id,\n",
    "            'total_candidates': len(df),\n",
    "            'match_found': df['is_match'].any(),\n",
    "            'match_rank': df['is_match'].argmax() + 1 if df['is_match'].any() else None,\n",
    "            'in_top_5': df.iloc[:5]['is_match'].any(),\n",
    "            'hsqc_score_of_true': df[df['is_match']]['hsqc_score'].iloc[0] if df['is_match'].any() else None,\n",
    "            'target_smiles': df['target_smiles'].iloc[0],\n",
    "            'true_smiles': true_smiles\n",
    "        }\n",
    "        \n",
    "        return df, stats\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {str(e)}\")\n",
    "        return pd.DataFrame(), {}\n",
    "\n",
    "def analyze_directory(directory_path: str, reference_csv: str) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Analyze all JSON files in a directory using reference data from CSV.\n",
    "    \"\"\"\n",
    "    # Load reference data\n",
    "    print(f\"Loading reference data from: {reference_csv}\")\n",
    "    reference_data = load_reference_data(reference_csv)\n",
    "    \n",
    "    # Get all JSON files in the directory\n",
    "    json_files = glob.glob(os.path.join(directory_path, \"*.json\"))\n",
    "    print(f\"Found {len(json_files)} JSON files to analyze\")\n",
    "    \n",
    "    all_results = []\n",
    "    all_stats = []\n",
    "    \n",
    "    for file_path in json_files:\n",
    "        df, stats = analyze_json_file(file_path, reference_data)\n",
    "        if not df.empty:\n",
    "            all_results.append(df)\n",
    "            all_stats.append(stats)\n",
    "    \n",
    "    # Combine all results\n",
    "    combined_results = pd.concat(all_results, ignore_index=True) if all_results else pd.DataFrame()\n",
    "    stats_df = pd.DataFrame(all_stats) if all_stats else pd.DataFrame()\n",
    "    \n",
    "    return combined_results, stats_df\n",
    "\n",
    "def generate_ranking_statistics(stats_df: pd.DataFrame) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Generate summary statistics from the analysis results.\n",
    "    \"\"\"\n",
    "    if stats_df.empty:\n",
    "        return {\n",
    "            'total_analyzed': 0,\n",
    "            'found_in_top_5': 0,\n",
    "            'found_in_top_5_percent': 0,\n",
    "            'total_found': 0,\n",
    "            'total_found_percent': 0,\n",
    "            'rank_distribution': {}\n",
    "        }\n",
    "    \n",
    "    total_files = len(stats_df)\n",
    "    \n",
    "    stats = {\n",
    "        'total_analyzed': total_files,\n",
    "        'found_in_top_5': stats_df['in_top_5'].sum(),\n",
    "        'found_in_top_5_percent': (stats_df['in_top_5'].sum() / total_files) * 100,\n",
    "        'total_found': stats_df['match_found'].sum(),\n",
    "        'total_found_percent': (stats_df['match_found'].sum() / total_files) * 100,\n",
    "    }\n",
    "    \n",
    "    # Calculate rank distribution for found molecules\n",
    "    found_ranks = stats_df[stats_df['match_found']]['match_rank']\n",
    "    if not found_ranks.empty:\n",
    "        stats.update({\n",
    "            'rank_min': found_ranks.min(),\n",
    "            'rank_max': found_ranks.max(),\n",
    "            'rank_mean': found_ranks.mean(),\n",
    "            'rank_median': found_ranks.median(),\n",
    "            'rank_std': found_ranks.std()\n",
    "        })\n",
    "        \n",
    "        # Calculate rank distribution\n",
    "        rank_bins = [0, 1, 5, 10, 20, 50, float('inf')]\n",
    "        rank_labels = ['1st', '2-5', '6-10', '11-20', '21-50', '50+']\n",
    "        rank_dist = pd.cut(found_ranks, bins=rank_bins, labels=rank_labels, right=False).value_counts()\n",
    "        stats['rank_distribution'] = rank_dist.to_dict()\n",
    "    \n",
    "    return stats\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace these paths with your actual paths\n",
    "    json_directory = \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_6.0_exp_d1_aug_finished\"\n",
    "    reference_csv = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "    \n",
    "    print(f\"Starting analysis...\")\n",
    "    print(f\"JSON directory: {json_directory}\")\n",
    "    print(f\"Reference CSV: {reference_csv}\")\n",
    "    \n",
    "    # Analyze all files\n",
    "    combined_results, stats_df = analyze_directory(json_directory, reference_csv)\n",
    "    \n",
    "    if combined_results.empty:\n",
    "        print(\"No results were generated. Please check your input files and paths.\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Generate statistics\n",
    "    summary_stats = generate_ranking_statistics(stats_df)\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\nAnalysis Summary:\")\n",
    "    print(f\"Total files analyzed: {summary_stats['total_analyzed']}\")\n",
    "    print(f\"Molecules found in top 5: {summary_stats['found_in_top_5']} ({summary_stats['found_in_top_5_percent']:.1f}%)\")\n",
    "    print(f\"Total molecules found: {summary_stats['total_found']} ({summary_stats['total_found_percent']:.1f}%)\")\n",
    "    \n",
    "    if summary_stats['total_found'] > 0:\n",
    "        print(\"\\nRank Statistics for Found Molecules:\")\n",
    "        print(f\"Min rank: {summary_stats['rank_min']}\")\n",
    "        print(f\"Max rank: {summary_stats['rank_max']}\")\n",
    "        print(f\"Mean rank: {summary_stats['rank_mean']:.1f}\")\n",
    "        print(f\"Median rank: {summary_stats['rank_median']}\")\n",
    "        \n",
    "        print(\"\\nRank Distribution:\")\n",
    "        for rank_range, count in summary_stats['rank_distribution'].items():\n",
    "            print(f\"{rank_range}: {count}\")\n",
    "    \n",
    "    # Save detailed results\n",
    "    output_dir = Path(json_directory) / \"analysis_results\"\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Save combined results\n",
    "    combined_results.to_csv(output_dir / \"all_molecules.csv\", index=False)\n",
    "    \n",
    "    # Save statistics\n",
    "    stats_df.to_csv(output_dir / \"file_statistics.csv\", index=False)\n",
    "    \n",
    "    # Save summary statistics\n",
    "    pd.DataFrame([summary_stats]).to_csv(output_dir / \"summary_statistics.csv\", index=False)\n",
    "    \n",
    "    print(f\"\\nDetailed results saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be90f061-d16d-48a6-9638-be80ffb61cf2",
   "metadata": {},
   "source": [
    "## Plot histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbc5e77-49dd-4e1f-b439-09790397769e",
   "metadata": {},
   "source": [
    "### V1 - OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed4f4e6-59e1-4a15-b6ca-554fd3cfd7e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def load_reference_data(csv_path):\n",
    "    \"\"\"Load reference SMILES from CSV file.\"\"\"\n",
    "    ref_df = pd.read_csv(csv_path)\n",
    "    # Convert to dictionary for faster lookups\n",
    "    return ref_df.set_index('sample-id')['SMILES'].to_dict()\n",
    "\n",
    "def get_base_sample_id(sample_id):\n",
    "    \"\"\"Extract base sample ID (part before underscore).\"\"\"\n",
    "    return sample_id.split('_')[0] if sample_id else ''\n",
    "\n",
    "def process_single_json(json_data):\n",
    "    \"\"\"Process a single JSON file and return sorted molecules.\"\"\"\n",
    "    try:\n",
    "        candidate_analysis = json_data[\"molecule_data\"]['candidate_analysis']\n",
    "    except KeyError:\n",
    "        return []\n",
    "    \n",
    "    all_molecules = []\n",
    "    analysis_types = ['forward_synthesis', 'mol2mol', 'mmst']\n",
    "    \n",
    "    for analysis_type in analysis_types:\n",
    "        if analysis_type in candidate_analysis:\n",
    "            molecules = candidate_analysis[analysis_type].get('molecules', [])\n",
    "            for mol in molecules:\n",
    "                try:\n",
    "                    processed_mol = {\n",
    "                        'smiles': mol['smiles'],\n",
    "                        'hsqc_score': mol.get('nmr_analysis', {}).get('matching_scores', {}).get('by_spectrum', {}).get('HSQC', None)\n",
    "                    }\n",
    "                    all_molecules.append(processed_mol)\n",
    "                except KeyError:\n",
    "                    continue\n",
    "    \n",
    "    # Sort by HSQC score\n",
    "    all_molecules.sort(key=lambda x: x['hsqc_score'] if x['hsqc_score'] is not None else float('inf'))\n",
    "    return all_molecules\n",
    "\n",
    "def find_molecule_rank(molecules, true_smiles):\n",
    "    \"\"\"Find the rank of the correct molecule.\"\"\"\n",
    "    for idx, mol in enumerate(molecules, 1):\n",
    "        if mol['smiles'] == true_smiles:\n",
    "            return idx\n",
    "    return None\n",
    "\n",
    "def analyze_directory(json_dir, reference_csv):\n",
    "    \"\"\"Analyze all JSON files and return list of rankings.\"\"\"\n",
    "    # Load reference data\n",
    "    reference_data = load_reference_data(reference_csv)\n",
    "    \n",
    "    # Get all JSON files\n",
    "    json_files = glob.glob(os.path.join(json_dir, \"*.json\"))\n",
    "    print(f\"Found {len(json_files)} JSON files to analyze\")\n",
    "    \n",
    "    rankings = []\n",
    "    \n",
    "    for file_path in json_files:\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                json_data = json.load(f)\n",
    "            \n",
    "            molecule_data = json_data.get('molecule_data', {})\n",
    "            sample_id = molecule_data.get('sample_id')\n",
    "            \n",
    "            if not sample_id:\n",
    "                continue\n",
    "                \n",
    "            # Get base sample ID for reference matching\n",
    "            base_sample_id = get_base_sample_id(sample_id)\n",
    "            \n",
    "            # Get correct SMILES\n",
    "            true_smiles = reference_data.get(base_sample_id)\n",
    "            if true_smiles is None:\n",
    "                print(f\"No reference SMILES found for {base_sample_id}\")\n",
    "                continue\n",
    "            \n",
    "            # Process molecules and find rank\n",
    "            molecules = process_single_json(json_data)\n",
    "            if not molecules:\n",
    "                continue\n",
    "                \n",
    "            rank = find_molecule_rank(molecules, true_smiles)\n",
    "            if rank is not None:\n",
    "                rankings.append(rank)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return rankings\n",
    "\n",
    "def plot_ranking_histogram(rankings, experiment_label=\"\", max_rank=10, figsize=(12, 6)):\n",
    "    \"\"\"\n",
    "    Create histogram of molecule rankings.\n",
    "    \n",
    "    Args:\n",
    "        rankings: List of rankings for correct molecules\n",
    "        experiment_label: Label for the experiment to be shown in title\n",
    "        max_rank: Maximum rank to show in histogram (default: 10)\n",
    "        figsize: Size of the figure (default: (12, 6))\n",
    "    \"\"\"\n",
    "    # Create bins for the histogram\n",
    "    bins = np.arange(1, max_rank + 2) - 0.5\n",
    "    \n",
    "    # Create figure with white background\n",
    "    fig, ax = plt.subplots(figsize=figsize, facecolor='white')\n",
    "    ax.set_facecolor('white')\n",
    "    \n",
    "    # Plot histogram\n",
    "    n, bins, patches = ax.hist(\n",
    "        [r for r in rankings if r <= max_rank],\n",
    "        bins=bins,\n",
    "        edgecolor='black',\n",
    "        alpha=0.7,\n",
    "        color='#4169E1'  # Royal Blue\n",
    "    )\n",
    "    \n",
    "    # Customize the plot\n",
    "    title = 'Distribution of Correct Molecule Rankings'\n",
    "    if experiment_label:\n",
    "        title += f' - {experiment_label}'\n",
    "    ax.set_title(title, fontsize=14, pad=20)\n",
    "    ax.set_xlabel('Rank', fontsize=12)\n",
    "    ax.set_ylabel('Number of Molecules', fontsize=12)\n",
    "    \n",
    "    # Set x-axis ticks\n",
    "    ax.set_xticks(range(1, max_rank + 1))\n",
    "    \n",
    "    # Add grid with light gray color\n",
    "    ax.grid(True, alpha=0.3, color='gray', linestyle='--')\n",
    "    \n",
    "    # Add counts above bars\n",
    "    for i, count in enumerate(n):\n",
    "        if count > 0:\n",
    "            ax.text(i + 1, count, f'{int(count)}', \n",
    "                   ha='center', va='bottom')\n",
    "    \n",
    "    # Calculate statistics\n",
    "    total_molecules = len(rankings)\n",
    "    in_top_5 = sum(1 for r in rankings if r <= 5)\n",
    "    in_top_10 = sum(1 for r in rankings if r <= 10)\n",
    "    \n",
    "    stats_text = (\n",
    "        f'Total molecules found: {total_molecules}\\n'\n",
    "        f'Found in top 5: {in_top_5} ({in_top_5/total_molecules*100:.1f}%)\\n'\n",
    "        f'Found in top 10: {in_top_10} ({in_top_10/total_molecules*100:.1f}%)'\n",
    "    )\n",
    "    \n",
    "    # Add statistics text box\n",
    "    ax.text(0.95, 0.95, stats_text,\n",
    "            transform=ax.transAxes,\n",
    "            verticalalignment='top',\n",
    "            horizontalalignment='right',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Print detailed distribution\n",
    "    print(f\"\\nDetailed rank distribution for {experiment_label if experiment_label else 'experiment'}:\")\n",
    "    rank_counts = pd.Series(rankings).value_counts().sort_index()\n",
    "    for rank, count in rank_counts.items():\n",
    "        print(f\"Rank {rank}: {count} molecules\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def main():\n",
    "    # Example usage with different experiments\n",
    "    experiments = {\n",
    "        \"Simulated Data\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_1_sim_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Simulated Data with Wrong Guess\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_2_sim_aug_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Simulated Data with Noise\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_3_sim+noise_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Experimental Data\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_4_exp_d1_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Experimental Data with Wrong Guess\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_5_exp_d1_aug_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Experimental Data d4\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_6_exp_d4_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for exp_label, paths in experiments.items():\n",
    "        print(f\"\\nAnalyzing {exp_label}...\")\n",
    "        \n",
    "        # Get rankings\n",
    "        rankings = analyze_directory(paths[\"json_directory\"], paths[\"reference_csv\"])\n",
    "        \n",
    "        if not rankings:\n",
    "            print(f\"No valid rankings found for {exp_label}. Please check your input files.\")\n",
    "            continue\n",
    "        \n",
    "        # Create and show plot\n",
    "        fig = plot_ranking_histogram(rankings, experiment_label=exp_label)\n",
    "        plt.show()\n",
    "        \n",
    "        # Optionally save the plot\n",
    "        # fig.savefig(f'ranking_histogram_{exp_label}.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cf49ee-0419-43f3-8694-a2ea1f596436",
   "metadata": {},
   "source": [
    "### V1.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d662dbb5-a560-4f99-9675-35ba494ccbe3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def load_reference_data(csv_path):\n",
    "    \"\"\"Load reference SMILES from CSV file.\"\"\"\n",
    "    ref_df = pd.read_csv(csv_path)\n",
    "    # Convert to dictionary for faster lookups\n",
    "    return ref_df.set_index('sample-id')['SMILES'].to_dict()\n",
    "\n",
    "def get_base_sample_id(sample_id):\n",
    "    \"\"\"Extract base sample ID (part before underscore).\"\"\"\n",
    "    return sample_id.split('_')[0] if sample_id else ''\n",
    "\n",
    "def process_single_json(json_data):\n",
    "    \"\"\"Process a single JSON file and return sorted molecules.\"\"\"\n",
    "    try:\n",
    "        candidate_analysis = json_data[\"molecule_data\"]['candidate_analysis']\n",
    "    except KeyError:\n",
    "        return []\n",
    "    \n",
    "    all_molecules = []\n",
    "    analysis_types = ['forward_synthesis', 'mol2mol', 'mmst']\n",
    "    \n",
    "    for analysis_type in analysis_types:\n",
    "        if analysis_type in candidate_analysis:\n",
    "            molecules = candidate_analysis[analysis_type].get('molecules', [])\n",
    "            for mol in molecules:\n",
    "                try:\n",
    "                    processed_mol = {\n",
    "                        'smiles': mol['smiles'],\n",
    "                        'hsqc_score': mol.get('nmr_analysis', {}).get('matching_scores', {}).get('by_spectrum', {}).get('HSQC', None)\n",
    "                    }\n",
    "                    all_molecules.append(processed_mol)\n",
    "                except KeyError:\n",
    "                    continue\n",
    "    \n",
    "    # Sort by HSQC score\n",
    "    all_molecules.sort(key=lambda x: x['hsqc_score'] if x['hsqc_score'] is not None else float('inf'))\n",
    "    return all_molecules\n",
    "\n",
    "def find_molecule_rank(molecules, true_smiles):\n",
    "    \"\"\"Find the rank of the correct molecule.\"\"\"\n",
    "    for idx, mol in enumerate(molecules, 1):\n",
    "        if mol['smiles'] == true_smiles:\n",
    "            return idx\n",
    "    return None\n",
    "\n",
    "def analyze_directory(json_dir, reference_csv):\n",
    "    \"\"\"Analyze all JSON files and return list of rankings.\"\"\"\n",
    "    # Load reference data\n",
    "    reference_data = load_reference_data(reference_csv)\n",
    "    \n",
    "    # Get all JSON files\n",
    "    json_files = glob.glob(os.path.join(json_dir, \"*.json\"))\n",
    "    print(f\"Found {len(json_files)} JSON files to analyze\")\n",
    "    \n",
    "    rankings = []\n",
    "    \n",
    "    for file_path in json_files:\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                json_data = json.load(f)\n",
    "            \n",
    "            molecule_data = json_data.get('molecule_data', {})\n",
    "            sample_id = molecule_data.get('sample_id')\n",
    "            \n",
    "            if not sample_id:\n",
    "                continue\n",
    "                \n",
    "            # Get base sample ID for reference matching\n",
    "            base_sample_id = get_base_sample_id(sample_id)\n",
    "            \n",
    "            # Get correct SMILES\n",
    "            true_smiles = reference_data.get(base_sample_id)\n",
    "            if true_smiles is None:\n",
    "                print(f\"No reference SMILES found for {base_sample_id}\")\n",
    "                continue\n",
    "            \n",
    "            # Process molecules and find rank\n",
    "            molecules = process_single_json(json_data)\n",
    "            if not molecules:\n",
    "                continue\n",
    "                \n",
    "            rank = find_molecule_rank(molecules, true_smiles)\n",
    "            if rank is not None:\n",
    "                rankings.append(rank)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return rankings\n",
    "\n",
    "def plot_ranking_histogram(rankings, experiment_label=\"\", max_rank=5, color=\"#4169E1\", figsize=(5.5, 5.5)):\n",
    "    \"\"\"\n",
    "    Create histogram of molecule rankings with an extra bin for ranks beyond max_rank.\n",
    "    \n",
    "    Args:\n",
    "        rankings: List of rankings for correct molecules\n",
    "        experiment_label: Label for the experiment to be shown in title\n",
    "        max_rank: Maximum individual rank to show in histogram (default: 5)\n",
    "        color: Color for histogram bars\n",
    "        figsize: Size of the figure (default: (5.5, 5.5) for square plot)\n",
    "    \"\"\"\n",
    "    # Create figure with white background\n",
    "    fig, ax = plt.subplots(figsize=figsize, facecolor='white')\n",
    "    ax.set_facecolor('white')\n",
    "    \n",
    "    # Prepare data for histogram\n",
    "    rank_counts = {}\n",
    "    \n",
    "    # Count ranks 1-5 individually\n",
    "    for r in range(1, max_rank + 1):\n",
    "        rank_counts[r] = sum(1 for rank in rankings if rank == r)\n",
    "    \n",
    "    # Count all ranks > max_rank together\n",
    "    rank_counts['6+'] = sum(1 for rank in rankings if rank > max_rank)\n",
    "    \n",
    "    # Plot the histogram\n",
    "    positions = list(range(1, max_rank + 1)) + [max_rank + 1]\n",
    "    counts = [rank_counts[r] if r <= max_rank else rank_counts['6+'] for r in positions]\n",
    "    \n",
    "    bars = ax.bar(\n",
    "        positions,\n",
    "        counts,\n",
    "        width=0.8,\n",
    "        edgecolor='black',\n",
    "        alpha=0.7,\n",
    "        color=color\n",
    "    )\n",
    "    \n",
    "    # Create two-line title with increased font size (20)\n",
    "    title_line1 = 'Distribution of Correct Molecule Rankings'\n",
    "    title_line2 = experiment_label if experiment_label else \"\"\n",
    "    \n",
    "    ax.set_title(f\"{title_line1}\\n{title_line2}\", fontsize=20, pad=10)\n",
    "    ax.set_xlabel('Rank', fontsize=16)\n",
    "    ax.set_ylabel('Number of Molecules', fontsize=16)\n",
    "    \n",
    "    # Set x-axis ticks and labels with increased font size (14)\n",
    "    ax.set_xticks(positions)\n",
    "    x_labels = [str(i) for i in range(1, max_rank + 1)] + ['6+']\n",
    "    ax.set_xticklabels(x_labels, fontsize=14)\n",
    "    ax.tick_params(axis='y', labelsize=14)\n",
    "    \n",
    "    # Add grid with light gray color\n",
    "    ax.grid(True, alpha=0.3, color='gray', linestyle='--', axis='y')\n",
    "    \n",
    "    # Add counts above bars with increased font size (14)\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            ax.text(\n",
    "                bar.get_x() + bar.get_width()/2, \n",
    "                height + 0.1, \n",
    "                f'{int(height)}',\n",
    "                ha='center', \n",
    "                va='bottom',\n",
    "                fontsize=14\n",
    "            )\n",
    "    \n",
    "    # Calculate statistics\n",
    "    total_molecules = len(rankings)\n",
    "    in_top_1 = sum(1 for r in rankings if r == 1)\n",
    "    in_top_3 = sum(1 for r in rankings if r <= 3)\n",
    "    in_top_5 = sum(1 for r in rankings if r <= 5)\n",
    "    after_top_5 = sum(1 for r in rankings if r > 5)\n",
    "    \n",
    "    stats_text = (\n",
    "        f'Total molecules found: {total_molecules}\\n'\n",
    "        f'Found in top 1: {in_top_1} ({in_top_1/total_molecules*100:.1f}%)\\n'\n",
    "        f'Found in top 3: {in_top_3} ({in_top_3/total_molecules*100:.1f}%)\\n'\n",
    "        f'Found in top 5: {in_top_5} ({in_top_5/total_molecules*100:.1f}%)\\n'\n",
    "        f'Found after top 5: {after_top_5} ({after_top_5/total_molecules*100:.1f}%)'\n",
    "    )\n",
    "    \n",
    "    # Add statistics text box with increased font size (14)\n",
    "    ax.text(0.95, 0.95, stats_text,\n",
    "            transform=ax.transAxes,\n",
    "            verticalalignment='top',\n",
    "            horizontalalignment='right',\n",
    "            fontsize=14,\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Print detailed distribution\n",
    "    print(f\"\\nDetailed rank distribution for {experiment_label if experiment_label else 'experiment'}:\")\n",
    "    rank_counts_series = pd.Series(rankings).value_counts().sort_index()\n",
    "    for rank, count in rank_counts_series.items():\n",
    "        print(f\"Rank {rank}: {count} molecules\")\n",
    "    \n",
    "    return fig\n",
    "def main():\n",
    "    # Define output directory for figures\n",
    "    output_dir = \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/Figures\"\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    import os\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Example usage with different experiments\n",
    "    experiments = {\n",
    "        \"Experimental Data with Wrong Guess all\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_10_exp_d1_MMST_all_new\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Experimental Data with very Wrong Guess\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_9_exp_d1_aug_st\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"ACD Data with Wrong Guess HSQC\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_8_ACD_d1_MMST_HSQC\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Experimental Data with Wrong Guess HSQC\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_7_exp_d1_MMST_HSQC_new\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Lukas Data\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/Lukas_Target_incomplete\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/53_Lukas_real_data/cleaned_data_CLEAN.csv\"\n",
    "        },        \n",
    "        \"Lukas Aug Data\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/Lukas_aug_3_try_\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/53_Lukas_real_data/cleaned_data_CLEAN.csv\"\n",
    "        },\n",
    "        \"Simulated Data\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_1_sim_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Simulated Data with Wrong Guess\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_2_sim_aug_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Simulated Data with Noise\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_3_sim+noise_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Experimental Data\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_4_exp_d1_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Experimental Data with Wrong Guess\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_5_exp_d1_aug_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Experimental Data \": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_6_exp_d4_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Define colors for each experiment (using the colors from the model list)\n",
    "    colors = {\n",
    "        \n",
    "        \"Experimental Data with Wrong Guess all\": \"#6366F1\",\n",
    "        \"Experimental Data with very Wrong Guess HSQC\": \"#6366F1\",\n",
    "        \"ACD Data with Wrong Guess HSQC\": \"#6366F1\",\n",
    "        \"Experimental Data with Wrong Guess HSQC\": \"#6366F1\",\n",
    "        \"Lukas Data\": \"#6366F1\",                   # Claude 3.5 Sonnet\n",
    "        \"Lukas Aug Data\": \"#6366F1\",                   # Claude 3.5 Sonnet\n",
    "        \"Simulated Data\": \"#6366F1\",                   # Claude 3.5 Sonnet\n",
    "        \"Simulated Data with Wrong Guess\": \"#3B82F6\",  # Claude 3.7 Sonnet-Thinking\n",
    "        \"Simulated Data with Noise\": \"#10B981\",        # DeepSeek-R1\n",
    "        \"Experimental Data\": \"#F59E0B\",                # Gemini-Thinking\n",
    "        \"Experimental Data with Wrong Guess\": \"#EC4899\", # o3-mini\n",
    "        \"Experimental Data \": \"#F59E0B\"             # Kimi 1.5\n",
    "    }\n",
    "    \n",
    "    # Collect summary statistics\n",
    "    summary_data = []\n",
    "    \n",
    "    # Process each experiment\n",
    "    for exp_label, paths in experiments.items():\n",
    "        print(f\"\\nAnalyzing {exp_label}...\")\n",
    "        \n",
    "        # Get rankings\n",
    "        rankings = analyze_directory(paths[\"json_directory\"], paths[\"reference_csv\"])\n",
    "        \n",
    "        if not rankings:\n",
    "            print(f\"No valid rankings found for {exp_label}. Please check your input files.\")\n",
    "            continue\n",
    "        \n",
    "        # Create and show individual plot with custom color and extra bin for 6+\n",
    "        fig = plot_ranking_histogram(\n",
    "            rankings, \n",
    "            experiment_label=exp_label, \n",
    "            max_rank=5,  # Show individual ranks 1-5\n",
    "            color=colors[exp_label],\n",
    "            figsize=(5.5, 5.5)  # Smaller square figure\n",
    "        )\n",
    "        plt.show()\n",
    "        \n",
    "        # Save the plot to the specified output directory\n",
    "        output_path = os.path.join(output_dir, f'ranking_histogram_{exp_label.replace(\" \", \"_\")}_MMST.png')\n",
    "        fig.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Saved figure to: {output_path}\")\n",
    "        \n",
    "        # Collect statistics for summary\n",
    "        total_molecules = len(rankings)\n",
    "        in_top_1 = sum(1 for r in rankings if r == 1)\n",
    "        in_top_3 = sum(1 for r in rankings if r <= 3)\n",
    "        in_top_5 = sum(1 for r in rankings if r <= 5)\n",
    "        in_top_10 = sum(1 for r in rankings if r <= 10)\n",
    "        \n",
    "        summary_data.append({\n",
    "            'Experiment': exp_label,\n",
    "            'Tool': 'MMST',\n",
    "            'Total': total_molecules,\n",
    "            'Top 1': in_top_1,\n",
    "            'Top 1 %': in_top_1/total_molecules*100 if total_molecules > 0 else 0,\n",
    "            'Top 3': in_top_3,\n",
    "            'Top 3 %': in_top_3/total_molecules*100 if total_molecules > 0 else 0,\n",
    "            'Top 5': in_top_5,\n",
    "            'Top 5 %': in_top_5/total_molecules*100 if total_molecules > 0 else 0,\n",
    "            'Top 10': in_top_10,\n",
    "            'Top 10 %': in_top_10/total_molecules*100 if total_molecules > 0 else 0\n",
    "        })\n",
    "    \n",
    "    # Save summary statistics to CSV\n",
    "    try:\n",
    "        if summary_data:\n",
    "            summary_df = pd.DataFrame(summary_data)\n",
    "            summary_csv_path = os.path.join(output_dir, 'mmst_summary_statistics.csv')\n",
    "            summary_df.to_csv(summary_csv_path, index=False)\n",
    "            print(f\"\\nSaved summary statistics to: {summary_csv_path}\")\n",
    "            \n",
    "            # Print summary table\n",
    "            print(\"\\n===== SUMMARY STATISTICS =====\")\n",
    "            for row in summary_data:\n",
    "                print(f\"\\n{row['Experiment']}:\")\n",
    "                print(f\"Total: {row['Total']}\")\n",
    "                print(f\"Top 1: {row['Top 1']} ({row['Top 1 %']:.1f}%)\")\n",
    "                print(f\"Top 3: {row['Top 3']} ({row['Top 3 %']:.1f}%)\")\n",
    "                print(f\"Top 5: {row['Top 5']} ({row['Top 5 %']:.1f}%)\")\n",
    "                print(f\"Top 10: {row['Top 10']} ({row['Top 10 %']:.1f}%)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving summary statistics: {e}\")\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0ddeaf-2fa2-4d40-bc72-852aafd92d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4c952c-2ee9-4727-bd02-2e36db1c727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_unranked_molecules(json_dir, reference_csv):\n",
    "    \"\"\"\n",
    "    Identify molecules that were not ranked in the analysis.\n",
    "    \n",
    "    Args:\n",
    "        json_dir: Directory containing JSON files\n",
    "        reference_csv: Path to reference CSV file\n",
    "    \n",
    "    Returns:\n",
    "        List of unranked sample IDs and their SMILES\n",
    "    \"\"\"\n",
    "    # Load reference data\n",
    "    reference_data = load_reference_data(reference_csv)\n",
    "    \n",
    "    # Get all JSON files\n",
    "    json_files = glob.glob(os.path.join(json_dir, \"*.json\"))\n",
    "    \n",
    "    # Track processed molecules\n",
    "    processed_smiles = set()\n",
    "    unranked_molecules = []\n",
    "    \n",
    "    for file_path in json_files:\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                json_data = json.load(f)\n",
    "            \n",
    "            molecule_data = json_data.get('molecule_data', {})\n",
    "            sample_id = molecule_data.get('sample_id')\n",
    "            \n",
    "            if not sample_id:\n",
    "                continue\n",
    "                \n",
    "            # Get base sample ID for reference matching\n",
    "            base_sample_id = get_base_sample_id(sample_id)\n",
    "            \n",
    "            # Get correct SMILES\n",
    "            true_smiles = reference_data.get(base_sample_id)\n",
    "            if true_smiles is None:\n",
    "                print(f\"No reference SMILES found for {base_sample_id}\")\n",
    "                continue\n",
    "            \n",
    "            # Process molecules and find rank\n",
    "            molecules = process_single_json(json_data)\n",
    "            if not molecules:\n",
    "                # If no molecules processed, this could be the unranked molecule\n",
    "                if true_smiles not in processed_smiles:\n",
    "                    unranked_molecules.append({\n",
    "                        'sample_id': base_sample_id,\n",
    "                        'smiles': true_smiles\n",
    "                    })\n",
    "                continue\n",
    "                \n",
    "            # Check if this molecule is in the processed list\n",
    "            for mol in molecules:\n",
    "                processed_smiles.add(mol['smiles'])\n",
    "                \n",
    "            # Check if the true SMILES is not found in the molecules\n",
    "            if not any(mol['smiles'] == true_smiles for mol in molecules):\n",
    "                if true_smiles not in processed_smiles:\n",
    "                    unranked_molecules.append({\n",
    "                        'sample_id': base_sample_id,\n",
    "                        'smiles': true_smiles\n",
    "                    })\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Compare with total reference molecules\n",
    "    total_reference_molecules = set(reference_data.values())\n",
    "    missing_total = total_reference_molecules - processed_smiles\n",
    "    \n",
    "    if missing_total:\n",
    "        print(\"\\nMolecules missing from ALL processed files:\")\n",
    "        for smiles in missing_total:\n",
    "            # Find corresponding sample IDs\n",
    "            missing_ids = [sample_id for sample_id, ref_smiles in reference_data.items() if ref_smiles == smiles]\n",
    "            print(f\"SMILES: {smiles}, Sample IDs: {missing_ids}\")\n",
    "    \n",
    "    return unranked_molecules\n",
    "\n",
    "def main_find_unranked():\n",
    "    \"\"\"\n",
    "    Example usage of find_unranked_molecules function\n",
    "    \"\"\"\n",
    "    experiments = {\n",
    "        \"Simulated Data with Wrong Guess\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_2_sim_aug_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for exp_label, paths in experiments.items():\n",
    "        print(f\"\\nAnalyzing {exp_label}...\")\n",
    "        \n",
    "        # Find unranked molecules\n",
    "        unranked = find_unranked_molecules(\n",
    "            paths[\"json_directory\"], \n",
    "            paths[\"reference_csv\"]\n",
    "        )\n",
    "        \n",
    "        # Print results\n",
    "        if unranked:\n",
    "            print(\"\\nUnranked Molecules:\")\n",
    "            for mol in unranked:\n",
    "                print(f\"Sample ID: {mol['sample_id']}, SMILES: {mol['smiles']}\")\n",
    "        else:\n",
    "            print(\"No unranked molecules found.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_find_unranked()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3e8b5a-d3fb-4dc9-b165-5f16ed13a3d6",
   "metadata": {},
   "source": [
    "### V1.3 new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359d4e10-1b9a-46a3-b35c-a50e4b83cfd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def load_reference_data(csv_path):\n",
    "    \"\"\"Load reference SMILES from CSV file.\"\"\"\n",
    "    ref_df = pd.read_csv(csv_path)\n",
    "    # Convert to dictionary for faster lookups\n",
    "    return ref_df.set_index('sample-id')['SMILES'].to_dict()\n",
    "\n",
    "def get_base_sample_id(sample_id):\n",
    "    \"\"\"Extract base sample ID (part before underscore).\"\"\"\n",
    "    return sample_id.split('_')[0] if sample_id else ''\n",
    "\n",
    "def process_single_json(json_data):\n",
    "    \"\"\"Process a single JSON file and return sorted molecules.\"\"\"\n",
    "    try:\n",
    "        candidate_analysis = json_data[\"molecule_data\"]['candidate_analysis']\n",
    "    except KeyError:\n",
    "        return []\n",
    "    \n",
    "    all_molecules = []\n",
    "    analysis_types = ['forward_synthesis', 'mol2mol', 'mmst']\n",
    "    \n",
    "    for analysis_type in analysis_types:\n",
    "        if analysis_type in candidate_analysis:\n",
    "            molecules = candidate_analysis[analysis_type].get('molecules', [])\n",
    "            for mol in molecules:\n",
    "                try:\n",
    "                    processed_mol = {\n",
    "                        'smiles': mol['smiles'],\n",
    "                        'hsqc_score': mol.get('nmr_analysis', {}).get('matching_scores', {}).get('by_spectrum', {}).get('HSQC', None)\n",
    "                    }\n",
    "                    all_molecules.append(processed_mol)\n",
    "                except KeyError:\n",
    "                    continue\n",
    "    \n",
    "    # Sort by HSQC score\n",
    "    all_molecules.sort(key=lambda x: x['hsqc_score'] if x['hsqc_score'] is not None else float('inf'))\n",
    "    return all_molecules\n",
    "\n",
    "def find_molecule_rank(molecules, true_smiles):\n",
    "    \"\"\"Find the rank of the correct molecule.\"\"\"\n",
    "    for idx, mol in enumerate(molecules, 1):\n",
    "        if mol['smiles'] == true_smiles:\n",
    "            return idx\n",
    "    return None\n",
    "\n",
    "def analyze_directory(json_dir, reference_csv):\n",
    "    \"\"\"Analyze all JSON files and return list of rankings.\"\"\"\n",
    "    # Load reference data\n",
    "    reference_data = load_reference_data(reference_csv)\n",
    "    \n",
    "    # Get all JSON files\n",
    "    json_files = glob.glob(os.path.join(json_dir, \"*.json\"))\n",
    "    print(f\"Found {len(json_files)} JSON files to analyze\")\n",
    "    \n",
    "    rankings = []\n",
    "    \n",
    "    for file_path in json_files:\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                json_data = json.load(f)\n",
    "            \n",
    "            molecule_data = json_data.get('molecule_data', {})\n",
    "            sample_id = molecule_data.get('sample_id')\n",
    "            \n",
    "            if not sample_id:\n",
    "                continue\n",
    "                \n",
    "            # Get base sample ID for reference matching\n",
    "            base_sample_id = get_base_sample_id(sample_id)\n",
    "            \n",
    "            # Get correct SMILES\n",
    "            true_smiles = reference_data.get(base_sample_id)\n",
    "            if true_smiles is None:\n",
    "                print(f\"No reference SMILES found for {base_sample_id}\")\n",
    "                continue\n",
    "            \n",
    "            # Process molecules and find rank\n",
    "            molecules = process_single_json(json_data)\n",
    "            if not molecules:\n",
    "                continue\n",
    "                \n",
    "            rank = find_molecule_rank(molecules, true_smiles)\n",
    "            if rank is not None:\n",
    "                rankings.append(rank)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return rankings\n",
    "def plot_ranking_histogram(rankings, experiment_label=\"\", max_rank=5, color=\"#4169E1\", figsize=(5.5, 5.5)):\n",
    "    \"\"\"\n",
    "    Create histogram of molecule rankings with an extra bin for ranks beyond max_rank.\n",
    "    \n",
    "    Args:\n",
    "        rankings: List of rankings for correct molecules\n",
    "        experiment_label: Label for the experiment to be shown in title\n",
    "        max_rank: Maximum individual rank to show in histogram (default: 5)\n",
    "        color: Color for histogram bars\n",
    "        figsize: Size of the figure (default: (5.5, 5.5) for square plot)\n",
    "    \"\"\"\n",
    "    # Create figure with white background\n",
    "    fig, ax = plt.subplots(figsize=figsize, facecolor='white')\n",
    "    ax.set_facecolor('white')\n",
    "    \n",
    "    # Prepare data for histogram\n",
    "    rank_counts = {}\n",
    "    \n",
    "    # Count ranks 1-5 individually\n",
    "    for r in range(1, max_rank + 1):\n",
    "        rank_counts[r] = sum(1 for rank in rankings if rank == r)\n",
    "    \n",
    "    # Count all ranks > max_rank together\n",
    "    rank_counts['6+'] = sum(1 for rank in rankings if rank > max_rank)\n",
    "    \n",
    "    # Plot the histogram\n",
    "    positions = list(range(1, max_rank + 1)) + [max_rank + 1]\n",
    "    counts = [rank_counts[r] if r <= max_rank else rank_counts['6+'] for r in positions]\n",
    "    \n",
    "    bars = ax.bar(\n",
    "        positions,\n",
    "        counts,\n",
    "        width=0.8,\n",
    "        edgecolor='black',\n",
    "        alpha=0.7,\n",
    "        color=color\n",
    "    )\n",
    "    \n",
    "    # Create two-line title with increased font size (20)\n",
    "    title_line1 = 'Distribution of Correct Molecule Rankings'\n",
    "    title_line2 = experiment_label if experiment_label else \"\"\n",
    "    \n",
    "    ax.set_title(f\"{title_line1}\\n{title_line2}\", fontsize=20, pad=10)\n",
    "    ax.set_xlabel('Rank', fontsize=16)\n",
    "    ax.set_ylabel('Number of Molecules', fontsize=16)\n",
    "    \n",
    "    # Set x-axis ticks and labels with increased font size (14)\n",
    "    ax.set_xticks(positions)\n",
    "    x_labels = [str(i) for i in range(1, max_rank + 1)] + ['6+']\n",
    "    ax.set_xticklabels(x_labels, fontsize=14)\n",
    "    ax.tick_params(axis='y', labelsize=14)\n",
    "    \n",
    "    # Add grid with light gray color\n",
    "    ax.grid(True, alpha=0.3, color='gray', linestyle='--', axis='y')\n",
    "    \n",
    "    # Set fixed y-axis maximum to 35\n",
    "    y_max = 35\n",
    "    ax.set_ylim(0, y_max)\n",
    "    \n",
    "    # Add counts above bars with increased font size (14) and better positioning\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            ax.text(\n",
    "                bar.get_x() + bar.get_width()/2, \n",
    "                height + 0.7,  # Fixed offset for consistent positioning\n",
    "                f'{int(height)}',\n",
    "                ha='center', \n",
    "                va='bottom',\n",
    "                fontsize=14\n",
    "            )\n",
    "    \n",
    "    # Calculate statistics\n",
    "    total_molecules = len(rankings)\n",
    "    in_top_1 = sum(1 for r in rankings if r == 1)\n",
    "    in_top_3 = sum(1 for r in rankings if r <= 3)\n",
    "    in_top_5 = sum(1 for r in rankings if r <= 5)\n",
    "    after_top_5 = sum(1 for r in rankings if r > 5)\n",
    "    \n",
    "    stats_text = (\n",
    "        f'Total molecules found: {total_molecules}\\n'\n",
    "        f'Found in top 1: {in_top_1} ({in_top_1/total_molecules*100:.1f}%)\\n'\n",
    "        f'Found in top 3: {in_top_3} ({in_top_3/total_molecules*100:.1f}%)\\n'\n",
    "        f'Found in top 5: {in_top_5} ({in_top_5/total_molecules*100:.1f}%)\\n'\n",
    "        f'Found after top 5: {after_top_5} ({after_top_5/total_molecules*100:.1f}%)'\n",
    "    )\n",
    "    \n",
    "    # Add statistics text box with increased font size (14)\n",
    "    ax.text(0.95, 0.95, stats_text,\n",
    "            transform=ax.transAxes,\n",
    "            verticalalignment='top',\n",
    "            horizontalalignment='right',\n",
    "            fontsize=14,\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Print detailed distribution\n",
    "    print(f\"\\nDetailed rank distribution for {experiment_label if experiment_label else 'experiment'}:\")\n",
    "    rank_counts_series = pd.Series(rankings).value_counts().sort_index()\n",
    "    for rank, count in rank_counts_series.items():\n",
    "        print(f\"Rank {rank}: {count} molecules\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def main():\n",
    "    # Define output directory for figures\n",
    "    output_dir = \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/Figures\"\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    import os\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Example usage with different experiments\n",
    "    experiments = {\n",
    "        #\"ACD Data HSQC with Wrong Guess\": {\n",
    "        #    \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_8_ACD_d1_MMST_HSQC\",\n",
    "        #   \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        #},\n",
    "        \"Additional Data HSQC aug\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_15_Lukas_aug_finished\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/53_Lukas_real_data/cleaned_data_CLEAN.csv\"\n",
    "        },\n",
    "        \"Additional Data HSQC\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_14_Lukas_target_finished\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/53_Lukas_real_data/cleaned_data_CLEAN.csv\"\n",
    "        },        \n",
    "        \"Simulated Data ALL with Wrong Guess\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_2_sim_aug_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Simulated Data ALL with Noise\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_3_sim+noise_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Simulated Data ALL\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_1_sim_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Experimental Data HSQC with Wrong Guess\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_12_exp_d1_aug_MMST_HSQC_finished\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Experimental Data HSQC\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_13_exp_d1_MMST_HSQC_finished\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Experimental Data ALL with Wrong Guess\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_5_exp_d1_aug_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Experimental Data ALL with Wrong Guess\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_10_exp_d1_aug_MMST_all_new\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Experimental Data ALL\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_4_exp_d1_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        #\"Experimental Data \": {\n",
    "        #    \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_6_exp_d4_finished_clean\",\n",
    "        #    \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "       # }\n",
    "    }\n",
    "    \n",
    "    # Define colors for each experiment (using the colors from the model list)\n",
    "    colors = {\n",
    "        #\"ACD Data HSQC with Wrong Guess\": \"#6366F1\",\n",
    "        \"Additional Data HSQC aug\": \"#14B8A6\",                # Teal-500 (new)\n",
    "        \"Additional Data HSQC\": \"#0EA5E9\",                    # Sky-500 (new)\n",
    "        \"Simulated Data ALL with Wrong Guess\": \"#3B82F6\",     # Claude 3.7 Sonnet-Thinking\n",
    "        \"Simulated Data ALL with Noise\": \"#10B981\",           # DeepSeek-R1\n",
    "        \"Simulated Data ALL\": \"#6366F1\",                      # Claude 3.5 Sonnet\n",
    "        \"Experimental Data HSQC with Wrong Guess\": \"#F97316\", # Orange-500 (new)\n",
    "        \"Experimental Data HSQC\": \"#84CC16\",                  # Lime-500 (new)\n",
    "        \"Experimental Data ALL with Wrong Guess\": \"#EC4899\",  # o3-mini\n",
    "        \"Experimental Data ALL with Wrong Guess\": \"#EC4899\",  # Kimi 1.5\n",
    "        \"Experimental Data ALL\": \"#8B5CF6\"                    # Kimi 1.5\n",
    "    }\n",
    "    \n",
    "    # Collect summary statistics\n",
    "    summary_data = []\n",
    "    \n",
    "    # Process each experiment\n",
    "    for exp_label, paths in experiments.items():\n",
    "        print(f\"\\nAnalyzing {exp_label}...\")\n",
    "        \n",
    "        # Get rankings\n",
    "        rankings = analyze_directory(paths[\"json_directory\"], paths[\"reference_csv\"])\n",
    "        \n",
    "        if not rankings:\n",
    "            print(f\"No valid rankings found for {exp_label}. Please check your input files.\")\n",
    "            continue\n",
    "        \n",
    "        # Create and show individual plot with custom color and extra bin for 6+\n",
    "        fig = plot_ranking_histogram(\n",
    "            rankings, \n",
    "            experiment_label=exp_label, \n",
    "            max_rank=5,  # Show individual ranks 1-5\n",
    "            color=colors[exp_label],\n",
    "            figsize=(5.5, 5.5)  # Smaller square figure\n",
    "        )\n",
    "        plt.show()\n",
    "        \n",
    "        # Save the plot to the specified output directory\n",
    "        output_path = os.path.join(output_dir, f'ranking_histogram_{exp_label.replace(\" \", \"_\")}_MMST.png')\n",
    "        fig.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Saved figure to: {output_path}\")\n",
    "        \n",
    "        # Collect statistics for summary\n",
    "        total_molecules = len(rankings)\n",
    "        in_top_1 = sum(1 for r in rankings if r == 1)\n",
    "        in_top_3 = sum(1 for r in rankings if r <= 3)\n",
    "        in_top_5 = sum(1 for r in rankings if r <= 5)\n",
    "        in_top_10 = sum(1 for r in rankings if r <= 10)\n",
    "        \n",
    "        summary_data.append({\n",
    "            'Experiment': exp_label,\n",
    "            'Tool': 'MMST',\n",
    "            'Total': total_molecules,\n",
    "            'Top 1': in_top_1,\n",
    "            'Top 1 %': in_top_1/total_molecules*100 if total_molecules > 0 else 0,\n",
    "            'Top 3': in_top_3,\n",
    "            'Top 3 %': in_top_3/total_molecules*100 if total_molecules > 0 else 0,\n",
    "            'Top 5': in_top_5,\n",
    "            'Top 5 %': in_top_5/total_molecules*100 if total_molecules > 0 else 0,\n",
    "            'Top 10': in_top_10,\n",
    "            'Top 10 %': in_top_10/total_molecules*100 if total_molecules > 0 else 0\n",
    "        })\n",
    "    \n",
    "    # Save summary statistics to CSV\n",
    "    try:\n",
    "        if summary_data:\n",
    "            summary_df = pd.DataFrame(summary_data)\n",
    "            summary_csv_path = os.path.join(output_dir, 'mmst_summary_statistics.csv')\n",
    "            summary_df.to_csv(summary_csv_path, index=False)\n",
    "            print(f\"\\nSaved summary statistics to: {summary_csv_path}\")\n",
    "            \n",
    "            # Print summary table\n",
    "            print(\"\\n===== SUMMARY STATISTICS =====\")\n",
    "            for row in summary_data:\n",
    "                print(f\"\\n{row['Experiment']}:\")\n",
    "                print(f\"Total: {row['Total']}\")\n",
    "                print(f\"Top 1: {row['Top 1']} ({row['Top 1 %']:.1f}%)\")\n",
    "                print(f\"Top 3: {row['Top 3']} ({row['Top 3 %']:.1f}%)\")\n",
    "                print(f\"Top 5: {row['Top 5']} ({row['Top 5 %']:.1f}%)\")\n",
    "                print(f\"Top 10: {row['Top 10']} ({row['Top 10 %']:.1f}%)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving summary statistics: {e}\")\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e2af24-0db5-4049-ad53-19373561439d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf00ed4-02aa-47ae-bfe3-d734cabd7d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d9ee0d-7661-4a5b-8010-10b308f1bbaf",
   "metadata": {},
   "source": [
    "### V2 - OLD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795f64cb-543d-41d4-8127-7f661cb99dcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def load_reference_data(csv_path):\n",
    "    \"\"\"Load reference SMILES from CSV file.\"\"\"\n",
    "    ref_df = pd.read_csv(csv_path)\n",
    "    return ref_df.set_index('sample-id')['SMILES'].to_dict()\n",
    "\n",
    "def get_base_sample_id(sample_id):\n",
    "    \"\"\"Extract base sample ID (part before underscore).\"\"\"\n",
    "    return sample_id.split('_')[0] if sample_id else ''\n",
    "\n",
    "def process_single_json(json_data):\n",
    "    \"\"\"Process a single JSON file and return sorted molecules.\"\"\"\n",
    "    try:\n",
    "        candidate_analysis = json_data[\"molecule_data\"]['candidate_analysis']\n",
    "    except KeyError:\n",
    "        return []\n",
    "    \n",
    "    all_molecules = []\n",
    "    analysis_types = ['forward_synthesis', 'mol2mol', 'mmst']\n",
    "    \n",
    "    for analysis_type in analysis_types:\n",
    "        if analysis_type in candidate_analysis:\n",
    "            molecules = candidate_analysis[analysis_type].get('molecules', [])\n",
    "            for mol in molecules:\n",
    "                try:\n",
    "                    processed_mol = {\n",
    "                        'smiles': mol['smiles'],\n",
    "                        'hsqc_score': mol.get('nmr_analysis', {}).get('matching_scores', {}).get('by_spectrum', {}).get('HSQC', None)\n",
    "                    }\n",
    "                    all_molecules.append(processed_mol)\n",
    "                except KeyError:\n",
    "                    continue\n",
    "    \n",
    "    all_molecules.sort(key=lambda x: x['hsqc_score'] if x['hsqc_score'] is not None else float('inf'))\n",
    "    return all_molecules\n",
    "\n",
    "def find_molecule_rank(molecules, true_smiles):\n",
    "    \"\"\"Find the rank of the correct molecule.\"\"\"\n",
    "    for idx, mol in enumerate(molecules, 1):\n",
    "        if mol['smiles'] == true_smiles:\n",
    "            return idx\n",
    "    return None\n",
    "\n",
    "def analyze_directory(json_dir, reference_csv):\n",
    "    \"\"\"Analyze all JSON files and return list of rankings.\"\"\"\n",
    "    reference_data = load_reference_data(reference_csv)\n",
    "    json_files = glob.glob(os.path.join(json_dir, \"*.json\"))\n",
    "    print(f\"Found {len(json_files)} JSON files to analyze\")\n",
    "    \n",
    "    rankings = []\n",
    "    \n",
    "    for file_path in json_files:\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                json_data = json.load(f)\n",
    "            \n",
    "            molecule_data = json_data.get('molecule_data', {})\n",
    "            sample_id = molecule_data.get('sample_id')\n",
    "            \n",
    "            if not sample_id:\n",
    "                continue\n",
    "                \n",
    "            base_sample_id = get_base_sample_id(sample_id)\n",
    "            true_smiles = reference_data.get(base_sample_id)\n",
    "            \n",
    "            if true_smiles is None:\n",
    "                print(f\"No reference SMILES found for {base_sample_id}\")\n",
    "                continue\n",
    "            \n",
    "            molecules = process_single_json(json_data)\n",
    "            if not molecules:\n",
    "                continue\n",
    "                \n",
    "            rank = find_molecule_rank(molecules, true_smiles)\n",
    "            if rank is not None:\n",
    "                rankings.append(rank)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return rankings\n",
    "\n",
    "def plot_ranking_histogram(rankings, experiment_label=\"\", max_rank=5, figsize=(5, 5)):\n",
    "    \"\"\"\n",
    "    Create histogram of molecule rankings.\n",
    "    \n",
    "    Args:\n",
    "        rankings: List of rankings for correct molecules\n",
    "        experiment_label: Label for the experiment to be shown in title\n",
    "        max_rank: Maximum rank to show in histogram (default: 5)\n",
    "        figsize: Size of the figure (default: (10, 10))\n",
    "    \"\"\"\n",
    "    bins = np.arange(1, max_rank + 2) - 0.5\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize, facecolor='white')\n",
    "    ax.set_facecolor('white')\n",
    "    \n",
    "    n, bins, patches = ax.hist(\n",
    "        [r for r in rankings if r <= max_rank],\n",
    "        bins=bins,\n",
    "        edgecolor='black',\n",
    "        alpha=0.7,\n",
    "        color='#4169E1'  # Royal Blue\n",
    "    )\n",
    "    \n",
    "    title = 'Distribution of Correct Molecule Rankings'\n",
    "    if experiment_label:\n",
    "        title += f'\\n{experiment_label}'\n",
    "    ax.set_title(title, fontsize=16, pad=20)\n",
    "    ax.set_xlabel('Rank', fontsize=14)\n",
    "    ax.set_ylabel('Number of Molecules', fontsize=14)\n",
    "    \n",
    "    # Set x-axis ticks with larger font\n",
    "    ax.set_xticks(range(1, max_rank + 1))\n",
    "    ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "    \n",
    "    # Add grid\n",
    "    ax.grid(True, alpha=0.3, color='gray', linestyle='--')\n",
    "    \n",
    "    # Add counts above bars with larger font\n",
    "    for i, count in enumerate(n):\n",
    "        if count > 0:\n",
    "            ax.text(i + 1, count, f'{int(count)}', \n",
    "                   ha='center', va='bottom', fontsize=12)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    total_molecules = len(rankings)\n",
    "    in_top_5 = sum(1 for r in rankings if r <= 5)\n",
    "    \n",
    "    stats_text = (\n",
    "        f'Total molecules found: {total_molecules}\\n'\n",
    "        f'Found in top 5: {in_top_5} ({in_top_5/total_molecules*100:.1f}%)'\n",
    "    )\n",
    "    \n",
    "    ## Add statistics text box with larger font\n",
    "    #ax.text(0.95, 0.95, stats_text,\n",
    "    #        transform=ax.transAxes,\n",
    "     #       verticalalignment='top',\n",
    "       #     horizontalalignment='right',\n",
    "        #    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
    "         #   fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Print detailed distribution\n",
    "    print(f\"\\nDetailed rank distribution for {experiment_label if experiment_label else 'experiment'}:\")\n",
    "    rank_counts = pd.Series(rankings).value_counts().sort_index()\n",
    "    for rank, count in rank_counts.items():\n",
    "        if rank <= max_rank:\n",
    "            print(f\"Rank {rank}: {count} molecules\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def main():\n",
    "    experiments = {\n",
    "        \"Simulated Data\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_1_sim_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Simulated Data with Wrong Guess\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_2_sim_aug_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Simulated Data with Noise\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_3_sim+noise_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Experimental Data\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_4_exp_d1_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Experimental Data with Wrong Guess\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_5_exp_d1_aug_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Experimental Data d4\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_6_exp_d4_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for exp_label, paths in experiments.items():\n",
    "        print(f\"\\nAnalyzing {exp_label}...\")\n",
    "        rankings = analyze_directory(paths[\"json_directory\"], paths[\"reference_csv\"])\n",
    "        \n",
    "        if not rankings:\n",
    "            print(f\"No valid rankings found for {exp_label}. Please check your input files.\")\n",
    "            continue\n",
    "        \n",
    "        fig = plot_ranking_histogram(rankings, experiment_label=exp_label)\n",
    "        plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ca0a9a-e7b3-4d6e-b9ad-d5b2c2f3b983",
   "metadata": {},
   "source": [
    "## Compare with LLM ranked Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6ebdc6-a874-443a-b6d7-54e0535f404b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "def analyze_o3_predictions(json_file: str, reference_csv: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Analyze O3's molecular predictions against ground truth.\n",
    "    \n",
    "    Args:\n",
    "        json_file: Path to JSON file with O3's analysis\n",
    "        reference_csv: Path to CSV file with ground truth data\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with analysis results\n",
    "    \"\"\"\n",
    "    # Load reference data\n",
    "    ref_df = pd.read_csv(reference_csv)\n",
    "    ref_dict = ref_df.set_index('sample-id')['SMILES'].to_dict()\n",
    "    \n",
    "    # Load and parse JSON file\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Get sample ID and true SMILES\n",
    "    sample_id = data[\"molecule_data\"][\"sample_id\"]\n",
    "    base_sample_id = sample_id.split('_')[0]  # Remove suffix after underscore\n",
    "    true_smiles = ref_dict.get(base_sample_id)\n",
    "    \n",
    "    if true_smiles is None:\n",
    "        raise ValueError(f\"No reference SMILES found for sample_id {base_sample_id}\")\n",
    "    \n",
    "    # Extract O3's candidates and sort by confidence\n",
    "    try:\n",
    "        o3_results = data[\"analysis_results\"][\"final_analysis\"][\"llm_responses\"][\"o3\"][\"parsed_results\"]\n",
    "        candidates = o3_results[\"candidates\"]\n",
    "        \n",
    "        # Sort candidates by confidence score\n",
    "        sorted_candidates = sorted(candidates, \n",
    "                                 key=lambda x: x[\"confidence_score\"], \n",
    "                                 reverse=True)\n",
    "        \n",
    "        # Find position of correct molecule\n",
    "        correct_position = None\n",
    "        for i, cand in enumerate(sorted_candidates, 1):\n",
    "            if cand[\"smiles\"] == true_smiles:\n",
    "                correct_position = i\n",
    "                break\n",
    "        \n",
    "        # Prepare results\n",
    "        results = {\n",
    "            \"sample_id\": sample_id,\n",
    "            \"true_smiles\": true_smiles,\n",
    "            \"top_prediction\": {\n",
    "                \"smiles\": sorted_candidates[0][\"smiles\"],\n",
    "                \"confidence\": sorted_candidates[0][\"confidence_score\"]\n",
    "            },\n",
    "            \"is_top_correct\": sorted_candidates[0][\"smiles\"] == true_smiles,\n",
    "            \"correct_molecule_position\": correct_position,\n",
    "            \"total_candidates\": len(sorted_candidates),\n",
    "            \"all_predictions\": [\n",
    "                {\n",
    "                    \"position\": i+1,\n",
    "                    \"smiles\": cand[\"smiles\"],\n",
    "                    \"confidence\": cand[\"confidence_score\"],\n",
    "                    \"is_correct\": cand[\"smiles\"] == true_smiles\n",
    "                }\n",
    "                for i, cand in enumerate(sorted_candidates)\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except KeyError as e:\n",
    "        raise KeyError(f\"Could not find O3 results in expected JSON structure: {e}\")\n",
    "\n",
    "def print_analysis_results(results: Dict[str, Any]):\n",
    "    \"\"\"Print a human-readable summary of the analysis results.\"\"\"\n",
    "    print(f\"\\nAnalysis Results for {results['sample_id']}:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"True SMILES: {results['true_smiles']}\")\n",
    "    print(\"\\nTop Prediction:\")\n",
    "    print(f\"SMILES: {results['top_prediction']['smiles']}\")\n",
    "    print(f\"Confidence: {results['top_prediction']['confidence']:.2f}\")\n",
    "    print(f\"Is Correct: {results['is_top_correct']}\")\n",
    "    \n",
    "    if results['correct_molecule_position']:\n",
    "        print(f\"\\nCorrect molecule found at position: {results['correct_molecule_position']}\")\n",
    "    else:\n",
    "        print(\"\\nCorrect molecule not found in candidates\")\n",
    "    \n",
    "    print(f\"\\nAll predictions (total: {results['total_candidates']}):\")\n",
    "    for pred in results['all_predictions']:\n",
    "        correct_marker = \"\" if pred['is_correct'] else \" \"\n",
    "        print(f\"{correct_marker} {pred['position']}. Confidence: {pred['confidence']:.2f} - SMILES: {pred['smiles']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your file paths\n",
    "\n",
    "    json_file= \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_aug_2.0_finished_clean/AZ10930573_aug_intermediate.json\"\n",
    "    reference_csv= \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "    \n",
    "    try:\n",
    "        results = analyze_o3_predictions(json_file, reference_csv)\n",
    "        print_analysis_results(results)\n",
    "        \n",
    "        # Optionally save results\n",
    "        output_file = Path(json_file).parent / \"o3_analysis_results.json\"\n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing predictions: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465020b9-4008-46fe-883c-58b23bc751e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "def load_reference_data(csv_path: str) -> Dict[str, str]:\n",
    "    \"\"\"Load reference SMILES from CSV file.\"\"\"\n",
    "    ref_df = pd.read_csv(csv_path)\n",
    "    return ref_df.set_index('sample-id')['SMILES'].to_dict()\n",
    "\n",
    "def analyze_single_json(json_file: str, reference_data: Dict[str, str]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Analyze a single JSON file's O3 predictions against ground truth.\n",
    "    \n",
    "    Args:\n",
    "        json_file: Path to JSON file with O3's analysis\n",
    "        reference_data: Dictionary mapping sample IDs to true SMILES\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with analysis results or None if analysis fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load and parse JSON file\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Get sample ID and true SMILES\n",
    "        sample_id = data[\"molecule_data\"][\"sample_id\"]\n",
    "        base_sample_id = sample_id.split('_')[0]  # Remove suffix after underscore\n",
    "        true_smiles = reference_data.get(base_sample_id)\n",
    "        \n",
    "        if true_smiles is None:\n",
    "            print(f\"Warning: No reference SMILES found for sample_id {base_sample_id}\")\n",
    "            return None\n",
    "        \n",
    "        # Extract O3's candidates and sort by confidence\n",
    "        o3_results = data[\"analysis_results\"][\"final_analysis\"][\"llm_responses\"][\"kimi\"][\"parsed_results\"]\n",
    "        candidates = o3_results[\"candidates\"]\n",
    "        \n",
    "        # Sort candidates by confidence score\n",
    "        sorted_candidates = sorted(candidates, \n",
    "                                 key=lambda x: x[\"confidence_score\"], \n",
    "                                 reverse=True)\n",
    "        \n",
    "        # Find position of correct molecule\n",
    "        correct_position = None\n",
    "        for i, cand in enumerate(sorted_candidates, 1):\n",
    "            if cand[\"smiles\"] == true_smiles:\n",
    "                correct_position = i\n",
    "                break\n",
    "        \n",
    "        return {\n",
    "            \"sample_id\": sample_id,\n",
    "            \"correct_position\": correct_position,\n",
    "            \"total_candidates\": len(sorted_candidates),\n",
    "            \"is_top_1\": correct_position == 1,\n",
    "            \"is_top_3\": correct_position is not None and correct_position <= 3,\n",
    "            \"is_top_5\": correct_position is not None and correct_position <= 5,\n",
    "            \"is_top_10\": correct_position is not None and correct_position <= 10\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {json_file}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def analyze_directory(json_dir: str, reference_csv: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Analyze all JSON files in a directory.\n",
    "    \n",
    "    Args:\n",
    "        json_dir: Directory containing JSON files\n",
    "        reference_csv: Path to CSV file with ground truth data\n",
    "        \n",
    "    Returns:\n",
    "        List of analysis results for each file\n",
    "    \"\"\"\n",
    "    # Load reference data\n",
    "    reference_data = load_reference_data(reference_csv)\n",
    "    \n",
    "    # Get all JSON files\n",
    "    json_files = glob.glob(os.path.join(json_dir, \"*.json\"))\n",
    "    print(f\"Found {len(json_files)} JSON files to analyze\")\n",
    "    \n",
    "    # Analyze each file\n",
    "    results = []\n",
    "    for file_path in json_files:\n",
    "        result = analyze_single_json(file_path, reference_data)\n",
    "        if result:\n",
    "            results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def plot_ranking_histogram(results: List[Dict[str, Any]], experiment_label: str = \"\", max_rank: int = 10):\n",
    "    \"\"\"\n",
    "    Create histogram of correct molecule rankings.\n",
    "    \n",
    "    Args:\n",
    "        results: List of analysis results\n",
    "        experiment_label: Label for the experiment\n",
    "        max_rank: Maximum rank to show in histogram\n",
    "    \"\"\"\n",
    "    # Extract rankings\n",
    "    rankings = [r[\"correct_position\"] for r in results if r[\"correct_position\"] is not None]\n",
    "    \n",
    "    # Create bins for the histogram\n",
    "    bins = np.arange(1, max_rank + 2) - 0.5\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(12, 6), facecolor='white')\n",
    "    ax.set_facecolor('white')\n",
    "    \n",
    "    # Plot histogram\n",
    "    n, bins, patches = ax.hist(\n",
    "        [r for r in rankings if r <= max_rank],\n",
    "        bins=bins,\n",
    "        edgecolor='black',\n",
    "        alpha=0.7,\n",
    "        color='#4169E1'\n",
    "    )\n",
    "    \n",
    "    # Customize the plot\n",
    "    title = 'Distribution of O3 Correct Molecule Rankings'\n",
    "    if experiment_label:\n",
    "        title += f' - {experiment_label}'\n",
    "    ax.set_title(title, fontsize=14, pad=20)\n",
    "    ax.set_xlabel('Rank', fontsize=12)\n",
    "    ax.set_ylabel('Number of Molecules', fontsize=12)\n",
    "    \n",
    "    # Set x-axis ticks\n",
    "    ax.set_xticks(range(1, max_rank + 1))\n",
    "    \n",
    "    # Add grid\n",
    "    ax.grid(True, alpha=0.3, color='gray', linestyle='--')\n",
    "    \n",
    "    # Add counts above bars\n",
    "    for i, count in enumerate(n):\n",
    "        if count > 0:\n",
    "            ax.text(i + 1, count, f'{int(count)}', \n",
    "                   ha='center', va='bottom')\n",
    "    \n",
    "    # Calculate statistics\n",
    "    total_analyzed = len(results)\n",
    "    total_found = len(rankings)\n",
    "    in_top_1 = sum(1 for r in results if r[\"is_top_1\"])\n",
    "    in_top_3 = sum(1 for r in results if r[\"is_top_3\"])\n",
    "    in_top_5 = sum(1 for r in results if r[\"is_top_5\"])\n",
    "    in_top_10 = sum(1 for r in results if r[\"is_top_10\"])\n",
    "    \n",
    "    stats_text = (\n",
    "        f'Total analyzed: {total_analyzed}\\n'\n",
    "        f'Total found: {total_found}\\n'\n",
    "        f'Top 1: {in_top_1} ({in_top_1/total_analyzed*100:.1f}%)\\n'\n",
    "        f'Top 3: {in_top_3} ({in_top_3/total_analyzed*100:.1f}%)\\n'\n",
    "        f'Top 5: {in_top_5} ({in_top_5/total_analyzed*100:.1f}%)\\n'\n",
    "        f'Top 10: {in_top_10} ({in_top_10/total_analyzed*100:.1f}%)'\n",
    "    )\n",
    "    \n",
    "    # Add statistics text box\n",
    "    ax.text(0.95, 0.95, stats_text,\n",
    "            transform=ax.transAxes,\n",
    "            verticalalignment='top',\n",
    "            horizontalalignment='right',\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Print detailed distribution\n",
    "    print(f\"\\nDetailed rank distribution for {experiment_label if experiment_label else 'experiment'}:\")\n",
    "    rank_counts = pd.Series(rankings).value_counts().sort_index()\n",
    "    for rank, count in rank_counts.items():\n",
    "        print(f\"Rank {rank}: {count} molecules\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def main():\n",
    "    # Example usage with different experiments\n",
    "    experiments = {\n",
    "        \"O3 Experiment\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_expd1_5.0_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "    }\n",
    "    \n",
    "    for exp_label, paths in experiments.items():\n",
    "        print(f\"\\nAnalyzing {exp_label}...\")\n",
    "        \n",
    "        # Analyze all files\n",
    "        results = analyze_directory(paths[\"json_directory\"], paths[\"reference_csv\"])\n",
    "        \n",
    "        if not results:\n",
    "            print(f\"No valid results found for {exp_label}. Please check your input files.\")\n",
    "            continue\n",
    "        \n",
    "        # Create visualization\n",
    "        fig = plot_ranking_histogram(results, experiment_label=exp_label)\n",
    "        plt.show()\n",
    "        \n",
    "        # Save results\n",
    "        output_dir = Path(paths[\"json_directory\"]) / \"analysis_results\"\n",
    "        output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.to_csv(output_dir / \"o3_analysis_results.csv\", index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e8aed0-7fab-40ac-a7b0-8bf4d98c79bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_single_json(json_file: str, reference_data: Dict[str, str]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Analyze a single JSON file's O3 predictions against ground truth.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"\\nProcessing file: {json_file}\")  # Debug: Show which file we're processing\n",
    "        \n",
    "        # Load and parse JSON file\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Get sample ID and true SMILES\n",
    "        sample_id = data[\"molecule_data\"][\"sample_id\"]\n",
    "        print(f\"Sample ID: {sample_id}\")  # Debug: Show sample ID\n",
    "        \n",
    "        base_sample_id = sample_id.split('_')[0]\n",
    "        print(f\"Base Sample ID: {base_sample_id}\")  # Debug: Show base sample ID\n",
    "        \n",
    "        true_smiles = reference_data.get(base_sample_id)\n",
    "        print(f\"True SMILES found: {true_smiles is not None}\")  # Debug: Show if we found true SMILES\n",
    "        \n",
    "        if true_smiles is None:\n",
    "            print(f\"Warning: No reference SMILES found for sample_id {base_sample_id}\")\n",
    "            return None\n",
    "        \n",
    "        # Extract O3's candidates\n",
    "        o3_results = data[\"analysis_results\"][\"final_analysis\"][\"llm_responses\"][\"kimi\"][\"parsed_results\"]\n",
    "        candidates = o3_results[\"candidates\"]\n",
    "        print(f\"Number of candidates found: {len(candidates)}\")  # Debug: Show number of candidates\n",
    "        \n",
    "        # Debug: Print each candidate's confidence score before sorting\n",
    "        print(\"\\nCandidate confidence scores before sorting:\")\n",
    "        for i, cand in enumerate(candidates):\n",
    "            confidence = cand.get(\"confidence_score\")\n",
    "            smiles = cand.get(\"smiles\")\n",
    "            print(f\"Candidate {i}: confidence={confidence}, SMILES={smiles}\")\n",
    "        \n",
    "        # Modified sorting with error checking\n",
    "        valid_candidates = []\n",
    "        invalid_candidates = []\n",
    "        for cand in candidates:\n",
    "            if \"confidence_score\" not in cand or cand[\"confidence_score\"] is None:\n",
    "                print(f\"Warning: Invalid confidence score for candidate: {cand}\")  # Debug: Show invalid candidates\n",
    "                invalid_candidates.append(cand)\n",
    "            else:\n",
    "                valid_candidates.append(cand)\n",
    "        \n",
    "        # Sort only valid candidates\n",
    "        sorted_candidates = sorted(valid_candidates, \n",
    "                                 key=lambda x: x[\"confidence_score\"], \n",
    "                                 reverse=True)\n",
    "        \n",
    "        # Add invalid candidates at the end if any\n",
    "        sorted_candidates.extend(invalid_candidates)\n",
    "        \n",
    "        # Find position of correct molecule\n",
    "        correct_position = None\n",
    "        for i, cand in enumerate(sorted_candidates, 1):\n",
    "            if cand.get(\"smiles\") == true_smiles:\n",
    "                correct_position = i\n",
    "                print(f\"Found correct SMILES at position {i}\")  # Debug: Show where we found the correct SMILES\n",
    "                break\n",
    "        \n",
    "        if correct_position is None:\n",
    "            print(\"Correct SMILES not found in candidates\")  # Debug: Show if we didn't find the SMILES\n",
    "        \n",
    "        return {\n",
    "            \"sample_id\": sample_id,\n",
    "            \"correct_position\": correct_position,\n",
    "            \"total_candidates\": len(sorted_candidates),\n",
    "            \"total_valid_candidates\": len(valid_candidates),\n",
    "            \"total_invalid_candidates\": len(invalid_candidates),\n",
    "            \"is_top_1\": correct_position == 1,\n",
    "            \"is_top_3\": correct_position is not None and correct_position <= 3,\n",
    "            \"is_top_5\": correct_position is not None and correct_position <= 5,\n",
    "            \"is_top_10\": correct_position is not None and correct_position <= 10\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nDetailed error processing {json_file}:\")\n",
    "        print(f\"Error type: {type(e)}\")\n",
    "        print(f\"Error message: {str(e)}\")\n",
    "        import traceback\n",
    "        print(\"Traceback:\")\n",
    "        print(traceback.format_exc())\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c2eb94-45cb-4b92-96bc-a6757f2277c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_single_json(json_file, reference_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9750048e-197c-46d9-898e-ba0ed0d28e29",
   "metadata": {},
   "source": [
    "### V1 - OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981d8fea-3b3b-4335-9680-2a6bf34d7389",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "def load_reference_data(csv_path: str) -> Dict[str, str]:\n",
    "    \"\"\"Load reference SMILES from CSV file.\"\"\"\n",
    "    ref_df = pd.read_csv(csv_path)\n",
    "    return ref_df.set_index('sample-id')['SMILES'].to_dict()\n",
    "\n",
    "def analyze_llm_predictions(json_data: Dict, true_smiles: str, llm_name: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Analyze predictions from a specific LLM model.\n",
    "    \n",
    "    Args:\n",
    "        json_data: Loaded JSON data\n",
    "        true_smiles: True SMILES string to compare against\n",
    "        llm_name: Name of the LLM model to analyze\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with analysis results or None if analysis fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract LLM's candidates and sort by confidence\n",
    "        llm_results = json_data[\"analysis_results\"][\"final_analysis\"][\"llm_responses\"][llm_name][\"parsed_results\"]\n",
    "        candidates = llm_results[\"candidates\"]\n",
    "        \n",
    "        # Sort candidates by confidence score\n",
    "        sorted_candidates = sorted(candidates, \n",
    "                                 key=lambda x: x[\"confidence_score\"], \n",
    "                                 reverse=True)\n",
    "        \n",
    "        # Find position of correct molecule\n",
    "        correct_position = None\n",
    "        for i, cand in enumerate(sorted_candidates, 1):\n",
    "            if cand[\"smiles\"] == true_smiles:\n",
    "                correct_position = i\n",
    "                break\n",
    "        \n",
    "        return {\n",
    "            \"llm_model\": llm_name,\n",
    "            \"correct_position\": correct_position,\n",
    "            \"total_candidates\": len(sorted_candidates),\n",
    "            \"is_top_1\": correct_position == 1,\n",
    "            \"is_top_3\": correct_position is not None and correct_position <= 3,\n",
    "            \"is_top_5\": correct_position is not None and correct_position <= 5,\n",
    "            \"is_top_10\": correct_position is not None and correct_position <= 10\n",
    "        }\n",
    "        \n",
    "    except KeyError:\n",
    "        # This LLM might not have results in this file\n",
    "        return None\n",
    "\n",
    "def analyze_single_json(json_file: str, reference_data: Dict[str, str]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Analyze a single JSON file for all LLM models.\n",
    "    \n",
    "    Args:\n",
    "        json_file: Path to JSON file\n",
    "        reference_data: Dictionary mapping sample IDs to true SMILES\n",
    "        \n",
    "    Returns:\n",
    "        List of analysis results for each LLM model\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load and parse JSON file\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Get sample ID and true SMILES\n",
    "        sample_id = data[\"molecule_data\"][\"sample_id\"]\n",
    "        base_sample_id = sample_id.split('_')[0]\n",
    "        true_smiles = reference_data.get(base_sample_id)\n",
    "        \n",
    "        if true_smiles is None:\n",
    "            print(f\"Warning: No reference SMILES found for sample_id {base_sample_id}\")\n",
    "            return []\n",
    "        \n",
    "        # List of LLM models to analyze\n",
    "        llm_models = [\"claude\", \"claude3-7\", \"o3\", \"kimi\", \"gemini\", \"deepseek\"]\n",
    "        \n",
    "        # Analyze each LLM's predictions\n",
    "        results = []\n",
    "        for llm in llm_models:\n",
    "            result = analyze_llm_predictions(data, true_smiles, llm)\n",
    "            if result:\n",
    "                result[\"sample_id\"] = sample_id\n",
    "                results.append(result)\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {json_file}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def analyze_directory(json_dir: str, reference_csv: str) -> Dict[str, List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Analyze all JSON files in a directory for all LLM models.\n",
    "    \"\"\"\n",
    "    reference_data = load_reference_data(reference_csv)\n",
    "    json_files = glob.glob(os.path.join(json_dir, \"*.json\"))\n",
    "    print(f\"Found {len(json_files)} JSON files to analyze\")\n",
    "    \n",
    "    # Initialize results dictionary for each LLM\n",
    "    results_by_llm = {\n",
    "        \"claude\": [],\"claude3-7\": [], \"o3\": [], \"kimi\": [], \"gemini\": [], \"deepseek\": []\n",
    "    }\n",
    "    \n",
    "    for file_path in json_files:\n",
    "        results = analyze_single_json(file_path, reference_data)\n",
    "        for result in results:\n",
    "            llm_name = result[\"llm_model\"]\n",
    "            results_by_llm[llm_name].append(result)\n",
    "    \n",
    "    return results_by_llm\n",
    "\n",
    "def plot_ranking_histograms(results_by_llm: Dict[str, List[Dict[str, Any]]], \n",
    "                          experiment_label: str = \"\", \n",
    "                          max_rank: int = 10):\n",
    "    \"\"\"\n",
    "    Create histograms for all LLM models.\n",
    "    \"\"\"\n",
    "    # Create a figure with subplots\n",
    "    n_models = len(results_by_llm)\n",
    "    n_cols = 2\n",
    "    n_rows = (n_models + 1) // 2\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows), facecolor='white')\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Color scheme for different LLMs\n",
    "    colors = {\n",
    "        \"claude3-7\": \"#4169E1\",  # Royal Blue\n",
    "        \"claude\": \"#4169E1\",  # Royal Blue\n",
    "        \"o3\": \"#2E8B57\",      # Sea Green\n",
    "        \"kimi\": \"#8B4513\",    # Saddle Brown\n",
    "        \"gemini\": \"#4B0082\",  # Indigo\n",
    "        \"deepseek\": \"#CD853F\" # Peru\n",
    "    }\n",
    "    \n",
    "    for idx, (llm_name, results) in enumerate(results_by_llm.items()):\n",
    "        if not results:\n",
    "            continue\n",
    "            \n",
    "        ax = axes[idx]\n",
    "        ax.set_facecolor('white')\n",
    "        \n",
    "        # Extract rankings\n",
    "        rankings = [r[\"correct_position\"] for r in results if r[\"correct_position\"] is not None]\n",
    "        \n",
    "        # Create bins\n",
    "        bins = np.arange(1, max_rank + 2) - 0.5\n",
    "        \n",
    "        # Plot histogram\n",
    "        n, bins, patches = ax.hist(\n",
    "            [r for r in rankings if r <= max_rank],\n",
    "            bins=bins,\n",
    "            edgecolor='black',\n",
    "            alpha=0.7,\n",
    "            color=colors.get(llm_name, '#4169E1')\n",
    "        )\n",
    "        \n",
    "        # Customize subplot\n",
    "        title = f'{llm_name.upper()} Model Rankings'\n",
    "        if experiment_label:\n",
    "            title += f'\\n{experiment_label}'\n",
    "        ax.set_title(title, fontsize=12, pad=20)\n",
    "        ax.set_xlabel('Rank', fontsize=10)\n",
    "        ax.set_ylabel('Number of Molecules', fontsize=10)\n",
    "        ax.set_xticks(range(1, max_rank + 1))\n",
    "        ax.grid(True, alpha=0.3, color='gray', linestyle='--')\n",
    "        \n",
    "        # Add counts above bars\n",
    "        for i, count in enumerate(n):\n",
    "            if count > 0:\n",
    "                ax.text(i + 1, count, f'{int(count)}', \n",
    "                       ha='center', va='bottom')\n",
    "        \n",
    "        # Calculate statistics\n",
    "        total_analyzed = len(results)\n",
    "        total_found = len(rankings)\n",
    "        in_top_1 = sum(1 for r in results if r[\"is_top_1\"])\n",
    "        in_top_3 = sum(1 for r in results if r[\"is_top_3\"])\n",
    "        in_top_5 = sum(1 for r in results if r[\"is_top_5\"])\n",
    "        \n",
    "        stats_text = (\n",
    "            f'Total: {total_analyzed}\\n'\n",
    "            f'Found: {total_found}\\n'\n",
    "            f'Top 1: {in_top_1} ({in_top_1/total_analyzed*100:.1f}%)\\n'\n",
    "            f'Top 3: {in_top_3} ({in_top_3/total_analyzed*100:.1f}%)\\n'\n",
    "            f'Top 5: {in_top_5} ({in_top_5/total_analyzed*100:.1f}%)'\n",
    "        )\n",
    "        \n",
    "        # Add statistics text box\n",
    "        ax.text(0.95, 0.95, stats_text,\n",
    "                transform=ax.transAxes,\n",
    "                verticalalignment='top',\n",
    "                horizontalalignment='right',\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
    "                fontsize=9)\n",
    "    \n",
    "    # Remove empty subplots if any\n",
    "    for idx in range(len(results_by_llm), len(axes)):\n",
    "        fig.delaxes(axes[idx])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def main():\n",
    "    # Example usage\n",
    "    experiments = {\n",
    "        \"Simulated Data\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_1_sim_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Simulated Data with Wrong Guess\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_2_sim_aug_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Simulated Data with Noise\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_3_sim+noise_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Experimental Data\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_4_exp_d1_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Experimental Data with Wrong Guess\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_5_exp_d1_aug_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Experimental Data d4\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_6_exp_d4_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    \n",
    "    for exp_label, paths in experiments.items():\n",
    "        print(f\"\\nAnalyzing {exp_label}...\")\n",
    "        \n",
    "        # Analyze all files for all LLMs\n",
    "        results_by_llm = analyze_directory(paths[\"json_directory\"], paths[\"reference_csv\"])\n",
    "        \n",
    "        if not any(results_by_llm.values()):\n",
    "            print(f\"No valid results found for {exp_label}. Please check your input files.\")\n",
    "            continue\n",
    "        \n",
    "        # Create visualizations\n",
    "        fig = plot_ranking_histograms(results_by_llm, experiment_label=exp_label)\n",
    "        plt.show()\n",
    "        \n",
    "        # Save results\n",
    "        output_dir = Path(paths[\"json_directory\"]) / \"analysis_results\"\n",
    "        output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Save results for each LLM\n",
    "        for llm_name, results in results_by_llm.items():\n",
    "            if results:\n",
    "                df = pd.DataFrame(results)\n",
    "                df.to_csv(output_dir / f\"{llm_name}_analysis_results.csv\", index=False)\n",
    "                \n",
    "                # Print summary statistics\n",
    "                print(f\"\\nSummary for {llm_name.upper()}:\")\n",
    "                total = len(results)\n",
    "                if total > 0:\n",
    "                    top_1 = sum(1 for r in results if r[\"is_top_1\"])\n",
    "                    top_3 = sum(1 for r in results if r[\"is_top_3\"])\n",
    "                    top_5 = sum(1 for r in results if r[\"is_top_5\"])\n",
    "                    print(f\"Total analyzed: {total}\")\n",
    "                    print(f\"Top 1: {top_1} ({top_1/total*100:.1f}%)\")\n",
    "                    print(f\"Top 3: {top_3} ({top_3/total*100:.1f}%)\")\n",
    "                    print(f\"Top 5: {top_5} ({top_5/total*100:.1f}%)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ef201a-2458-4f5a-bc15-37c32c466725",
   "metadata": {},
   "source": [
    "### V2 - OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b494ca40-a061-4c17-946f-cada8da45d61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "def analyze_single_json(json_file: str, reference_data: Dict[str, str]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Analyze a single JSON file for all LLM models.\n",
    "    \n",
    "    Args:\n",
    "        json_file: Path to JSON file\n",
    "        reference_data: Dictionary mapping sample IDs to true SMILES\n",
    "        \n",
    "    Returns:\n",
    "        List of analysis results for each LLM model\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load and parse JSON file\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Get sample ID and true SMILES\n",
    "        sample_id = data[\"molecule_data\"][\"sample_id\"]\n",
    "        base_sample_id = sample_id.split('_')[0]\n",
    "        true_smiles = reference_data.get(base_sample_id)\n",
    "        \n",
    "        if true_smiles is None:\n",
    "            print(f\"Warning: No reference SMILES found for sample_id {base_sample_id}\")\n",
    "            return []\n",
    "        \n",
    "        # List of LLM models to analyze\n",
    "        llm_models = [\"claude\", \"claude3-7\", \"o3\", \"kimi\", \"gemini\", \"deepseek\"]\n",
    "        \n",
    "        # Analyze each LLM's predictions\n",
    "        results = []\n",
    "        for llm in llm_models:\n",
    "            result = analyze_llm_predictions(data, true_smiles, llm)\n",
    "            if result:\n",
    "                result[\"sample_id\"] = sample_id\n",
    "                results.append(result)\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {json_file}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "    \n",
    "    \n",
    "def analyze_directory(json_dir: str, reference_csv: str) -> Dict[str, List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Analyze all JSON files in a directory for all LLM models.\n",
    "    \"\"\"\n",
    "    reference_data = load_reference_data(reference_csv)\n",
    "    json_files = glob.glob(os.path.join(json_dir, \"*.json\"))\n",
    "    print(f\"Found {len(json_files)} JSON files to analyze\")\n",
    "    \n",
    "    # Initialize results dictionary for each LLM\n",
    "    results_by_llm = {\n",
    "        \"claude\": [], \"claude3-7\": [], \"o3\": [], \"kimi\": [], \"gemini\": [], \"deepseek\": []\n",
    "    }\n",
    "    \n",
    "    for file_path in json_files:\n",
    "        results = analyze_single_json(file_path, reference_data)\n",
    "        for result in results:\n",
    "            llm_name = result[\"llm_model\"]\n",
    "            results_by_llm[llm_name].append(result)\n",
    "    \n",
    "    return results_by_llm\n",
    "\n",
    "def plot_ranking_histograms(results_by_llm: Dict[str, List[Dict[str, Any]]], \n",
    "                          experiment_label: str = \"\"):\n",
    "    \"\"\"Create histograms for all LLM models.\"\"\"\n",
    "    n_models = len(results_by_llm)\n",
    "    n_cols = 2\n",
    "    n_rows = (n_models + 1) // 2\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 5*n_rows), facecolor='white')\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    colors = {\n",
    "        \"claude\": \"#4169E1\",      # Royal Blue\n",
    "        \"claude3-7\": \"#1E90FF\",   # Dodger Blue for Claude 3.7\n",
    "        \"o3\": \"#2E8B57\",          # Sea Green\n",
    "        \"kimi\": \"#8B4513\",        # Saddle Brown\n",
    "        \"gemini\": \"#4B0082\",      # Indigo\n",
    "        \"deepseek\": \"#CD853F\"     # Peru\n",
    "    }\n",
    "    \n",
    "    for idx, (llm_name, results) in enumerate(results_by_llm.items()):\n",
    "        if not results:\n",
    "            continue\n",
    "            \n",
    "        ax = axes[idx]\n",
    "        ax.set_facecolor('white')\n",
    "        \n",
    "        rankings = [r[\"correct_position\"] for r in results if r[\"correct_position\"] is not None]\n",
    "        bins = np.arange(1, 6 + 1) - 0.5\n",
    "        \n",
    "        # Create histogram\n",
    "        n, bins, patches = ax.hist(\n",
    "            [r for r in rankings if r <= 5],\n",
    "            bins=bins,\n",
    "            edgecolor='black',\n",
    "            alpha=0.7,\n",
    "            color=colors.get(llm_name, '#4169E1'),\n",
    "            label=llm_name.upper()  # Add label for the histogram\n",
    "        )\n",
    "        \n",
    "        # Calculate statistics for legend\n",
    "        total_analyzed = len(results)\n",
    "        in_top_5 = sum(1 for r in results if r[\"is_top_5\"])\n",
    "        top_5_percent = in_top_5/total_analyzed*100 if total_analyzed > 0 else 0\n",
    "        \n",
    "        # Add custom legend entry\n",
    "        ax.plot([], [], color=colors.get(llm_name, '#4169E1'), alpha=0.7,\n",
    "                label=f'Top 5: {in_top_5}/{total_analyzed} ({top_5_percent:.1f}%)')\n",
    "        \n",
    "        # Set title (now only showing LLM name and experiment label)\n",
    "        title = llm_name.upper()\n",
    "        if experiment_label:\n",
    "            title = f'{experiment_label}\\n{title}'\n",
    "        ax.set_title(title, fontsize=16, pad=20)\n",
    "        \n",
    "        # Set labels and ticks\n",
    "        ax.set_xlabel('Rank', fontsize=14)\n",
    "        ax.set_ylabel('Number of Molecules', fontsize=14)\n",
    "        ax.set_xticks(range(1, 6))\n",
    "        ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "        ax.grid(True, alpha=0.3, color='gray', linestyle='--')\n",
    "        \n",
    "        # Add counts above bars\n",
    "        for i, count in enumerate(n):\n",
    "            if count > 0:\n",
    "                ax.text(i + 1, count, f'{int(count)}', \n",
    "                       ha='center', va='bottom', fontsize=12)\n",
    "        \n",
    "        # Add legend with larger font\n",
    "        #ax.legend(fontsize=12, loc='upper right')\n",
    "    \n",
    "    # Remove empty subplots\n",
    "    for idx in range(len(results_by_llm), len(axes)):\n",
    "        fig.delaxes(axes[idx])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def main():\n",
    "    experiments = {\n",
    "        \"Simulated Data\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_1_sim_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Simulated Data with Wrong Guess\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_2_sim_aug_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Simulated Data with Noise\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_3_sim+noise_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Experimental Data\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_4_exp_d1_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Experimental Data with Wrong Guess\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_5_exp_d1_aug_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Experimental Data d4\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_6_exp_d4_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        }\n",
    "    }\n",
    "        \n",
    "    \n",
    "    for exp_label, paths in experiments.items():\n",
    "        print(f\"\\nAnalyzing {exp_label}...\")\n",
    "        results_by_llm = analyze_directory(paths[\"json_directory\"], paths[\"reference_csv\"])\n",
    "        \n",
    "        if not any(results_by_llm.values()):\n",
    "            print(f\"No valid results found for {exp_label}. Please check your input files.\")\n",
    "            continue\n",
    "        \n",
    "        fig = plot_ranking_histograms(results_by_llm, experiment_label=exp_label)\n",
    "        plt.show()\n",
    "        \n",
    "        # Print summary statistics\n",
    "        for llm_name, results in results_by_llm.items():\n",
    "            if results:\n",
    "                total = len(results)\n",
    "                in_top_5 = sum(1 for r in results if r[\"is_top_5\"])\n",
    "                print(f\"\\n{llm_name.upper()}:\")\n",
    "                print(f\"Top 5: {in_top_5}/{total} ({in_top_5/total*100:.1f}%)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1134fac3-ae48-445d-ade9-023707e033a9",
   "metadata": {},
   "source": [
    "### V2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d6c5ab-4d68-46cb-a784-6b14bbcbd359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "def load_reference_data(csv_path: str) -> Dict[str, str]:\n",
    "    \"\"\"Load reference SMILES from CSV file.\"\"\"\n",
    "    ref_df = pd.read_csv(csv_path)\n",
    "    # Convert to dictionary for faster lookups\n",
    "    return ref_df.set_index('sample-id')['SMILES'].to_dict()\n",
    "\n",
    "def get_base_sample_id(sample_id: str) -> str:\n",
    "    \"\"\"Extract base sample ID (part before underscore).\"\"\"\n",
    "    return sample_id.split('_')[0] if sample_id else ''\n",
    "\n",
    "def analyze_llm_predictions(json_data: Dict, true_smiles: str, llm_name: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Analyze predictions from a specific LLM model.\n",
    "    \n",
    "    Args:\n",
    "        json_data: Loaded JSON data\n",
    "        true_smiles: True SMILES string to compare against\n",
    "        llm_name: Name of the LLM model to analyze\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with analysis results or None if analysis fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract LLM's candidates and sort by confidence\n",
    "        llm_results = json_data[\"analysis_results\"][\"final_analysis\"][\"llm_responses\"][llm_name][\"parsed_results\"]\n",
    "        candidates = llm_results[\"candidates\"]\n",
    "        \n",
    "        # Sort candidates by confidence score\n",
    "        sorted_candidates = sorted(candidates, \n",
    "                                 key=lambda x: x[\"confidence_score\"], \n",
    "                                 reverse=True)\n",
    "        \n",
    "        # Find position of correct molecule\n",
    "        correct_position = None\n",
    "        for i, cand in enumerate(sorted_candidates, 1):\n",
    "            if cand[\"smiles\"] == true_smiles:\n",
    "                correct_position = i\n",
    "                break\n",
    "        \n",
    "        return {\n",
    "            \"llm_model\": llm_name,\n",
    "            \"correct_position\": correct_position,\n",
    "            \"total_candidates\": len(sorted_candidates),\n",
    "            \"is_top_1\": correct_position == 1 if correct_position else False,\n",
    "            \"is_top_5\": correct_position is not None and correct_position <= 5,\n",
    "            \"is_top_10\": correct_position is not None and correct_position <= 10,\n",
    "            \"is_after_top_10\": correct_position is not None and correct_position > 10\n",
    "        }\n",
    "        \n",
    "    except KeyError:\n",
    "        # This LLM might not have results in this file\n",
    "        return None\n",
    "\n",
    "def analyze_single_json(json_file: str, reference_data: Dict[str, str]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Analyze a single JSON file for all LLM models.\n",
    "    \n",
    "    Args:\n",
    "        json_file: Path to JSON file\n",
    "        reference_data: Dictionary mapping sample IDs to true SMILES\n",
    "        \n",
    "    Returns:\n",
    "        List of analysis results for each LLM model\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load and parse JSON file\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Get sample ID and true SMILES\n",
    "        sample_id = data.get(\"molecule_data\", {}).get(\"sample_id\")\n",
    "        if not sample_id:\n",
    "            return []\n",
    "            \n",
    "        base_sample_id = get_base_sample_id(sample_id)\n",
    "        true_smiles = reference_data.get(base_sample_id)\n",
    "        \n",
    "        if true_smiles is None:\n",
    "            print(f\"Warning: No reference SMILES found for sample_id {base_sample_id}\")\n",
    "            return []\n",
    "        \n",
    "        # List of LLM models to analyze\n",
    "        llm_models = [\"claude\", \"claude3-7\", \"o3\", \"kimi\", \"gemini\", \"deepseek\"]\n",
    "        \n",
    "        # Analyze each LLM's predictions\n",
    "        results = []\n",
    "        for llm in llm_models:\n",
    "            result = analyze_llm_predictions(data, true_smiles, llm)\n",
    "            if result:\n",
    "                result[\"sample_id\"] = sample_id\n",
    "                results.append(result)\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {json_file}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def analyze_directory(json_dir: str, reference_csv: str) -> Dict[str, List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Analyze all JSON files in a directory for all LLM models.\n",
    "    \"\"\"\n",
    "    reference_data = load_reference_data(reference_csv)\n",
    "    json_files = glob.glob(os.path.join(json_dir, \"*.json\"))\n",
    "    print(f\"Found {len(json_files)} JSON files to analyze\")\n",
    "    \n",
    "    # Initialize results dictionary for each LLM\n",
    "    results_by_llm = {\n",
    "        \"claude\": [], \"claude3-7\": [], \"o3\": [], \"kimi\": [], \"gemini\": [], \"deepseek\": []\n",
    "    }\n",
    "    \n",
    "    for file_path in json_files:\n",
    "        results = analyze_single_json(file_path, reference_data)\n",
    "        for result in results:\n",
    "            llm_name = result[\"llm_model\"]\n",
    "            results_by_llm[llm_name].append(result)\n",
    "    \n",
    "    return results_by_llm\n",
    "\n",
    "def get_display_name(llm_name):\n",
    "    \"\"\"Convert internal model names to display-friendly names.\"\"\"\n",
    "    name_mapping = {\n",
    "        \"claude\": \"Claude 3.5\",\n",
    "        \"claude3-7\": \"Claude 3.7 Thinking\",\n",
    "        \"o3\": \"o3 mini high\",\n",
    "        \"kimi\": \"Kimi 1.5\",\n",
    "        \"gemini\": \"Gemini 2.0 Thinking\",\n",
    "        \"deepseek\": \"DeepSeek R1\"\n",
    "    }\n",
    "    return name_mapping.get(llm_name, llm_name)\n",
    "\n",
    "def plot_llm_ranking_histogram(rankings: List[int], llm_name: str, experiment_label: str, \n",
    "                             max_rank: int = 5, color: str = \"#4169E1\", figsize: tuple = (5.5, 5.5)):\n",
    "    \"\"\"\n",
    "    Create histogram of molecule rankings for an LLM model with an extra bin for ranks beyond max_rank.\n",
    "    \n",
    "    Args:\n",
    "        rankings: List of rankings for correct molecules\n",
    "        llm_name: Name of the LLM model\n",
    "        experiment_label: Label for the experiment\n",
    "        max_rank: Maximum individual rank to show in histogram (default: 5)\n",
    "        color: Color for histogram bars\n",
    "        figsize: Size of the figure\n",
    "    \"\"\"\n",
    "    # Create figure with white background\n",
    "    fig, ax = plt.subplots(figsize=figsize, facecolor='white')\n",
    "    ax.set_facecolor('white')\n",
    "    \n",
    "    # Prepare data for histogram\n",
    "    rank_counts = {}\n",
    "    \n",
    "    # Count ranks 1-5 individually\n",
    "    for r in range(1, max_rank + 1):\n",
    "        rank_counts[r] = sum(1 for rank in rankings if rank == r)\n",
    "    \n",
    "    # Count all ranks > max_rank together\n",
    "    rank_counts['6+'] = sum(1 for rank in rankings if rank > max_rank)\n",
    "    \n",
    "    # Plot the histogram\n",
    "    positions = list(range(1, max_rank + 1)) + [max_rank + 1]\n",
    "    counts = [rank_counts[r] if r <= max_rank else rank_counts['6+'] for r in positions]\n",
    "    \n",
    "    bars = ax.bar(\n",
    "        positions,\n",
    "        counts,\n",
    "        width=0.8,\n",
    "        edgecolor='black',\n",
    "        alpha=0.7,\n",
    "        color=color\n",
    "    )\n",
    "    \n",
    "    # Get display-friendly model name\n",
    "    display_name = get_display_name(llm_name)\n",
    "    \n",
    "    # Create title with model name and experiment label\n",
    "    title = f\"{display_name} - {experiment_label}\"\n",
    "    ax.set_title(title, fontsize=16, pad=10)\n",
    "    \n",
    "    ax.set_xlabel('Rank', fontsize=14)\n",
    "    ax.set_ylabel('Number of Molecules', fontsize=14)\n",
    "    \n",
    "    # Set x-axis ticks and labels\n",
    "    ax.set_xticks(positions)\n",
    "    x_labels = [str(i) for i in range(1, max_rank + 1)] + ['6+']\n",
    "    ax.set_xticklabels(x_labels, fontsize=12)\n",
    "    ax.tick_params(axis='y', labelsize=12)\n",
    "    \n",
    "    # Add grid with light gray color\n",
    "    ax.grid(True, alpha=0.3, color='gray', linestyle='--', axis='y')\n",
    "    \n",
    "    # Calculate the maximum y value and add padding (20%)\n",
    "    max_count = max(counts) if counts else 0\n",
    "    y_max = 35 # Add 20% padding above the highest bar\n",
    "    ax.set_ylim(0, y_max)\n",
    "    \n",
    "    # Add counts above bars (not bold)\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            ax.text(\n",
    "                bar.get_x() + bar.get_width()/2, \n",
    "                height + (y_max * 0.01),  # Adjust text position based on y-axis range\n",
    "                f'{int(height)}',\n",
    "                ha='center', \n",
    "                va='bottom',\n",
    "                fontsize=12\n",
    "            )\n",
    "    \n",
    "    # Calculate statistics\n",
    "    total_molecules = len(rankings)\n",
    "    in_top_1 = sum(1 for r in rankings if r == 1)\n",
    "    in_top_3 = sum(1 for r in rankings if r <= 3)\n",
    "    in_top_5 = sum(1 for r in rankings if r <= 5)\n",
    "    after_top_5 = sum(1 for r in rankings if r > 5)\n",
    "    \n",
    "    stats_text = (\n",
    "        f'Total molecules found: {total_molecules}\\n'\n",
    "        f'Found in top 1: {in_top_1} ({in_top_1/total_molecules*100:.1f}%)\\n'\n",
    "        f'Found in top 3: {in_top_3} ({in_top_3/total_molecules*100:.1f}%)\\n'\n",
    "        f'Found in top 5: {in_top_5} ({in_top_5/total_molecules*100:.1f}%)\\n'\n",
    "        f'Found after top 5: {after_top_5} ({after_top_5/total_molecules*100:.1f}%)'\n",
    "    )\n",
    "    \n",
    "    # Add statistics text box\n",
    "    ax.text(0.95, 0.95, stats_text,\n",
    "            transform=ax.transAxes,\n",
    "            verticalalignment='top',\n",
    "            horizontalalignment='right',\n",
    "            fontsize=12,\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def analyze_and_plot_llm_results(llm_models_to_analyze=['deepseek']):\n",
    "    \"\"\"\n",
    "    Analyze and plot results for specified LLM models.\n",
    "    \n",
    "    Args:\n",
    "        llm_models_to_analyze: List of LLM models to analyze\n",
    "    \"\"\"\n",
    "    # Check if 'all' is in the list of LLMs to analyze\n",
    "    if 'all' in llm_models_to_analyze:\n",
    "        llm_models_to_analyze = ['claude', 'claude3-7', 'o3', 'kimi', 'gemini', 'deepseek']\n",
    "    \n",
    "    # Example usage with different experiments\n",
    "    experiments = {\n",
    "        \"Sim Data\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_1_sim_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Sim Data + Wrong Guess\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_2_sim_aug_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Sim Data + Noise\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_3_sim+noise_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Exp Data\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_4_exp_d1_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Exp Data + Wrong Guess\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_5_exp_d1_aug_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Exp Data d4\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_6_exp_d4_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Define colors for each experiment (using the colors from the model list)\n",
    "    experiment_colors = {\n",
    "        \"Sim Data\": \"#6366F1\",                   # Claude 3.5 Sonnet\n",
    "        \"Sim Data + Wrong Guess\": \"#3B82F6\",  # Claude 3.7 Sonnet-Thinking\n",
    "        \"Sim Data + Noise\": \"#10B981\",        # DeepSeek-R1\n",
    "        \"Exp Data\": \"#F59E0B\",                # Gemini-Thinking\n",
    "        \"Exp Data + Wrong Guess\": \"#EC4899\", # o3-mini\n",
    "        \"Exp Data d4\": \"#8B5CF6\"              # Kimi 1.5\n",
    "    }\n",
    "    \n",
    "    # Define colors for each LLM (if you want to color by LLM instead of experiment)\n",
    "    llm_colors = {\n",
    "        \"claude\": \"#4169E1\",      # Royal Blue\n",
    "        \"claude3-7\": \"#1E90FF\",   # Dodger Blue\n",
    "        \"o3\": \"#2E8B57\",          # Sea Green\n",
    "        \"kimi\": \"#8B4513\",        # Saddle Brown\n",
    "        \"gemini\": \"#4B0082\",      # Indigo\n",
    "        \"deepseek\": \"#CD853F\"     # Peru\n",
    "    }\n",
    "    \n",
    "    # Store summary statistics for all LLMs and experiments\n",
    "    summary_stats = {}\n",
    "    \n",
    "    # Process each experiment\n",
    "    for exp_label, paths in experiments.items():\n",
    "        print(f\"\\nAnalyzing {exp_label}...\")\n",
    "        \n",
    "        # Get results for all LLMs for this experiment\n",
    "        results_by_llm = analyze_directory(paths[\"json_directory\"], paths[\"reference_csv\"])\n",
    "        \n",
    "        # Process selected LLMs\n",
    "        for llm_name in llm_models_to_analyze:\n",
    "            if llm_name not in results_by_llm or not results_by_llm[llm_name]:\n",
    "                print(f\"No valid results found for {llm_name} in {exp_label}.\")\n",
    "                continue\n",
    "            \n",
    "            # Extract rankings\n",
    "            rankings = [r[\"correct_position\"] for r in results_by_llm[llm_name] \n",
    "                        if r[\"correct_position\"] is not None]\n",
    "            \n",
    "            if not rankings:\n",
    "                print(f\"No rankings found for {llm_name} in {exp_label}.\")\n",
    "                continue\n",
    "            \n",
    "            # Create and show individual plot\n",
    "            fig = plot_llm_ranking_histogram(\n",
    "                rankings,\n",
    "                llm_name,\n",
    "                exp_label, \n",
    "                color=experiment_colors[exp_label],  # Color by experiment\n",
    "                figsize=(6, 6)  # Slightly larger figure size\n",
    "            )\n",
    "            plt.show()\n",
    "            \n",
    "            # Save the plot with display name\n",
    "            display_name = get_display_name(llm_name)\n",
    "            fig.savefig(f'ranking_histogram_{exp_label}_{display_name.replace(\" \", \"_\")}.png', \n",
    "                      dpi=300, bbox_inches='tight')\n",
    "            \n",
    "            # Store statistics\n",
    "            if exp_label not in summary_stats:\n",
    "                summary_stats[exp_label] = {}\n",
    "                \n",
    "            total = len(rankings)\n",
    "            in_top_1 = sum(1 for r in rankings if r == 1)\n",
    "            in_top_5 = sum(1 for r in rankings if r <= 5)\n",
    "            in_top_10 = sum(1 for r in rankings if r <= 10)\n",
    "            \n",
    "            summary_stats[exp_label][llm_name] = {\n",
    "                \"total\": total,\n",
    "                \"in_top_1\": in_top_1,\n",
    "                \"in_top_5\": in_top_5,\n",
    "                \"in_top_10\": in_top_10,\n",
    "                \"percent_top_1\": in_top_1/total*100 if total > 0 else 0,\n",
    "                \"percent_top_5\": in_top_5/total*100 if total > 0 else 0,\n",
    "                \"percent_top_10\": in_top_10/total*100 if total > 0 else 0\n",
    "            }\n",
    "    \n",
    "    # Print summary table with display names\n",
    "    print(\"\\n===== SUMMARY STATISTICS =====\")\n",
    "    for exp_label, llm_stats in summary_stats.items():\n",
    "        print(f\"\\n{exp_label}:\")\n",
    "        print(f\"{'Model':<25} {'Total':<8} {'Top 1':<12} {'Top 5':<12} {'Top 10':<12}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        for llm_name, stats in llm_stats.items():\n",
    "            display_name = get_display_name(llm_name)\n",
    "            print(f\"{display_name:<25} {stats['total']:<8} \"\n",
    "                  f\"{stats['in_top_1']} ({stats['percent_top_1']:.1f}%) \"\n",
    "                  f\"{stats['in_top_5']} ({stats['percent_top_5']:.1f}%) \"\n",
    "                  f\"{stats['in_top_10']} ({stats['percent_top_10']:.1f}%)\")\n",
    "    \n",
    "    return summary_stats\n",
    "\n",
    "# Example of how to call the function with various LLM selections\n",
    "# Run this in a Jupyter cell:\n",
    "\n",
    "# Analyze only deepseek\n",
    "# analyze_and_plot_llm_results()\n",
    "\n",
    "# Analyze specific LLMs\n",
    "# analyze_and_plot_llm_results(['deepseek', 'claude3-7'])\n",
    "\n",
    "# Analyze all LLMs with updated display names\n",
    "analyze_and_plot_llm_results(['deepseek', 'claude', 'claude3-7', 'o3', 'kimi', 'gemini'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdc121b-1070-4933-b5b6-6a15228cbc99",
   "metadata": {},
   "source": [
    "### V3 Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4988320-dc7a-4c9f-9728-7b3d362338cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_llm_grid(experiment_label, results_by_llm, llm_models_to_analyze, experiment_colors):\n",
    "    \"\"\"\n",
    "    Create a 32 grid of histograms for all LLM models for a single experiment.\n",
    "    \n",
    "    Args:\n",
    "        experiment_label: Label of the current experiment\n",
    "        results_by_llm: Dictionary of results for each LLM\n",
    "        llm_models_to_analyze: List of LLM models to include in the grid\n",
    "        experiment_colors: Dictionary mapping experiment labels to colors\n",
    "    \n",
    "    Returns:\n",
    "        Matplotlib figure with the grid of histograms\n",
    "    \"\"\"\n",
    "    # Create a 32 grid of subplots\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(12, 16), facecolor='white')\n",
    "    axes = axes.flatten()  # Flatten to make indexing easier\n",
    "    \n",
    "    color = experiment_colors[experiment_label]\n",
    "    \n",
    "    # Plot each LLM in its own subplot\n",
    "    for i, llm_name in enumerate(llm_models_to_analyze):\n",
    "        if i >= len(axes):  # Safety check\n",
    "            break\n",
    "            \n",
    "        if llm_name not in results_by_llm or not results_by_llm[llm_name]:\n",
    "            # Skip if no data, but keep the subplot\n",
    "            axes[i].text(0.5, 0.5, f\"No data for {get_display_name(llm_name)}\", \n",
    "                       ha='center', va='center', fontsize=14)\n",
    "            axes[i].axis('off')\n",
    "            continue\n",
    "            \n",
    "        # Extract rankings\n",
    "        rankings = [r[\"correct_position\"] for r in results_by_llm[llm_name] \n",
    "                   if r[\"correct_position\"] is not None]\n",
    "        \n",
    "        if not rankings:\n",
    "            # Skip if no rankings\n",
    "            axes[i].text(0.5, 0.5, f\"No rankings for {get_display_name(llm_name)}\", \n",
    "                       ha='center', va='center', fontsize=14)\n",
    "            axes[i].axis('off')\n",
    "            continue\n",
    "            \n",
    "        # Set current axis\n",
    "        ax = axes[i]\n",
    "        ax.set_facecolor('white')\n",
    "        \n",
    "        # Prepare data for histogram\n",
    "        max_rank = 5\n",
    "        rank_counts = {}\n",
    "        \n",
    "        # Count ranks 1-5 individually\n",
    "        for r in range(1, max_rank + 1):\n",
    "            rank_counts[r] = sum(1 for rank in rankings if rank == r)\n",
    "        \n",
    "        # Count all ranks > max_rank together\n",
    "        rank_counts['6+'] = sum(1 for rank in rankings if rank > max_rank)\n",
    "        \n",
    "        # Plot the histogram\n",
    "        positions = list(range(1, max_rank + 1)) + [max_rank + 1]\n",
    "        counts = [rank_counts[r] if r <= max_rank else rank_counts['6+'] for r in positions]\n",
    "        \n",
    "        bars = ax.bar(\n",
    "            positions,\n",
    "            counts,\n",
    "            width=0.8,\n",
    "            edgecolor='black',\n",
    "            alpha=0.7,\n",
    "            color=color\n",
    "        )\n",
    "        \n",
    "        # Get display-friendly model name\n",
    "        display_name = get_display_name(llm_name)\n",
    "        \n",
    "        # Create title with only the model name (removed experiment label)\n",
    "        # and increased font size from 14 to 20\n",
    "        title = f\"{display_name}\"\n",
    "        ax.set_title(title, fontsize=20, pad=10)\n",
    "        \n",
    "        ax.set_xlabel('Rank', fontsize=16)\n",
    "        ax.set_ylabel('Number of Molecules', fontsize=16)\n",
    "        \n",
    "        # Set x-axis ticks and labels\n",
    "        ax.set_xticks(positions)\n",
    "        x_labels = [str(i) for i in range(1, max_rank + 1)] + ['6+']\n",
    "        ax.set_xticklabels(x_labels, fontsize=14)\n",
    "        ax.tick_params(axis='y', labelsize=14)\n",
    "        \n",
    "        # Add grid with light gray color\n",
    "        ax.grid(True, alpha=0.3, color='gray', linestyle='--', axis='y')\n",
    "        \n",
    "        # Add counts above bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            if height > 0:\n",
    "                ax.text(\n",
    "                    bar.get_x() + bar.get_width()/2, \n",
    "                    height + 0.1, \n",
    "                    f'{int(height)}',\n",
    "                    ha='center', \n",
    "                    va='bottom',\n",
    "                    fontsize=14\n",
    "                )\n",
    "        \n",
    "        # Calculate statistics\n",
    "        total_molecules = len(rankings)\n",
    "        in_top_1 = sum(1 for r in rankings if r == 1)\n",
    "        in_top_3 = sum(1 for r in rankings if r <= 3)\n",
    "        in_top_5 = sum(1 for r in rankings if r <= 5)\n",
    "        after_top_5 = sum(1 for r in rankings if r > 5)\n",
    "        \n",
    "        stats_text = (\n",
    "            f'Total: {total_molecules}\\n'\n",
    "            f'Top 1: {in_top_1} ({in_top_1/total_molecules*100:.1f}%)\\n'\n",
    "            f'Top 3: {in_top_3} ({in_top_3/total_molecules*100:.1f}%)\\n'\n",
    "            f'Top 5: {in_top_5} ({in_top_5/total_molecules*100:.1f}%)'\n",
    "        )\n",
    "        \n",
    "        # Add statistics text box\n",
    "        ax.text(0.95, 0.95, stats_text,\n",
    "                transform=ax.transAxes,\n",
    "                verticalalignment='top',\n",
    "                horizontalalignment='right',\n",
    "                fontsize=14,\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dc85ce-aea6-439a-8d1c-21a0914caa31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analyze_and_plot_llm_results(llm_models_to_analyze=['all']):\n",
    "    \"\"\"\n",
    "    Analyze and plot results for specified LLM models.\n",
    "    \n",
    "    Args:\n",
    "        llm_models_to_analyze: List of LLM models to analyze\n",
    "    \"\"\"\n",
    "    # Check if 'all' is in the list of LLMs to analyze\n",
    "    if 'all' in llm_models_to_analyze:\n",
    "        llm_models_to_analyze = ['claude', 'claude3-7', 'o3', 'kimi', 'gemini', 'deepseek']\n",
    "    \n",
    "    # Define output directory for figures\n",
    "    output_dir = \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/Figures\"\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    import os\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Example usage with different experiments\n",
    "    experiments = {\n",
    "        \"Sim Data\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_1_sim_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Sim Data + Wrong Guess\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_2_sim_aug_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Sim Data + Noise\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_3_sim+noise_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Exp Data\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_4_exp_d1_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Exp Data + Wrong Guess\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_5_exp_d1_aug_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Exp Data d4\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_6_exp_d4_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Define colors for each experiment (using the colors from the model list)\n",
    "    experiment_colors = {\n",
    "        \"Sim Data\": \"#6366F1\",                   # Claude 3.5 Sonnet\n",
    "        \"Sim Data + Wrong Guess\": \"#3B82F6\",     # Claude 3.7 Sonnet-Thinking\n",
    "        \"Sim Data + Noise\": \"#10B981\",           # DeepSeek-R1\n",
    "        \"Exp Data\": \"#F59E0B\",                   # Gemini-Thinking\n",
    "        \"Exp Data + Wrong Guess\": \"#EC4899\",     # o3-mini\n",
    "        \"Exp Data d4\": \"#8B5CF6\"                 # Kimi 1.5\n",
    "    }\n",
    "\n",
    "    \n",
    "    # Store summary statistics for all LLMs and experiments\n",
    "    summary_stats = {}\n",
    "    \n",
    "    # Process each experiment\n",
    "    for exp_label, paths in experiments.items():\n",
    "        print(f\"\\nAnalyzing {exp_label}...\")\n",
    "        \n",
    "        # Get results for all LLMs for this experiment\n",
    "        results_by_llm = analyze_directory(paths[\"json_directory\"], paths[\"reference_csv\"])\n",
    "        \n",
    "        # Create grid plot for all models for this experiment\n",
    "        grid_fig = plot_llm_grid(exp_label, results_by_llm, llm_models_to_analyze, experiment_colors)\n",
    "        \n",
    "        # Show the grid plot\n",
    "        plt.figure(grid_fig.number)\n",
    "        plt.show()\n",
    "        \n",
    "        # Save the grid plot to the specified output directory\n",
    "        grid_fig_path = os.path.join(output_dir, f'grid_histogram_{exp_label.replace(\" \", \"_\")}.png')\n",
    "        grid_fig.savefig(grid_fig_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Saved grid figure to: {grid_fig_path}\")\n",
    "        \n",
    "        # Store statistics for summary\n",
    "        if exp_label not in summary_stats:\n",
    "            summary_stats[exp_label] = {}\n",
    "            \n",
    "        # Process individual models for statistics\n",
    "        for llm_name in llm_models_to_analyze:\n",
    "            if llm_name not in results_by_llm or not results_by_llm[llm_name]:\n",
    "                continue\n",
    "                \n",
    "            # Extract rankings\n",
    "            rankings = [r[\"correct_position\"] for r in results_by_llm[llm_name] \n",
    "                       if r[\"correct_position\"] is not None]\n",
    "            \n",
    "            if not rankings:\n",
    "                continue\n",
    "                \n",
    "            # Create and save individual plot (optional)\n",
    "            fig = plot_llm_ranking_histogram(\n",
    "                rankings,\n",
    "                llm_name,\n",
    "                exp_label, \n",
    "                color=experiment_colors[exp_label],\n",
    "                figsize=(6, 6)\n",
    "            )\n",
    "            \n",
    "            display_name = get_display_name(llm_name)\n",
    "            individual_fig_path = os.path.join(\n",
    "                output_dir, \n",
    "                f'ranking_histogram_{exp_label.replace(\" \", \"_\")}_{display_name.replace(\" \", \"_\")}.png'\n",
    "            )\n",
    "            fig.savefig(individual_fig_path, dpi=300, bbox_inches='tight')\n",
    "            print(f\"Saved individual figure to: {individual_fig_path}\")\n",
    "            plt.close(fig)  # Close individual figure to save memory\n",
    "            \n",
    "            # Store statistics\n",
    "            total = len(rankings)\n",
    "            in_top_1 = sum(1 for r in rankings if r == 1)\n",
    "            in_top_5 = sum(1 for r in rankings if r <= 5)\n",
    "            in_top_10 = sum(1 for r in rankings if r <= 10)\n",
    "            \n",
    "            summary_stats[exp_label][llm_name] = {\n",
    "                \"total\": total,\n",
    "                \"in_top_1\": in_top_1,\n",
    "                \"in_top_5\": in_top_5,\n",
    "                \"in_top_10\": in_top_10,\n",
    "                \"percent_top_1\": in_top_1/total*100 if total > 0 else 0,\n",
    "                \"percent_top_5\": in_top_5/total*100 if total > 0 else 0,\n",
    "                \"percent_top_10\": in_top_10/total*100 if total > 0 else 0\n",
    "            }\n",
    "    \n",
    "    # Print summary table with display names\n",
    "    print(\"\\n===== SUMMARY STATISTICS =====\")\n",
    "    for exp_label, llm_stats in summary_stats.items():\n",
    "        print(f\"\\n{exp_label}:\")\n",
    "        print(f\"{'Model':<25} {'Total':<8} {'Top 1':<12} {'Top 5':<12} {'Top 10':<12}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        for llm_name, stats in llm_stats.items():\n",
    "            display_name = get_display_name(llm_name)\n",
    "            print(f\"{display_name:<25} {stats['total']:<8} \"\n",
    "                  f\"{stats['in_top_1']} ({stats['percent_top_1']:.1f}%) \"\n",
    "                  f\"{stats['in_top_5']} ({stats['percent_top_5']:.1f}%) \"\n",
    "                  f\"{stats['in_top_10']} ({stats['percent_top_10']:.1f}%)\")\n",
    "    \n",
    "    # Save summary statistics to a CSV file\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        summary_data = []\n",
    "        \n",
    "        for exp_label, llm_stats in summary_stats.items():\n",
    "            for llm_name, stats in llm_stats.items():\n",
    "                display_name = get_display_name(llm_name)\n",
    "                summary_data.append({\n",
    "                    'Experiment': exp_label,\n",
    "                    'Model': display_name,\n",
    "                    'Total': stats['total'],\n",
    "                    'Top 1': stats['in_top_1'],\n",
    "                    'Top 1 %': stats['percent_top_1'],\n",
    "                    'Top 5': stats['in_top_5'],\n",
    "                    'Top 5 %': stats['percent_top_5'],\n",
    "                    'Top 10': stats['in_top_10'],\n",
    "                    'Top 10 %': stats['percent_top_10']\n",
    "                })\n",
    "        \n",
    "        if summary_data:\n",
    "            summary_df = pd.DataFrame(summary_data)\n",
    "            summary_csv_path = os.path.join(output_dir, 'summary_statistics.csv')\n",
    "            summary_df.to_csv(summary_csv_path, index=False)\n",
    "            print(f\"\\nSaved summary statistics to: {summary_csv_path}\")\n",
    "    except ImportError:\n",
    "        print(\"pandas not available. Summary statistics not saved to CSV.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving summary statistics: {e}\")\n",
    "    \n",
    "    return summary_stats\n",
    "\n",
    "# Run the analysis with all models\n",
    "analyze_and_plot_llm_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98438b17-1620-4feb-9606-82e60156c896",
   "metadata": {},
   "source": [
    "### V3.1 Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119ab797-0a16-4adb-9c3b-9e8391c43ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_llm_grid(experiment_label, results_by_llm, llm_models_to_analyze, experiment_colors):\n",
    "    \"\"\"\n",
    "    Create a 32 grid of histograms for all LLM models for a single experiment.\n",
    "    \n",
    "    Args:\n",
    "        experiment_label: Label of the current experiment\n",
    "        results_by_llm: Dictionary of results for each LLM\n",
    "        llm_models_to_analyze: List of LLM models to include in the grid\n",
    "        experiment_colors: Dictionary mapping experiment labels to colors\n",
    "    \n",
    "    Returns:\n",
    "        Matplotlib figure with the grid of histograms\n",
    "    \"\"\"\n",
    "    # Create a 32 grid of subplots\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(12, 16), facecolor='white')\n",
    "    axes = axes.flatten()  # Flatten to make indexing easier\n",
    "    \n",
    "    color = experiment_colors[experiment_label]\n",
    "    \n",
    "    # Plot each LLM in its own subplot\n",
    "    for i, llm_name in enumerate(llm_models_to_analyze):\n",
    "        if i >= len(axes):  # Safety check\n",
    "            break\n",
    "            \n",
    "        if llm_name not in results_by_llm or not results_by_llm[llm_name]:\n",
    "            # Skip if no data, but keep the subplot\n",
    "            axes[i].text(0.5, 0.5, f\"No data for {get_display_name(llm_name)}\", \n",
    "                       ha='center', va='center', fontsize=14)\n",
    "            axes[i].axis('off')\n",
    "            continue\n",
    "            \n",
    "        # Extract rankings\n",
    "        rankings = [r[\"correct_position\"] for r in results_by_llm[llm_name] \n",
    "                   if r[\"correct_position\"] is not None]\n",
    "        \n",
    "        if not rankings:\n",
    "            # Skip if no rankings\n",
    "            axes[i].text(0.5, 0.5, f\"No rankings for {get_display_name(llm_name)}\", \n",
    "                       ha='center', va='center', fontsize=14)\n",
    "            axes[i].axis('off')\n",
    "            continue\n",
    "            \n",
    "        # Set current axis\n",
    "        ax = axes[i]\n",
    "        ax.set_facecolor('white')\n",
    "        \n",
    "        # Prepare data for histogram\n",
    "        max_rank = 5\n",
    "        rank_counts = {}\n",
    "        \n",
    "        # Count ranks 1-5 individually\n",
    "        for r in range(1, max_rank + 1):\n",
    "            rank_counts[r] = sum(1 for rank in rankings if rank == r)\n",
    "        \n",
    "        # Count all ranks > max_rank together\n",
    "        rank_counts['6+'] = sum(1 for rank in rankings if rank > max_rank)\n",
    "        \n",
    "        # Plot the histogram\n",
    "        positions = list(range(1, max_rank + 1)) + [max_rank + 1]\n",
    "        counts = [rank_counts[r] if r <= max_rank else rank_counts['6+'] for r in positions]\n",
    "        \n",
    "        bars = ax.bar(\n",
    "            positions,\n",
    "            counts,\n",
    "            width=0.8,\n",
    "            edgecolor='black',\n",
    "            alpha=0.7,\n",
    "            color=color\n",
    "        )\n",
    "        \n",
    "        # Get display-friendly model name\n",
    "        display_name = get_display_name(llm_name)\n",
    "        \n",
    "        # Create title with only the model name (removed experiment label)\n",
    "        # and increased font size from 14 to 20\n",
    "        title = f\"{display_name}\"\n",
    "        ax.set_title(title, fontsize=20, pad=10)\n",
    "        \n",
    "        ax.set_xlabel('Rank', fontsize=16)\n",
    "        ax.set_ylabel('Number of Molecules', fontsize=16)\n",
    "        \n",
    "        # Set x-axis ticks and labels\n",
    "        ax.set_xticks(positions)\n",
    "        x_labels = [str(i) for i in range(1, max_rank + 1)] + ['6+']\n",
    "        ax.set_xticklabels(x_labels, fontsize=14)\n",
    "        ax.tick_params(axis='y', labelsize=14)\n",
    "        \n",
    "        # Add grid with light gray color\n",
    "        ax.grid(True, alpha=0.3, color='gray', linestyle='--', axis='y')\n",
    "        \n",
    "        # Set fixed y-axis maximum to 34\n",
    "        y_max = 35\n",
    "        ax.set_ylim(0, y_max)\n",
    "        \n",
    "        # Add counts above bars with fixed positioning\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            if height > 0:\n",
    "                ax.text(\n",
    "                    bar.get_x() + bar.get_width()/2, \n",
    "                    height + 0.7,  # Fixed offset for consistent positioning\n",
    "                    f'{int(height)}',\n",
    "                    ha='center', \n",
    "                    va='bottom',\n",
    "                    fontsize=14\n",
    "                )\n",
    "        \n",
    "        # Calculate statistics\n",
    "        total_molecules = len(rankings)\n",
    "        in_top_1 = sum(1 for r in rankings if r == 1)\n",
    "        in_top_3 = sum(1 for r in rankings if r <= 3)\n",
    "        in_top_5 = sum(1 for r in rankings if r <= 5)\n",
    "        after_top_5 = sum(1 for r in rankings if r > 5)\n",
    "        \n",
    "        stats_text = (\n",
    "            f'Total: {total_molecules}\\n'\n",
    "            f'Top 1: {in_top_1} ({in_top_1/total_molecules*100:.1f}%)\\n'\n",
    "            f'Top 3: {in_top_3} ({in_top_3/total_molecules*100:.1f}%)\\n'\n",
    "            f'Top 5: {in_top_5} ({in_top_5/total_molecules*100:.1f}%)'\n",
    "        )\n",
    "        \n",
    "        # Add statistics text box\n",
    "        ax.text(0.95, 0.95, stats_text,\n",
    "                transform=ax.transAxes,\n",
    "                verticalalignment='top',\n",
    "                horizontalalignment='right',\n",
    "                fontsize=14,\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Add main title for the entire figure with the experiment label\n",
    "    fig.suptitle(f\"{experiment_label}\", fontsize=24, y=0.98)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(hspace=0.3, wspace=0.3, top=0.95)  # Adjusted top to make room for suptitle\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55865923-5453-4504-9e55-9508e048057e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analyze_and_plot_llm_results(llm_models_to_analyze=['all']):\n",
    "    \"\"\"\n",
    "    Analyze and plot results for specified LLM models.\n",
    "    \n",
    "    Args:\n",
    "        llm_models_to_analyze: List of LLM models to analyze\n",
    "    \"\"\"\n",
    "    # Check if 'all' is in the list of LLMs to analyze\n",
    "    if 'all' in llm_models_to_analyze:\n",
    "        llm_models_to_analyze = ['claude', 'claude3-7', 'o3', 'kimi', 'gemini', 'deepseek']\n",
    "    \n",
    "    # Define output directory for figures\n",
    "    output_dir = \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/Figures\"\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    import os\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Example usage with different experiments\n",
    "    experiments = {\n",
    "        \"Sim Data\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_1_sim_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Sim Data + Wrong Guess\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_2_sim_aug_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Sim Data + Noise\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_3_sim+noise_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Exp Data\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_4_exp_d1_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Exp Data + Wrong Guess\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_5_exp_d1_aug_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Exp Data d4\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_6_exp_d4_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Define colors for each experiment (using the colors from the model list)\n",
    "    experiment_colors = {\n",
    "        \"Sim Data\": \"#6366F1\",                   # Claude 3.5 Sonnet\n",
    "        \"Sim Data + Wrong Guess\": \"#3B82F6\",     # Claude 3.7 Sonnet-Thinking\n",
    "        \"Sim Data + Noise\": \"#10B981\",           # DeepSeek-R1\n",
    "        \"Exp Data\": \"#F59E0B\",                   # Gemini-Thinking\n",
    "        \"Exp Data + Wrong Guess\": \"#EC4899\",     # o3-mini\n",
    "        \"Exp Data d4\": \"#8B5CF6\"                 # Kimi 1.5\n",
    "    }\n",
    "    experiment_colors = {\n",
    "    \"Sim Data\": \"#6366F1\",                   # Same as \"Simulated Data ALL\"\n",
    "    \"Sim Data + Wrong Guess\": \"#3B82F6\",     # Same as \"Simulated Data ALL with Wrong Guess\"\n",
    "    \"Sim Data + Noise\": \"#10B981\",           # Same as \"Simulated Data ALL with Noise\"\n",
    "    \"Exp Data\": \"#84CC16\",                   # Matched with \"Experimental Data HSQC\" (new lime color)\n",
    "    \"Exp Data + Wrong Guess\": \"#F97316\",     # Matched with \"Experimental Data HSQC with Wrong Guess\" (new orange color)\n",
    "    \"Exp Data d4\": \"#8B5CF6\"                 # Same as \"Experimental Data ALL\"\n",
    "    }\n",
    "    \n",
    "    # Store summary statistics for all LLMs and experiments\n",
    "    summary_stats = {}\n",
    "    \n",
    "    # Process each experiment\n",
    "    for exp_label, paths in experiments.items():\n",
    "        print(f\"\\nAnalyzing {exp_label}...\")\n",
    "        \n",
    "        # Get results for all LLMs for this experiment\n",
    "        results_by_llm = analyze_directory(paths[\"json_directory\"], paths[\"reference_csv\"])\n",
    "        \n",
    "        # Create grid plot for all models for this experiment\n",
    "        grid_fig = plot_llm_grid(exp_label, results_by_llm, llm_models_to_analyze, experiment_colors)\n",
    "        \n",
    "        # Show the grid plot\n",
    "        plt.figure(grid_fig.number)\n",
    "        plt.show()\n",
    "        \n",
    "        # Save the grid plot to the specified output directory\n",
    "        grid_fig_path = os.path.join(output_dir, f'grid_histogram_{exp_label.replace(\" \", \"_\")}.png')\n",
    "        grid_fig.savefig(grid_fig_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Saved grid figure to: {grid_fig_path}\")\n",
    "        \n",
    "        # Store statistics for summary\n",
    "        if exp_label not in summary_stats:\n",
    "            summary_stats[exp_label] = {}\n",
    "            \n",
    "        # Process individual models for statistics\n",
    "        for llm_name in llm_models_to_analyze:\n",
    "            if llm_name not in results_by_llm or not results_by_llm[llm_name]:\n",
    "                continue\n",
    "                \n",
    "            # Extract rankings\n",
    "            rankings = [r[\"correct_position\"] for r in results_by_llm[llm_name] \n",
    "                       if r[\"correct_position\"] is not None]\n",
    "            \n",
    "            if not rankings:\n",
    "                continue\n",
    "                \n",
    "            # Create and save individual plot (optional)\n",
    "            fig = plot_llm_ranking_histogram(\n",
    "                rankings,\n",
    "                llm_name,\n",
    "                exp_label, \n",
    "                color=experiment_colors[exp_label],\n",
    "                figsize=(6, 6)\n",
    "            )\n",
    "            \n",
    "            display_name = get_display_name(llm_name)\n",
    "            individual_fig_path = os.path.join(\n",
    "                output_dir, \n",
    "                f'ranking_histogram_{exp_label.replace(\" \", \"_\")}_{display_name.replace(\" \", \"_\")}.png'\n",
    "            )\n",
    "            fig.savefig(individual_fig_path, dpi=300, bbox_inches='tight')\n",
    "            print(f\"Saved individual figure to: {individual_fig_path}\")\n",
    "            plt.close(fig)  # Close individual figure to save memory\n",
    "            \n",
    "            # Store statistics\n",
    "            total = len(rankings)\n",
    "            in_top_1 = sum(1 for r in rankings if r == 1)\n",
    "            in_top_5 = sum(1 for r in rankings if r <= 5)\n",
    "            in_top_10 = sum(1 for r in rankings if r <= 10)\n",
    "            \n",
    "            summary_stats[exp_label][llm_name] = {\n",
    "                \"total\": total,\n",
    "                \"in_top_1\": in_top_1,\n",
    "                \"in_top_5\": in_top_5,\n",
    "                \"in_top_10\": in_top_10,\n",
    "                \"percent_top_1\": in_top_1/total*100 if total > 0 else 0,\n",
    "                \"percent_top_5\": in_top_5/total*100 if total > 0 else 0,\n",
    "                \"percent_top_10\": in_top_10/total*100 if total > 0 else 0\n",
    "            }\n",
    "    \n",
    "    # Print summary table with display names\n",
    "    print(\"\\n===== SUMMARY STATISTICS =====\")\n",
    "    for exp_label, llm_stats in summary_stats.items():\n",
    "        print(f\"\\n{exp_label}:\")\n",
    "        print(f\"{'Model':<25} {'Total':<8} {'Top 1':<12} {'Top 5':<12} {'Top 10':<12}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        for llm_name, stats in llm_stats.items():\n",
    "            display_name = get_display_name(llm_name)\n",
    "            print(f\"{display_name:<25} {stats['total']:<8} \"\n",
    "                  f\"{stats['in_top_1']} ({stats['percent_top_1']:.1f}%) \"\n",
    "                  f\"{stats['in_top_5']} ({stats['percent_top_5']:.1f}%) \"\n",
    "                  f\"{stats['in_top_10']} ({stats['percent_top_10']:.1f}%)\")\n",
    "    \n",
    "    # Save summary statistics to a CSV file\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        summary_data = []\n",
    "        \n",
    "        for exp_label, llm_stats in summary_stats.items():\n",
    "            for llm_name, stats in llm_stats.items():\n",
    "                display_name = get_display_name(llm_name)\n",
    "                summary_data.append({\n",
    "                    'Experiment': exp_label,\n",
    "                    'Model': display_name,\n",
    "                    'Total': stats['total'],\n",
    "                    'Top 1': stats['in_top_1'],\n",
    "                    'Top 1 %': stats['percent_top_1'],\n",
    "                    'Top 5': stats['in_top_5'],\n",
    "                    'Top 5 %': stats['percent_top_5'],\n",
    "                    'Top 10': stats['in_top_10'],\n",
    "                    'Top 10 %': stats['percent_top_10']\n",
    "                })\n",
    "        \n",
    "        if summary_data:\n",
    "            summary_df = pd.DataFrame(summary_data)\n",
    "            summary_csv_path = os.path.join(output_dir, 'summary_statistics.csv')\n",
    "            summary_df.to_csv(summary_csv_path, index=False)\n",
    "            print(f\"\\nSaved summary statistics to: {summary_csv_path}\")\n",
    "    except ImportError:\n",
    "        print(\"pandas not available. Summary statistics not saved to CSV.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving summary statistics: {e}\")\n",
    "    \n",
    "    return summary_stats\n",
    "\n",
    "# Run the analysis with all models\n",
    "analyze_and_plot_llm_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d92d450-879f-4144-9f07-16881a2a9aa6",
   "metadata": {},
   "source": [
    "### V4 just Deepseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220a696f-73c2-49c1-abda-5023fb76d89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "def load_reference_data(csv_path: str) -> Dict[str, str]:\n",
    "    \"\"\"Load reference SMILES from CSV file.\"\"\"\n",
    "    ref_df = pd.read_csv(csv_path)\n",
    "    # Convert to dictionary for faster lookups\n",
    "    return ref_df.set_index('sample-id')['SMILES'].to_dict()\n",
    "\n",
    "def get_base_sample_id(sample_id: str) -> str:\n",
    "    \"\"\"Extract base sample ID (part before underscore).\"\"\"\n",
    "    return sample_id.split('_')[0] if sample_id else ''\n",
    "\n",
    "def analyze_llm_predictions(json_data: Dict, true_smiles: str, llm_name: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Analyze predictions from a specific LLM model.\n",
    "    \n",
    "    Args:\n",
    "        json_data: Loaded JSON data\n",
    "        true_smiles: True SMILES string to compare against\n",
    "        llm_name: Name of the LLM model to analyze\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with analysis results or None if analysis fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract LLM's candidates and sort by confidence\n",
    "        llm_results = json_data[\"analysis_results\"][\"final_analysis\"][\"llm_responses\"][llm_name][\"parsed_results\"]\n",
    "        candidates = llm_results[\"candidates\"]\n",
    "        \n",
    "        # Sort candidates by confidence score\n",
    "        sorted_candidates = sorted(candidates, \n",
    "                                 key=lambda x: x[\"confidence_score\"], \n",
    "                                 reverse=True)\n",
    "        \n",
    "        # Find position of correct molecule\n",
    "        correct_position = None\n",
    "        for i, cand in enumerate(sorted_candidates, 1):\n",
    "            if cand[\"smiles\"] == true_smiles:\n",
    "                correct_position = i\n",
    "                break\n",
    "        \n",
    "        return {\n",
    "            \"llm_model\": llm_name,\n",
    "            \"correct_position\": correct_position,\n",
    "            \"total_candidates\": len(sorted_candidates),\n",
    "            \"is_top_1\": correct_position == 1 if correct_position else False,\n",
    "            \"is_top_5\": correct_position is not None and correct_position <= 5,\n",
    "            \"is_top_10\": correct_position is not None and correct_position <= 10,\n",
    "            \"is_after_top_10\": correct_position is not None and correct_position > 10\n",
    "        }\n",
    "        \n",
    "    except KeyError:\n",
    "        # This LLM might not have results in this file\n",
    "        return None\n",
    "\n",
    "def analyze_single_json(json_file: str, reference_data: Dict[str, str]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Analyze a single JSON file for DeepSeek model.\n",
    "    \n",
    "    Args:\n",
    "        json_file: Path to JSON file\n",
    "        reference_data: Dictionary mapping sample IDs to true SMILES\n",
    "        \n",
    "    Returns:\n",
    "        List of analysis results for DeepSeek model\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load and parse JSON file\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Get sample ID and true SMILES\n",
    "        sample_id = data.get(\"molecule_data\", {}).get(\"sample_id\")\n",
    "        if not sample_id:\n",
    "            return []\n",
    "            \n",
    "        base_sample_id = get_base_sample_id(sample_id)\n",
    "        true_smiles = reference_data.get(base_sample_id)\n",
    "        \n",
    "        if true_smiles is None:\n",
    "            # print(f\"Warning: No reference SMILES found for sample_id {base_sample_id}\")\n",
    "            return []\n",
    "        \n",
    "        # Only analyze DeepSeek\n",
    "        llm_name = \"deepseek\"\n",
    "        \n",
    "        # Analyze DeepSeek's predictions\n",
    "        result = analyze_llm_predictions(data, true_smiles, llm_name)\n",
    "        if result:\n",
    "            result[\"sample_id\"] = sample_id\n",
    "            return [result]\n",
    "        \n",
    "        return []\n",
    "        \n",
    "    except Exception as e:\n",
    "        # print(f\"Error processing {json_file}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def analyze_directory(json_dir: str, reference_csv: str) -> Dict[str, List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Analyze all JSON files in a directory for DeepSeek model.\n",
    "    \"\"\"\n",
    "    reference_data = load_reference_data(reference_csv)\n",
    "    json_files = glob.glob(os.path.join(json_dir, \"*.json\"))\n",
    "    print(f\"Found {len(json_files)} JSON files to analyze\")\n",
    "    \n",
    "    # Initialize results dictionary just for DeepSeek\n",
    "    results_by_llm = {\"deepseek\": []}\n",
    "    \n",
    "    for file_path in json_files:\n",
    "        results = analyze_single_json(file_path, reference_data)\n",
    "        for result in results:\n",
    "            results_by_llm[\"deepseek\"].append(result)\n",
    "    \n",
    "    return results_by_llm\n",
    "\n",
    "def get_display_name(llm_name):\n",
    "    \"\"\"Convert internal model names to display-friendly names.\"\"\"\n",
    "    name_mapping = {\n",
    "        \"deepseek\": \"DeepSeek R1\"\n",
    "    }\n",
    "    return name_mapping.get(llm_name, llm_name)\n",
    "\n",
    "def plot_llm_ranking_histogram(rankings: List[int], llm_name: str, experiment_label: str, \n",
    "                             max_rank: int = 5, color: str = \"#4169E1\", figsize: tuple = (5.5, 5.5)):\n",
    "    \"\"\"\n",
    "    Create histogram of molecule rankings for an LLM model with an extra bin for ranks beyond max_rank.\n",
    "    \n",
    "    Args:\n",
    "        rankings: List of rankings for correct molecules\n",
    "        llm_name: Name of the LLM model\n",
    "        experiment_label: Label for the experiment\n",
    "        max_rank: Maximum individual rank to show in histogram (default: 5)\n",
    "        color: Color for histogram bars\n",
    "        figsize: Size of the figure\n",
    "    \"\"\"\n",
    "    # Create figure with white background\n",
    "    fig, ax = plt.subplots(figsize=figsize, facecolor='white')\n",
    "    ax.set_facecolor('white')\n",
    "    \n",
    "    # Prepare data for histogram\n",
    "    rank_counts = {}\n",
    "    \n",
    "    # Count ranks 1-5 individually\n",
    "    for r in range(1, max_rank + 1):\n",
    "        rank_counts[r] = sum(1 for rank in rankings if rank == r)\n",
    "    \n",
    "    # Count all ranks > max_rank together\n",
    "    rank_counts['6+'] = sum(1 for rank in rankings if rank > max_rank)\n",
    "    \n",
    "    # Plot the histogram\n",
    "    positions = list(range(1, max_rank + 1)) + [max_rank + 1]\n",
    "    counts = [rank_counts[r] if r <= max_rank else rank_counts['6+'] for r in positions]\n",
    "    \n",
    "    bars = ax.bar(\n",
    "        positions,\n",
    "        counts,\n",
    "        width=0.8,\n",
    "        edgecolor='black',\n",
    "        alpha=0.7,\n",
    "        color=color\n",
    "    )\n",
    "    \n",
    "    # Get display-friendly model name\n",
    "    display_name = get_display_name(llm_name)\n",
    "    \n",
    "    # Create title with model name and experiment label\n",
    "    title = f\"{display_name} - {experiment_label}\"\n",
    "    ax.set_title(title, fontsize=16, pad=10)\n",
    "    \n",
    "    ax.set_xlabel('Rank', fontsize=14)\n",
    "    ax.set_ylabel('Number of Molecules', fontsize=14)\n",
    "    \n",
    "    # Set x-axis ticks and labels\n",
    "    ax.set_xticks(positions)\n",
    "    x_labels = [str(i) for i in range(1, max_rank + 1)] + ['6+']\n",
    "    ax.set_xticklabels(x_labels, fontsize=12)\n",
    "    ax.tick_params(axis='y', labelsize=12)\n",
    "    \n",
    "    # Add grid with light gray color\n",
    "    ax.grid(True, alpha=0.3, color='gray', linestyle='--', axis='y')\n",
    "    \n",
    "    # Calculate the maximum y value and add padding (20%)\n",
    "    max_count = max(counts) if counts else 0\n",
    "    y_max = 35 # Add 20% padding above the highest bar\n",
    "    ax.set_ylim(0, y_max)\n",
    "    \n",
    "    # Add counts above bars (not bold)\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            ax.text(\n",
    "                bar.get_x() + bar.get_width()/2, \n",
    "                height + (y_max * 0.01),  # Adjust text position based on y-axis range\n",
    "                f'{int(height)}',\n",
    "                ha='center', \n",
    "                va='bottom',\n",
    "                fontsize=12\n",
    "            )\n",
    "    \n",
    "    # Calculate statistics\n",
    "    total_molecules = len(rankings)\n",
    "    in_top_1 = sum(1 for r in rankings if r == 1)\n",
    "    in_top_3 = sum(1 for r in rankings if r <= 3)\n",
    "    in_top_5 = sum(1 for r in rankings if r <= 5)\n",
    "    after_top_5 = sum(1 for r in rankings if r > 5)\n",
    "    \n",
    "    stats_text = (\n",
    "        f'Total molecules found: {total_molecules}\\n'\n",
    "        f'Found in top 1: {in_top_1} ({in_top_1/total_molecules*100:.1f}%)\\n'\n",
    "        f'Found in top 3: {in_top_3} ({in_top_3/total_molecules*100:.1f}%)\\n'\n",
    "        f'Found in top 5: {in_top_5} ({in_top_5/total_molecules*100:.1f}%)\\n'\n",
    "        f'Found after top 5: {after_top_5} ({after_top_5/total_molecules*100:.1f}%)'\n",
    "    )\n",
    "    \n",
    "    # Add statistics text box\n",
    "    ax.text(0.95, 0.95, stats_text,\n",
    "            transform=ax.transAxes,\n",
    "            verticalalignment='top',\n",
    "            horizontalalignment='right',\n",
    "            fontsize=12,\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def analyze_deepseek_results():\n",
    "    \"\"\"\n",
    "    Analyze DeepSeek results across specified experiments with updated colors.\n",
    "    \"\"\"\n",
    "    # Define output directory for figures\n",
    "    output_dir = \"./deepseek_results\"\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Define experiments to analyze (from the second reference file)\n",
    "    experiments = {\n",
    "        \"Additional Data HSQC aug\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_15_Lukas_aug_finished\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/53_Lukas_real_data/cleaned_data_CLEAN.csv\"\n",
    "        },\n",
    "        \"Additional Data HSQC\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_14_Lukas_target_finished\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/53_Lukas_real_data/cleaned_data_CLEAN.csv\"\n",
    "        },        \n",
    "        \"Simulated Data ALL with Wrong Guess\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_2_sim_aug_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Simulated Data ALL with Noise\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_3_sim+noise_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Simulated Data ALL\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_1_sim_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Experimental Data HSQC with Wrong Guess\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_12_exp_d1_aug_MMST_HSQC_finished\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Experimental Data HSQC\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_13_exp_d1_MMST_HSQC_finished\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Experimental Data ALL with Wrong Guess\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_10_exp_d1_aug_MMST_all_new\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Experimental Data ALL\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_4_exp_d1_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Define colors for each experiment (from the second reference file)\n",
    "    experiment_colors = {\n",
    "        \"Additional Data HSQC aug\": \"#14B8A6\",                # Teal-500\n",
    "        \"Additional Data HSQC\": \"#0EA5E9\",                    # Sky-500\n",
    "        \"Simulated Data ALL with Wrong Guess\": \"#3B82F6\",     # Blue\n",
    "        \"Simulated Data ALL with Noise\": \"#10B981\",           # Green\n",
    "        \"Simulated Data ALL\": \"#6366F1\",                      # Indigo\n",
    "        \"Experimental Data HSQC with Wrong Guess\": \"#F97316\", # Orange\n",
    "        \"Experimental Data HSQC\": \"#84CC16\",                  # Lime\n",
    "        \"Experimental Data ALL with Wrong Guess\": \"#EC4899\",  # Pink\n",
    "        \"Experimental Data ALL\": \"#8B5CF6\"                    # Purple\n",
    "    }\n",
    "    \n",
    "    # Store summary statistics\n",
    "    summary_stats = {}\n",
    "    \n",
    "    # Process each experiment\n",
    "    for exp_label, paths in experiments.items():\n",
    "        print(f\"\\nAnalyzing {exp_label}...\")\n",
    "        \n",
    "        # Get results for DeepSeek for this experiment\n",
    "        results_by_llm = analyze_directory(paths[\"json_directory\"], paths[\"reference_csv\"])\n",
    "        \n",
    "        # Check if DeepSeek results exist for this experiment\n",
    "        if not results_by_llm[\"deepseek\"]:\n",
    "            print(f\"No DeepSeek results found for {exp_label}\")\n",
    "            continue\n",
    "            \n",
    "        # Extract rankings for DeepSeek\n",
    "        deepseek_results = results_by_llm[\"deepseek\"]\n",
    "        rankings = [r[\"correct_position\"] for r in deepseek_results if r[\"correct_position\"] is not None]\n",
    "        \n",
    "        if not rankings:\n",
    "            print(f\"No valid rankings found for DeepSeek in {exp_label}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"Found {len(rankings)} valid rankings for DeepSeek in {exp_label}\")\n",
    "            \n",
    "        # Create individual plot for DeepSeek for this experiment\n",
    "        fig = plot_llm_ranking_histogram(\n",
    "            rankings,\n",
    "            'deepseek',\n",
    "            exp_label, \n",
    "            color=experiment_colors[exp_label],\n",
    "            figsize=(10, 6)\n",
    "        )\n",
    "        \n",
    "        # Save the figure\n",
    "        fig_path = os.path.join(output_dir, f'deepseek_{exp_label.replace(\" \", \"_\")}.png')\n",
    "        fig.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Saved figure to: {fig_path}\")\n",
    "        \n",
    "        # Calculate statistics\n",
    "        total = len(rankings)\n",
    "        in_top_1 = sum(1 for r in rankings if r == 1)\n",
    "        in_top_5 = sum(1 for r in rankings if r <= 5)\n",
    "        in_top_10 = sum(1 for r in rankings if r <= 10)\n",
    "        \n",
    "        summary_stats[exp_label] = {\n",
    "            \"total\": total,\n",
    "            \"in_top_1\": in_top_1,\n",
    "            \"in_top_5\": in_top_5,\n",
    "            \"in_top_10\": in_top_10,\n",
    "            \"percent_top_1\": in_top_1/total*100 if total > 0 else 0,\n",
    "            \"percent_top_5\": in_top_5/total*100 if total > 0 else 0,\n",
    "            \"percent_top_10\": in_top_10/total*100 if total > 0 else 0\n",
    "        }\n",
    "    \n",
    "    # Create comparison figure with all experiments\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Set up bar positions\n",
    "    bar_width = 0.8\n",
    "    bar_positions = np.arange(len(summary_stats))\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    labels = []\n",
    "    top_1_values = []\n",
    "    top_5_values = []\n",
    "    top_10_values = []\n",
    "    colors = []\n",
    "    \n",
    "    for exp_label, stats in summary_stats.items():\n",
    "        labels.append(exp_label)\n",
    "        top_1_values.append(stats['percent_top_1'])\n",
    "        top_5_values.append(stats['percent_top_5'])\n",
    "        top_10_values.append(stats['percent_top_10'])\n",
    "        colors.append(experiment_colors[exp_label])\n",
    "    \n",
    "    # Create comparison bar chart for Top-1 performance\n",
    "    bars = ax.bar(\n",
    "        bar_positions,\n",
    "        top_1_values,\n",
    "        bar_width,\n",
    "        color=colors,\n",
    "        edgecolor='black',\n",
    "        alpha=0.8,\n",
    "        label='Top-1 Accuracy'\n",
    "    )\n",
    "    \n",
    "    # Add text labels on bars\n",
    "    for i, bar in enumerate(bars):\n",
    "        height = bar.get_height()\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width()/2.,\n",
    "            height + 1,\n",
    "            f\"{top_1_values[i]:.1f}%\",\n",
    "            ha='center',\n",
    "            va='bottom',\n",
    "            fontsize=9\n",
    "        )\n",
    "    \n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('Experiment')\n",
    "    ax.set_ylabel('Top-1 Accuracy (%)')\n",
    "    ax.set_title('DeepSeek R1 Performance Across Experiments (Top-1 Accuracy)')\n",
    "    \n",
    "    # Set x-ticks and labels\n",
    "    ax.set_xticks(bar_positions)\n",
    "    ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "    \n",
    "    # Add a grid for better readability\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Adjust layout and save figure\n",
    "    plt.tight_layout()\n",
    "    comparison_fig_path = os.path.join(output_dir, 'deepseek_comparison.png')\n",
    "    fig.savefig(comparison_fig_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved comparison figure to: {comparison_fig_path}\")\n",
    "    \n",
    "    # Create a summary table\n",
    "    print(\"\\n===== DEEPSEEK PERFORMANCE SUMMARY =====\")\n",
    "    print(f\"{'Experiment':<40} {'Total':<8} {'Top 1':<12} {'Top 5':<12} {'Top 10':<12}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for exp_label, stats in summary_stats.items():\n",
    "        print(f\"{exp_label:<40} {stats['total']:<8} \"\n",
    "              f\"{stats['in_top_1']} ({stats['percent_top_1']:.1f}%) \"\n",
    "              f\"{stats['in_top_5']} ({stats['percent_top_5']:.1f}%) \"\n",
    "              f\"{stats['in_top_10']} ({stats['percent_top_10']:.1f}%)\")\n",
    "    \n",
    "    # Save summary statistics to a CSV file\n",
    "    try:\n",
    "        summary_data = []\n",
    "        \n",
    "        for exp_label, stats in summary_stats.items():\n",
    "            summary_data.append({\n",
    "                'Experiment': exp_label,\n",
    "                'Model': 'DeepSeek R1',\n",
    "                'Total': stats['total'],\n",
    "                'Top 1': stats['in_top_1'],\n",
    "                'Top 1 %': stats['percent_top_1'],\n",
    "                'Top 5': stats['in_top_5'],\n",
    "                'Top 5 %': stats['percent_top_5'],\n",
    "                'Top 10': stats['in_top_10'],\n",
    "                'Top 10 %': stats['percent_top_10']\n",
    "            })\n",
    "        \n",
    "        if summary_data:\n",
    "            summary_df = pd.DataFrame(summary_data)\n",
    "            summary_csv_path = os.path.join(output_dir, 'deepseek_summary_statistics.csv')\n",
    "            summary_df.to_csv(summary_csv_path, index=False)\n",
    "            print(f\"\\nSaved summary statistics to: {summary_csv_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving summary statistics: {e}\")\n",
    "    \n",
    "    return summary_stats\n",
    "\n",
    "# Run the analysis\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_deepseek_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bbf4c4-e007-4384-bb09-b899335b91d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1752f5-0fbd-4d81-be3c-f81d535e7c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d33c8bf-768a-4407-853f-872e48fd4d66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4230149-ad73-436f-b9dd-358aae70bde5",
   "metadata": {},
   "source": [
    "## Comparison HSQC and HSQC+LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39683abb-8b10-4f79-9af1-a22f2b5d3262",
   "metadata": {},
   "source": [
    "### V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa3a132-a6b0-42ca-9eee-190f0d71b177",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "from typing import Dict, List, Tuple, Any\n",
    "\n",
    "def load_reference_data(csv_path):\n",
    "    \"\"\"Load reference SMILES from CSV file.\"\"\"\n",
    "    ref_df = pd.read_csv(csv_path)\n",
    "    # Convert to dictionary for faster lookups\n",
    "    return ref_df.set_index('sample-id')['SMILES'].to_dict()\n",
    "\n",
    "def get_base_sample_id(sample_id):\n",
    "    \"\"\"Extract base sample ID (part before underscore).\"\"\"\n",
    "    return sample_id.split('_')[0] if sample_id else ''\n",
    "\n",
    "def process_single_json_hsqc(json_data):\n",
    "    \"\"\"Process a single JSON file and return sorted molecules by HSQC score.\"\"\"\n",
    "    try:\n",
    "        candidate_analysis = json_data[\"molecule_data\"]['candidate_analysis']\n",
    "    except KeyError:\n",
    "        return []\n",
    "    \n",
    "    all_molecules = []\n",
    "    analysis_types = ['forward_synthesis', 'mol2mol', 'mmst']\n",
    "    \n",
    "    for analysis_type in analysis_types:\n",
    "        if analysis_type in candidate_analysis:\n",
    "            molecules = candidate_analysis[analysis_type].get('molecules', [])\n",
    "            for mol in molecules:\n",
    "                try:\n",
    "                    processed_mol = {\n",
    "                        'smiles': mol['smiles'],\n",
    "                        'hsqc_score': mol.get('nmr_analysis', {}).get('matching_scores', {}).get('by_spectrum', {}).get('HSQC', None)\n",
    "                    }\n",
    "                    all_molecules.append(processed_mol)\n",
    "                except KeyError:\n",
    "                    continue\n",
    "    \n",
    "    # Sort by HSQC score\n",
    "    all_molecules.sort(key=lambda x: x['hsqc_score'] if x['hsqc_score'] is not None else float('inf'))\n",
    "    return all_molecules\n",
    "\n",
    "def analyze_llm_predictions(json_data, true_smiles, llm_name=\"deepseek\"):\n",
    "    \"\"\"\n",
    "    Analyze predictions from the DeepSeek LLM model.\n",
    "    \n",
    "    Args:\n",
    "        json_data: Loaded JSON data\n",
    "        true_smiles: True SMILES string to compare against\n",
    "        llm_name: Name of the LLM model to analyze (default: deepseek)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with analysis results or None if analysis fails\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract LLM's candidates and sort by confidence\n",
    "        llm_results = json_data[\"analysis_results\"][\"final_analysis\"][\"llm_responses\"][llm_name][\"parsed_results\"]\n",
    "        candidates = llm_results[\"candidates\"]\n",
    "        \n",
    "        # Sort candidates by confidence score\n",
    "        sorted_candidates = sorted(candidates, \n",
    "                                 key=lambda x: x[\"confidence_score\"], \n",
    "                                 reverse=True)\n",
    "        \n",
    "        # Find position of correct molecule\n",
    "        correct_position = None\n",
    "        for i, cand in enumerate(sorted_candidates, 1):\n",
    "            if cand[\"smiles\"] == true_smiles:\n",
    "                correct_position = i\n",
    "                break\n",
    "        \n",
    "        return {\n",
    "            \"correct_position\": correct_position,\n",
    "            \"total_candidates\": len(sorted_candidates),\n",
    "            \"is_top_1\": correct_position == 1 if correct_position else False,\n",
    "            \"is_top_5\": correct_position is not None and correct_position <= 6\n",
    "        }\n",
    "        \n",
    "    except (KeyError, TypeError):\n",
    "        # This LLM might not have results in this file\n",
    "        return None\n",
    "\n",
    "def find_molecule_rank(molecules, true_smiles):\n",
    "    \"\"\"Find the rank of the correct molecule.\"\"\"\n",
    "    for idx, mol in enumerate(molecules, 1):\n",
    "        if mol['smiles'] == true_smiles:\n",
    "            return idx\n",
    "    return None\n",
    "\n",
    "def analyze_directory_both_methods(json_dir, reference_csv, total_possible=34):\n",
    "    \"\"\"\n",
    "    Analyze all JSON files using both HSQC and DeepSeek.\n",
    "    Returns accuracy statistics for both methods.\n",
    "    \n",
    "    Args:\n",
    "        json_dir: Directory containing JSON files\n",
    "        reference_csv: Path to reference CSV file\n",
    "        total_possible: Total number of possible molecules to identify (default: 34)\n",
    "    \"\"\"\n",
    "    # Load reference data\n",
    "    reference_data = load_reference_data(reference_csv)\n",
    "    \n",
    "    # Get all JSON files\n",
    "    json_files = glob.glob(os.path.join(json_dir, \"*.json\"))\n",
    "    print(f\"Found {len(json_files)} JSON files to analyze\")\n",
    "    \n",
    "    hsqc_rankings = []\n",
    "    deepseek_rankings = []\n",
    "    \n",
    "    sample_ids = []  # Keep track of which samples were analyzed\n",
    "    \n",
    "    for file_path in json_files:\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                json_data = json.load(f)\n",
    "            \n",
    "            molecule_data = json_data.get('molecule_data', {})\n",
    "            sample_id = molecule_data.get('sample_id')\n",
    "            \n",
    "            if not sample_id:\n",
    "                continue\n",
    "                \n",
    "            # Get base sample ID for reference matching\n",
    "            base_sample_id = get_base_sample_id(sample_id)\n",
    "            \n",
    "            # Get correct SMILES\n",
    "            true_smiles = reference_data.get(base_sample_id)\n",
    "            if true_smiles is None:\n",
    "                print(f\"No reference SMILES found for {base_sample_id}\")\n",
    "                continue\n",
    "            \n",
    "            # Process HSQC ranking\n",
    "            molecules = process_single_json_hsqc(json_data)\n",
    "            if not molecules:\n",
    "                continue\n",
    "                \n",
    "            hsqc_rank = find_molecule_rank(molecules, true_smiles)\n",
    "            \n",
    "            # Process DeepSeek ranking\n",
    "            deepseek_result = analyze_llm_predictions(json_data, true_smiles)\n",
    "            \n",
    "            # Only include in analysis if both methods have results\n",
    "            if hsqc_rank is not None and deepseek_result is not None and deepseek_result.get(\"correct_position\") is not None:\n",
    "                hsqc_rankings.append(hsqc_rank)\n",
    "                deepseek_rankings.append(deepseek_result[\"correct_position\"])\n",
    "                sample_ids.append(sample_id)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Calculate statistics\n",
    "    total_samples = len(hsqc_rankings)\n",
    "    \n",
    "    if total_samples == 0:\n",
    "        return {\n",
    "            \"total_samples\": 0,\n",
    "            \"hsqc_top_1\": 0,\n",
    "            \"hsqc_top_1_percent\": 0,\n",
    "            \"deepseek_top_1\": 0,\n",
    "            \"deepseek_top_1_percent\": 0,\n",
    "            \"sample_ids\": []\n",
    "        }\n",
    "    \n",
    "    hsqc_top_1 = sum(1 for r in hsqc_rankings if r == 1)\n",
    "    hsqc_top_1_percent = (hsqc_top_1 / total_possible) * 100\n",
    "    \n",
    "    deepseek_top_1 = sum(1 for r in deepseek_rankings if r == 1)\n",
    "    deepseek_top_1_percent = (deepseek_top_1 / total_possible) * 100\n",
    "    \n",
    "    return {\n",
    "        \"total_samples\": total_samples,\n",
    "        \"total_possible\": total_possible,\n",
    "        \"hsqc_top_1\": hsqc_top_1,\n",
    "        \"hsqc_top_1_percent\": hsqc_top_1_percent,\n",
    "        \"deepseek_top_1\": deepseek_top_1,\n",
    "        \"deepseek_top_1_percent\": deepseek_top_1_percent,\n",
    "        \"sample_ids\": sample_ids\n",
    "    }\n",
    "\n",
    "def analyze_directory_both_methods(json_dir, reference_csv, total_possible=34):\n",
    "    \"\"\"\n",
    "    Analyze all JSON files using both HSQC and DeepSeek.\n",
    "    Returns accuracy statistics for both methods.\n",
    "    \n",
    "    Args:\n",
    "        json_dir: Directory containing JSON files\n",
    "        reference_csv: Path to reference CSV file\n",
    "        total_possible: Total number of possible molecules to identify (default: 34)\n",
    "    \"\"\"\n",
    "    # Load reference data\n",
    "    reference_data = load_reference_data(reference_csv)\n",
    "    \n",
    "    # Get all JSON files\n",
    "    json_files = glob.glob(os.path.join(json_dir, \"*.json\"))\n",
    "    print(f\"Found {len(json_files)} JSON files to analyze\")\n",
    "    \n",
    "    hsqc_rankings = []\n",
    "    deepseek_rankings = []\n",
    "    \n",
    "    hsqc_top_5_rankings = []\n",
    "    \n",
    "    sample_ids = []  # Keep track of which samples were analyzed\n",
    "    \n",
    "    for file_path in json_files:\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                json_data = json.load(f)\n",
    "            \n",
    "            molecule_data = json_data.get('molecule_data', {})\n",
    "            sample_id = molecule_data.get('sample_id')\n",
    "            \n",
    "            if not sample_id:\n",
    "                continue\n",
    "                \n",
    "            # Get base sample ID for reference matching\n",
    "            base_sample_id = get_base_sample_id(sample_id)\n",
    "            \n",
    "            # Get correct SMILES\n",
    "            true_smiles = reference_data.get(base_sample_id)\n",
    "            if true_smiles is None:\n",
    "                print(f\"No reference SMILES found for {base_sample_id}\")\n",
    "                continue\n",
    "            \n",
    "            # Process HSQC ranking\n",
    "            molecules = process_single_json_hsqc(json_data)\n",
    "            if not molecules:\n",
    "                continue\n",
    "                \n",
    "            hsqc_rank = find_molecule_rank(molecules, true_smiles)\n",
    "            \n",
    "            # Process DeepSeek ranking\n",
    "            deepseek_result = analyze_llm_predictions(json_data, true_smiles)\n",
    "            \n",
    "            # Only include in analysis if both methods have results\n",
    "            if hsqc_rank is not None and deepseek_result is not None and deepseek_result.get(\"correct_position\") is not None:\n",
    "                hsqc_rankings.append(hsqc_rank)\n",
    "                deepseek_rankings.append(deepseek_result[\"correct_position\"])\n",
    "                \n",
    "                # Track HSQC top-5 results\n",
    "                hsqc_top_5_rankings.append(hsqc_rank if hsqc_rank is not None and hsqc_rank <= 5 else None)\n",
    "                \n",
    "                sample_ids.append(sample_id)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Calculate statistics\n",
    "    total_samples = len(hsqc_rankings)\n",
    "    \n",
    "    if total_samples == 0:\n",
    "        return {\n",
    "            \"total_samples\": 0,\n",
    "            \"hsqc_top_1\": 0,\n",
    "            \"hsqc_top_1_percent\": 0,\n",
    "            \"deepseek_top_1\": 0,\n",
    "            \"deepseek_top_1_percent\": 0,\n",
    "            \"hsqc_top_5\": 0,\n",
    "            \"hsqc_top_5_percent\": 0,\n",
    "            \"sample_ids\": []\n",
    "        }\n",
    "    \n",
    "    hsqc_top_1 = sum(1 for r in hsqc_rankings if r == 1)\n",
    "    hsqc_top_1_percent = (hsqc_top_1 / total_possible) * 100\n",
    "    \n",
    "    deepseek_top_1 = sum(1 for r in deepseek_rankings if r == 1)\n",
    "    deepseek_top_1_percent = (deepseek_top_1 / total_possible) * 100\n",
    "    \n",
    "    # Top-5 calculations for HSQC\n",
    "    hsqc_top_5 = sum(1 for r in hsqc_top_5_rankings if r is not None)\n",
    "    hsqc_top_5_percent = (hsqc_top_5 / total_possible) * 100\n",
    "    \n",
    "    return {\n",
    "        \"total_samples\": total_samples,\n",
    "        \"total_possible\": total_possible,\n",
    "        \"hsqc_top_1\": hsqc_top_1,\n",
    "        \"hsqc_top_1_percent\": hsqc_top_1_percent,\n",
    "        \"deepseek_top_1\": deepseek_top_1,\n",
    "        \"deepseek_top_1_percent\": deepseek_top_1_percent,\n",
    "        \"hsqc_top_5\": hsqc_top_5,\n",
    "        \"hsqc_top_5_percent\": hsqc_top_5_percent,\n",
    "        \"sample_ids\": sample_ids\n",
    "    }\n",
    "\n",
    "def plot_comparison_chart(experiment_results, total_possible=34):\n",
    "    \"\"\"\n",
    "    Create a grouped bar chart comparing HSQC Top-5, Top-1, and DeepSeek Top-1 accuracy.\n",
    "    Show actual counts in bars and percentages on top.\n",
    "    \n",
    "    Args:\n",
    "        experiment_results: Dictionary with experiment names as keys and results dictionaries as values\n",
    "        total_possible: Total number of possible molecules to identify (default: 34)\n",
    "    \"\"\"\n",
    "    # Extract data for plotting\n",
    "    experiments = list(experiment_results.keys())\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    hsqc_top_5_counts = [results[\"hsqc_top_5\"] for results in experiment_results.values()]\n",
    "    hsqc_top_1_counts = [results[\"hsqc_top_1\"] for results in experiment_results.values()]\n",
    "    deepseek_top_1_counts = [results[\"deepseek_top_1\"] for results in experiment_results.values()]\n",
    "    \n",
    "    hsqc_top_5_percentages = [results[\"hsqc_top_5_percent\"] for results in experiment_results.values()]\n",
    "    hsqc_top_1_percentages = [results[\"hsqc_top_1_percent\"] for results in experiment_results.values()]\n",
    "    deepseek_top_1_percentages = [results[\"deepseek_top_1_percent\"] for results in experiment_results.values()]\n",
    "    \n",
    "    # For the x-axis positions\n",
    "    x = np.arange(len(experiments))\n",
    "    width = 0.25  # Adjusted width to accommodate three bars\n",
    "    \n",
    "    # Create figure and axis with increased size\n",
    "    fig, ax = plt.subplots(figsize=(16, 10), facecolor='white')\n",
    "    ax.set_facecolor('white')\n",
    "    \n",
    "    # Create the bars in the specified order\n",
    "    rects1 = ax.bar(x - width, hsqc_top_5_counts, width, label='HSQC Top-5', \n",
    "                  color='#2ca02c', alpha=0.7, edgecolor='black')\n",
    "    rects2 = ax.bar(x, hsqc_top_1_counts, width, label='HSQC Top-1', \n",
    "                  color='#1f77b4', alpha=0.7, edgecolor='black')\n",
    "    rects3 = ax.bar(x + width, deepseek_top_1_counts, width, label='DeepSeek Top-1', \n",
    "                  color='#ff7f0e', alpha=0.7, edgecolor='black')\n",
    "    \n",
    "    # Increase font sizes even more\n",
    "    ax.set_xlabel('Experiment', fontsize=20)\n",
    "    ax.set_ylabel('Number of Correct Predictions', fontsize=20)\n",
    "    \n",
    "    # Remove title as requested\n",
    "    # ax.set_title('Comparison of Top-5, Top-1 Accuracy: HSQC and DeepSeek', fontsize=18, pad=20)\n",
    "    \n",
    "    # Set y-axis to show actual counts, extending to 36\n",
    "    ax.set_ylim(0, 36)\n",
    "    \n",
    "    # Adjust x-axis tick labels\n",
    "    ax.set_xticks(x)\n",
    "    \n",
    "    # Shorten experiment names for display\n",
    "    short_names = []\n",
    "    for exp in experiments:\n",
    "        if \"Simulated Data\" in exp:\n",
    "            if \"Wrong Guess\" in exp:\n",
    "                short_names.append(\"Sim+WG\")\n",
    "            elif \"Noise\" in exp:\n",
    "                short_names.append(\"Sim+Noise\")\n",
    "            else:\n",
    "                short_names.append(\"Sim\")\n",
    "        elif \"Experimental Data\" in exp:\n",
    "            if \"Wrong Guess\" in exp:\n",
    "                short_names.append(\"Exp+WG\")\n",
    "            elif \"d4\" in exp:\n",
    "                short_names.append(\"Exp d4\")\n",
    "            else:\n",
    "                short_names.append(\"Exp\")\n",
    "        else:\n",
    "            short_names.append(exp)\n",
    "    \n",
    "    # Increase font size for x-axis labels\n",
    "    ax.set_xticklabels(short_names, ha='center', fontsize=18)\n",
    "    # Increase font size for y-axis labels\n",
    "    ax.tick_params(axis='y', labelsize=18)\n",
    "    \n",
    "    # Increase legend font size even more\n",
    "    ax.legend(fontsize=18, loc='upper right')\n",
    "    \n",
    "    # Add a grid\n",
    "    ax.grid(True, linestyle='--', alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add count inside bars and percentage on top with larger font\n",
    "    def add_labels(rects, counts, percentages):\n",
    "        for i, (rect, count, pct) in enumerate(zip(rects, counts, percentages)):\n",
    "            # Add count inside bar\n",
    "            height = rect.get_height()\n",
    "            center_x = rect.get_x() + rect.get_width() / 2\n",
    "            \n",
    "            # Only show count inside bar if bar is tall enough\n",
    "            if height > 5:  # Only show if bar is taller than 5 units\n",
    "                ax.text(center_x, height/2, str(count),\n",
    "                      ha='center', va='center',\n",
    "                      fontsize=16, color='white')  # Removed fontweight='bold'\n",
    "            else:\n",
    "                # For short bars, place count just above\n",
    "                ax.text(center_x, height + 1, str(count),\n",
    "                      ha='center', va='bottom',\n",
    "                      fontsize=16)\n",
    "            \n",
    "            # Add percentage on top with larger font\n",
    "            ax.text(center_x, height + 0.5, f'{pct:.1f}%',\n",
    "                  ha='center', va='bottom',\n",
    "                  fontsize=16)\n",
    "    \n",
    "    add_labels(rects1, hsqc_top_5_counts, hsqc_top_5_percentages)\n",
    "    add_labels(rects2, hsqc_top_1_counts, hsqc_top_1_percentages)\n",
    "    add_labels(rects3, deepseek_top_1_counts, deepseek_top_1_percentages)\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def main():\n",
    "    # Define the experiments\n",
    "    experiments = {\n",
    "        \"Simulated Data\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_1_sim_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Simulated Data with Wrong Guess\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_2_sim_aug_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Simulated Data with Noise\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_3_sim+noise_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Experimental Data\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_4_exp_d1_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        \"Experimental Data with Wrong Guess\": {\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_5_exp_d1_aug_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "      #  \"Experimental Data d4\": {\n",
    "      #      \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_6_exp_d4_finished_clean\",\n",
    "      #      \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "      #  }\n",
    "    }\n",
    "    \n",
    "    # Define the total possible number of molecules\n",
    "    TOTAL_POSSIBLE = 34\n",
    "    \n",
    "    # Store results for each experiment\n",
    "    experiment_results = {}\n",
    "    \n",
    "    # Process each experiment\n",
    "    for exp_label, paths in experiments.items():\n",
    "        print(f\"\\nAnalyzing {exp_label}...\")\n",
    "        \n",
    "        # Get rankings for both methods\n",
    "        results = analyze_directory_both_methods(paths[\"json_directory\"], paths[\"reference_csv\"], TOTAL_POSSIBLE)\n",
    "        \n",
    "        if results[\"total_samples\"] == 0:\n",
    "            print(f\"No valid results found for {exp_label}. Please check your input files.\")\n",
    "            continue\n",
    "        \n",
    "        experiment_results[exp_label] = results\n",
    "        \n",
    "        # Print individual experiment results\n",
    "        print(f\"Total samples analyzed: {results['total_samples']}\")\n",
    "        print(f\"HSQC Top-1: {results['hsqc_top_1']}/{TOTAL_POSSIBLE} ({results['hsqc_top_1_percent']:.1f}%)\")\n",
    "        print(f\"DeepSeek Top-1: {results['deepseek_top_1']}/{TOTAL_POSSIBLE} ({results['deepseek_top_1_percent']:.1f}%)\")\n",
    "        print(f\"Improvement: +{results['deepseek_top_1'] - results['hsqc_top_1']} hits (+{results['deepseek_top_1_percent'] - results['hsqc_top_1_percent']:.1f}%)\")\n",
    "    \n",
    "    # Create combined comparison plot\n",
    "    if experiment_results:\n",
    "        fig = plot_comparison_chart(experiment_results, TOTAL_POSSIBLE)\n",
    "        plt.show()\n",
    "        \n",
    "        # Save the plot\n",
    "        fig.savefig('top1_accuracy_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    else:\n",
    "        print(\"No results to display. Please check your input files.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779dbb09-dc1b-4420-830e-b181d1cec7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison_chart(experiment_results, total_possible=34):\n",
    "    \"\"\"\n",
    "    Create a grouped bar chart comparing HSQC Top-5, Top-1, and DeepSeek Top-1 accuracy.\n",
    "    Show actual counts in bars and percentages on top.\n",
    "    \n",
    "    Args:\n",
    "        experiment_results: Dictionary with experiment names as keys and results dictionaries as values\n",
    "        total_possible: Total number of possible molecules to identify (default: 34)\n",
    "    \"\"\"\n",
    "    # Extract data for plotting\n",
    "    experiments = list(experiment_results.keys())\n",
    "    \n",
    "    # Prepare data for plotting\n",
    "    hsqc_top_5_counts = [results[\"hsqc_top_5\"] for results in experiment_results.values()]\n",
    "    hsqc_top_1_counts = [results[\"hsqc_top_1\"] for results in experiment_results.values()]\n",
    "    deepseek_top_1_counts = [results[\"deepseek_top_1\"] for results in experiment_results.values()]\n",
    "    \n",
    "    hsqc_top_5_percentages = [results[\"hsqc_top_5_percent\"] for results in experiment_results.values()]\n",
    "    hsqc_top_1_percentages = [results[\"hsqc_top_1_percent\"] for results in experiment_results.values()]\n",
    "    deepseek_top_1_percentages = [results[\"deepseek_top_1_percent\"] for results in experiment_results.values()]\n",
    "    \n",
    "    # For the x-axis positions\n",
    "    x = np.arange(len(experiments))\n",
    "    width = 0.25  # Adjusted width to accommodate three bars\n",
    "    \n",
    "    # Create figure and axis with increased size\n",
    "    fig, ax = plt.subplots(figsize=(16, 10), facecolor='white')\n",
    "    ax.set_facecolor('white')\n",
    "    \n",
    "    # Create the bars in the specified order\n",
    "    rects1 = ax.bar(x - width, hsqc_top_5_counts, width, label='HSQC Top-5', \n",
    "                  color='#2ca02c', alpha=0.7, edgecolor='black')\n",
    "    rects2 = ax.bar(x, hsqc_top_1_counts, width, label='HSQC Top-1', \n",
    "                  color='#1f77b4', alpha=0.7, edgecolor='black')\n",
    "    rects3 = ax.bar(x + width, deepseek_top_1_counts, width, label='DeepSeek Top-1', \n",
    "                  color='#ff7f0e', alpha=0.7, edgecolor='black')\n",
    "    \n",
    "    # Increase font sizes even more\n",
    "    #ax.set_xlabel('Experiment', fontsize=20)\n",
    "    ax.set_ylabel('Number of Correct Predictions', fontsize=20)\n",
    "    \n",
    "    # Set y-axis to show actual counts, extending to 36\n",
    "    ax.set_ylim(0, 36)\n",
    "    \n",
    "    # Adjust x-axis tick labels\n",
    "    ax.set_xticks(x)\n",
    "    \n",
    "    # Update experiment names for display using Target/Analogue terminology\n",
    "    short_names = []\n",
    "    for exp in experiments:\n",
    "        if \"Simulated Data\" in exp:\n",
    "            if \"Wrong Guess\" in exp:\n",
    "                short_names.append(\"Sim Analogue\")\n",
    "            elif \"Noise\" in exp:\n",
    "                short_names.append(\"Sim Target+Noise\")\n",
    "            else:\n",
    "                short_names.append(\"Sim Target\")\n",
    "        elif \"Experimental Data\" in exp:\n",
    "            if \"Wrong Guess\" in exp:\n",
    "                short_names.append(\"Exp Analogue\")\n",
    "            elif \"d4\" in exp:\n",
    "                short_names.append(\"Exp d4\")\n",
    "            else:\n",
    "                short_names.append(\"Exp Target\")\n",
    "        else:\n",
    "            short_names.append(exp)\n",
    "    \n",
    "    # Increase font size for x-axis labels\n",
    "    ax.set_xticklabels(short_names, ha='center', fontsize=18)\n",
    "    # Increase font size for y-axis labels\n",
    "    ax.tick_params(axis='y', labelsize=18)\n",
    "    \n",
    "    # Increase legend font size even more\n",
    "    ax.legend(fontsize=18, loc='upper right')\n",
    "    \n",
    "    # Add a grid\n",
    "    ax.grid(True, linestyle='--', alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add count inside bars and percentage on top with larger font\n",
    "    def add_labels(rects, counts, percentages):\n",
    "        for i, (rect, count, pct) in enumerate(zip(rects, counts, percentages)):\n",
    "            # Add count inside bar\n",
    "            height = rect.get_height()\n",
    "            center_x = rect.get_x() + rect.get_width() / 2\n",
    "            \n",
    "            # Only show count inside bar if bar is tall enough\n",
    "            if height > 5:  # Only show if bar is taller than 5 units\n",
    "                ax.text(center_x, height/2, str(count),\n",
    "                      ha='center', va='center',\n",
    "                      fontsize=16, color='white')\n",
    "            else:\n",
    "                # For short bars, place count just above\n",
    "                ax.text(center_x, height + 1, str(count),\n",
    "                      ha='center', va='bottom',\n",
    "                      fontsize=16)\n",
    "            \n",
    "            # Add percentage on top with larger font\n",
    "            ax.text(center_x, height + 0.5, f'{pct:.1f}%',\n",
    "                  ha='center', va='bottom',\n",
    "                  fontsize=16)\n",
    "    \n",
    "    add_labels(rects1, hsqc_top_5_counts, hsqc_top_5_percentages)\n",
    "    add_labels(rects2, hsqc_top_1_counts, hsqc_top_1_percentages)\n",
    "    add_labels(rects3, deepseek_top_1_counts, deepseek_top_1_percentages)\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "        # Create the save path\n",
    "    save_path = \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/Figures/hsqc_deepseek_comparison.png\"\n",
    "    \n",
    "    # Save the figure with high resolution\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    print(f\"Figure saved at: {save_path}\")\n",
    "    \n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484f7b24-b37b-47a1-841f-510aceda6d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360e0501-a9b1-4e46-82ac-577d75e089a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0876da04-f292-4e93-bdc0-4d2613bbef4a",
   "metadata": {},
   "source": [
    "#### Noise Example case study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126e2f13-3324-4a18-a870-a4d89597f245",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "from typing import Dict, List, Tuple, Any\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "def load_reference_data(csv_path):\n",
    "    \"\"\"Load reference SMILES from CSV file.\"\"\"\n",
    "    ref_df = pd.read_csv(csv_path)\n",
    "    # Convert to dictionary for faster lookups\n",
    "    return ref_df.set_index('sample-id')['SMILES'].to_dict()\n",
    "\n",
    "def get_base_sample_id(sample_id):\n",
    "    \"\"\"Extract base sample ID (part before underscore).\"\"\"\n",
    "    return sample_id.split('_')[0] if sample_id else ''\n",
    "\n",
    "def process_single_json_hsqc(json_data):\n",
    "    \"\"\"Process a single JSON file and return sorted molecules by HSQC score.\"\"\"\n",
    "    try:\n",
    "        candidate_analysis = json_data[\"molecule_data\"]['candidate_analysis']\n",
    "    except KeyError:\n",
    "        return []\n",
    "    \n",
    "    all_molecules = []\n",
    "    analysis_types = ['forward_synthesis',  'mmst']\n",
    "    \n",
    "    for analysis_type in analysis_types:\n",
    "        if analysis_type in candidate_analysis:\n",
    "            molecules = candidate_analysis[analysis_type].get('molecules', [])\n",
    "            for mol in molecules:\n",
    "                try:\n",
    "                    processed_mol = {\n",
    "                        'smiles': mol['smiles'],\n",
    "                        'hsqc_score': mol.get('nmr_analysis', {}).get('matching_scores', {}).get('by_spectrum', {}).get('HSQC', None)\n",
    "                    }\n",
    "                    all_molecules.append(processed_mol)\n",
    "                except KeyError:\n",
    "                    continue\n",
    "    \n",
    "    # Sort by HSQC score\n",
    "    all_molecules.sort(key=lambda x: x['hsqc_score'] if x['hsqc_score'] is not None else float('inf'))\n",
    "    return all_molecules\n",
    "\n",
    "def analyze_llm_predictions(json_data, true_smiles, llm_name=\"deepseek\"):\n",
    "    \"\"\"\n",
    "    Analyze predictions from the LLM model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract LLM's candidates and sort by confidence\n",
    "        llm_results = json_data[\"analysis_results\"][\"final_analysis\"][\"llm_responses\"][llm_name][\"parsed_results\"]\n",
    "        candidates = llm_results[\"candidates\"]\n",
    "        \n",
    "        # Sort candidates by confidence score\n",
    "        sorted_candidates = sorted(candidates, \n",
    "                                 key=lambda x: x[\"confidence_score\"], \n",
    "                                 reverse=True)\n",
    "        \n",
    "        # Find position of correct molecule\n",
    "        correct_position = None\n",
    "        for i, cand in enumerate(sorted_candidates, 1):\n",
    "            if cand[\"smiles\"] == true_smiles:\n",
    "                correct_position = i\n",
    "                break\n",
    "        \n",
    "        return {\n",
    "            \"correct_position\": correct_position,\n",
    "            \"total_candidates\": len(sorted_candidates),\n",
    "            \"is_top_1\": correct_position == 1 if correct_position else False,\n",
    "            \"is_top_5\": correct_position is not None and correct_position <= 5\n",
    "        }\n",
    "        \n",
    "    except (KeyError, TypeError):\n",
    "        # This LLM might not have results in this file\n",
    "        return None\n",
    "\n",
    "def find_molecule_rank(molecules, true_smiles):\n",
    "    \"\"\"Find the rank of the correct molecule.\"\"\"\n",
    "    for idx, mol in enumerate(molecules, 1):\n",
    "        if mol['smiles'] == true_smiles:\n",
    "            return idx\n",
    "    return None\n",
    "\n",
    "def find_llm_corrected_molecules(json_dir, reference_csv):\n",
    "    \"\"\"\n",
    "    Find molecules where the LLM corrected the HSQC ranking in the \"Sim+Noise\" condition.\n",
    "    \n",
    "    Args:\n",
    "        json_dir: Directory containing JSON files for Sim+Noise condition\n",
    "        reference_csv: Path to reference CSV file\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries with sample ID and positions for molecules corrected by LLM\n",
    "    \"\"\"\n",
    "    # Load reference data\n",
    "    reference_data = load_reference_data(reference_csv)\n",
    "    \n",
    "    # Get all JSON files\n",
    "    json_files = glob.glob(os.path.join(json_dir, \"*.json\"))\n",
    "    print(f\"Found {len(json_files)} JSON files to analyze\")\n",
    "    \n",
    "    corrected_molecules = []\n",
    "    \n",
    "    for file_path in json_files:\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                json_data = json.load(f)\n",
    "            \n",
    "            molecule_data = json_data.get('molecule_data', {})\n",
    "            sample_id = molecule_data.get('sample_id')\n",
    "            \n",
    "            if not sample_id:\n",
    "                continue\n",
    "                \n",
    "            # Get base sample ID for reference matching\n",
    "            base_sample_id = get_base_sample_id(sample_id)\n",
    "            \n",
    "            # Get correct SMILES\n",
    "            true_smiles = reference_data.get(base_sample_id)\n",
    "            if true_smiles is None:\n",
    "                print(f\"No reference SMILES found for {base_sample_id}\")\n",
    "                continue\n",
    "            \n",
    "            # Process HSQC ranking\n",
    "            molecules = process_single_json_hsqc(json_data)\n",
    "            if not molecules:\n",
    "                continue\n",
    "                \n",
    "            hsqc_rank = find_molecule_rank(molecules, true_smiles)\n",
    "            \n",
    "            # Process DeepSeek ranking\n",
    "            deepseek_result = analyze_llm_predictions(json_data, true_smiles)\n",
    "            \n",
    "            # If both methods have results and LLM corrected HSQC\n",
    "            if (hsqc_rank is not None and \n",
    "                deepseek_result is not None and \n",
    "                deepseek_result.get(\"correct_position\") is not None):\n",
    "                \n",
    "                # Found a case where LLM corrected (HSQC not top-1, LLM is top-1)\n",
    "                if hsqc_rank != 1 and deepseek_result[\"correct_position\"] == 1:\n",
    "                    corrected_molecules.append({\n",
    "                        \"sample_id\": sample_id,\n",
    "                        \"base_sample_id\": base_sample_id,\n",
    "                        \"hsqc_rank\": hsqc_rank,\n",
    "                        \"deepseek_rank\": deepseek_result[\"correct_position\"]\n",
    "                    })\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return corrected_molecules\n",
    "\n",
    "def generate_molecule_image(smiles):\n",
    "    \"\"\"Generate an RDKit molecule object from SMILES.\"\"\"\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        return mol\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating molecule from SMILES: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def visualize_corrected_molecules_matplotlib(corrected_molecules, reference_data, max_molecules_per_fig=6):\n",
    "    \"\"\"\n",
    "    Visualize corrected molecules using Matplotlib.\n",
    "    \n",
    "    Args:\n",
    "        corrected_molecules: List of dictionaries with corrected molecule info\n",
    "        reference_data: Dictionary mapping sample IDs to SMILES\n",
    "        max_molecules_per_fig: Maximum number of molecules per figure\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with corrected molecules data\n",
    "    \"\"\"\n",
    "    total_molecules = len(corrected_molecules)\n",
    "    if total_molecules == 0:\n",
    "        print(\"No corrected molecules found.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Print summary first\n",
    "    print(f\"\\nFound {total_molecules} molecules corrected by LLM:\")\n",
    "    \n",
    "    # Create DataFrame for easier analysis\n",
    "    df = pd.DataFrame(corrected_molecules)\n",
    "    df['smiles'] = df['base_sample_id'].apply(lambda x: reference_data.get(x, ''))\n",
    "    \n",
    "    # Calculate how many figures needed\n",
    "    num_figures = (total_molecules + max_molecules_per_fig - 1) // max_molecules_per_fig\n",
    "    \n",
    "    # Create RDKit molecules list\n",
    "    mols = []\n",
    "    labels = []\n",
    "    titles = []\n",
    "    \n",
    "    for i, mol_info in enumerate(corrected_molecules):\n",
    "        base_sample_id = mol_info['base_sample_id']\n",
    "        hsqc_rank = mol_info['hsqc_rank']\n",
    "        \n",
    "        # Get SMILES\n",
    "        smiles = reference_data.get(base_sample_id)\n",
    "        if not smiles:\n",
    "            print(f\"No SMILES found for {base_sample_id}\")\n",
    "            continue\n",
    "        \n",
    "        # Generate molecule\n",
    "        mol = generate_molecule_image(smiles)\n",
    "        if mol is None:\n",
    "            print(f\"Could not generate molecule for {base_sample_id}\")\n",
    "            continue\n",
    "        \n",
    "        mols.append(mol)\n",
    "        labels.append(f\"{base_sample_id}\")\n",
    "        titles.append(f\"HSQC Rank: {hsqc_rank}  DeepSeek: 1\")\n",
    "        \n",
    "        # Print to console\n",
    "        print(f\"{i+1}. Sample ID: {base_sample_id}\")\n",
    "        print(f\"   SMILES: {smiles}\")\n",
    "        print(f\"   HSQC Rank: {hsqc_rank}  DeepSeek Rank: 1\")\n",
    "        print()\n",
    "    \n",
    "    # Plot molecules in batches\n",
    "    for fig_num in range(num_figures):\n",
    "        start_idx = fig_num * max_molecules_per_fig\n",
    "        end_idx = min(start_idx + max_molecules_per_fig, total_molecules)\n",
    "        \n",
    "        fig_mols = mols[start_idx:end_idx]\n",
    "        fig_labels = labels[start_idx:end_idx]\n",
    "        fig_titles = titles[start_idx:end_idx]\n",
    "        \n",
    "        # Calculate grid dimensions\n",
    "        if len(fig_mols) <= 3:\n",
    "            n_rows, n_cols = 1, len(fig_mols)\n",
    "        else:\n",
    "            n_rows = (len(fig_mols) + 2) // 3  # Ceiling division by 3\n",
    "            n_cols = min(3, len(fig_mols))\n",
    "        \n",
    "        # Create figure\n",
    "        fig = plt.figure(figsize=(n_cols * 5, n_rows * 5))\n",
    "        \n",
    "        for j, (mol, label, title) in enumerate(zip(fig_mols, fig_labels, fig_titles)):\n",
    "            # Create subplot\n",
    "            ax = fig.add_subplot(n_rows, n_cols, j + 1)\n",
    "            \n",
    "            # Use RDKit's MolToImage directly for this subplot\n",
    "            img = Draw.MolToImage(mol, size=(400, 300))\n",
    "            ax.imshow(img)\n",
    "            \n",
    "            # Add title and other information\n",
    "            ax.set_title(f\"{label}\\n{title}\", fontsize=12)\n",
    "            ax.axis('off')  # Turn off axis\n",
    "        \n",
    "        # Adjust layout\n",
    "        plt.tight_layout()\n",
    "        plt.suptitle(f\"Molecules Corrected by LLM (Simulated Data with Noise) - Set {fig_num+1}/{num_figures}\", \n",
    "                    fontsize=16, y=1.02)\n",
    "        \n",
    "        # Save figure\n",
    "        plt.savefig(f\"corrected_molecules_set_{fig_num+1}.png\", dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        # Show figure\n",
    "        plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\nSummary:\")\n",
    "    print(f\"Total molecules corrected: {len(df)}\")\n",
    "    print(\"\\nHSQC original rankings of corrected molecules:\")\n",
    "    print(df['hsqc_rank'].value_counts().sort_index())\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv('llm_corrected_molecules_sim_noise.csv', index=False)\n",
    "    print(\"Saved results to 'llm_corrected_molecules_sim_noise.csv'\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    # Define the paths\n",
    "    sim_noise_json_dir = \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_3_sim+noise_finished_clean\"\n",
    "    reference_csv = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "    \n",
    "    # Load reference data\n",
    "    reference_data = load_reference_data(reference_csv)\n",
    "    \n",
    "    # Find molecules corrected by LLM\n",
    "    corrected_molecules = find_llm_corrected_molecules(sim_noise_json_dir, reference_csv)\n",
    "    \n",
    "    # Visualize corrected molecules using Matplotlib\n",
    "    df = visualize_corrected_molecules_matplotlib(corrected_molecules, reference_data, max_molecules_per_fig=6)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116a3928-2b8d-44d1-b5ec-00d033e26df9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw, Descriptors, AllChem\n",
    "import numpy as np\n",
    "import io\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import pandas as pd\n",
    "\n",
    "def create_confidence_bar(width, height, confidence):\n",
    "    \"\"\"\n",
    "    Create a confidence bar image with color based on confidence score.\n",
    "    \"\"\"\n",
    "    # Create image with white background\n",
    "    bar_img = Image.new('RGB', (width, height), (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(bar_img)\n",
    "    \n",
    "    # Determine color based on confidence\n",
    "    if confidence <= 0.5:\n",
    "        # Red (1,0,0) to Yellow (1,1,0)\n",
    "        r = 255\n",
    "        g = int(confidence * 2 * 255)\n",
    "        b = 0\n",
    "    else:\n",
    "        # Yellow (1,1,0) to Green (0,0.8,0)\n",
    "        r = int((2 - confidence * 2) * 255)\n",
    "        g = 204\n",
    "        b = 0\n",
    "    \n",
    "    # Draw the colored bar\n",
    "    bar_width = int(confidence * width)\n",
    "    draw.rectangle([(0, 0), (bar_width, height)], fill=(r, g, b))\n",
    "    \n",
    "    # Add a border\n",
    "    draw.rectangle([(0, 0), (width-1, height-1)], outline=(100, 100, 100), width=2)\n",
    "    \n",
    "    return bar_img\n",
    "\n",
    "def generate_molecule_card(smiles, confidence, hsqc_error, hsqc_rank, is_correct=False, \n",
    "                          mol_size=(450, 350), card_width=520, card_height=750):\n",
    "    \"\"\"\n",
    "    Generate a card with molecule image using standard RDKit drawing.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Parse SMILES and prepare molecule\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return None\n",
    "            \n",
    "        # Calculate molecular weight\n",
    "        mol_weight = Descriptors.MolWt(mol)\n",
    "        \n",
    "        # Draw the molecule using standard RDKit drawing\n",
    "        drawer = Draw.rdMolDraw2D.MolDraw2DCairo(mol_size[0], mol_size[1])\n",
    "        drawer.SetFontSize(1.4)  # Further increase the font size for atom labels\n",
    "        drawer.DrawMolecule(mol)\n",
    "        drawer.FinishDrawing()\n",
    "        png = drawer.GetDrawingText()\n",
    "        mol_img = Image.open(io.BytesIO(png))\n",
    "        \n",
    "        # Create a new card image with white background\n",
    "        card = Image.new('RGB', (card_width, card_height), (252, 252, 252))\n",
    "        \n",
    "        # Paste the molecule image\n",
    "        card.paste(mol_img, ((card_width - mol_size[0]) // 2, 60))\n",
    "        \n",
    "        # Create and paste the confidence bar\n",
    "        conf_bar = create_confidence_bar(card_width - 80, 36, confidence)\n",
    "        card.paste(conf_bar, (40, mol_size[1] + 100))\n",
    "        \n",
    "        # Add text with Draw\n",
    "        draw = ImageDraw.Draw(card)\n",
    "        \n",
    "        # Try to load a font, fall back to default if not available\n",
    "        try:\n",
    "            title_font = ImageFont.truetype(\"arial.ttf\", 28)\n",
    "            font = ImageFont.truetype(\"arial.ttf\", 26)\n",
    "            small_font = ImageFont.truetype(\"arial.ttf\", 24)\n",
    "        except IOError:\n",
    "            try:\n",
    "                title_font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", 28)\n",
    "                font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", 26)\n",
    "                small_font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", 24)\n",
    "            except IOError:\n",
    "                title_font = ImageFont.load_default()\n",
    "                font = ImageFont.load_default()\n",
    "                small_font = ImageFont.load_default()\n",
    "        \n",
    "        # Add title with HSQC rank\n",
    "        title = f\"HSQC Rank {hsqc_rank}\"\n",
    "        if is_correct:\n",
    "            title += \" (CORRECT)\"\n",
    "        \n",
    "        # Calculate text position for center alignment\n",
    "        try:\n",
    "            title_width = draw.textlength(title, font=title_font)\n",
    "        except AttributeError:  # For older PIL versions\n",
    "            title_width = title_font.getsize(title)[0]\n",
    "            \n",
    "        title_position = ((card_width - title_width) // 2, 15)\n",
    "        \n",
    "        # Draw a background for the title\n",
    "        if is_correct:\n",
    "            draw.rectangle([(0, 0), (card_width, 55)], fill=(220, 245, 220))\n",
    "            draw.text(title_position, title, fill=(0, 100, 0), font=title_font)\n",
    "        else:\n",
    "            draw.rectangle([(0, 0), (card_width, 55)], fill=(240, 240, 245))\n",
    "            draw.text(title_position, title, fill=(50, 50, 100), font=title_font)\n",
    "        \n",
    "        # Add confidence text with larger font\n",
    "        conf_text = f\"Confidence: {confidence:.2f}\"\n",
    "        try:\n",
    "            conf_width = draw.textlength(conf_text, font=font)\n",
    "        except AttributeError:  # For older PIL versions\n",
    "            conf_width = font.getsize(conf_text)[0]\n",
    "            \n",
    "        conf_position = ((card_width - conf_width) // 2, mol_size[1] + 150)\n",
    "        draw.text(conf_position, conf_text, fill=(0, 0, 0), font=font)\n",
    "        \n",
    "        # Add HSQC error with larger font\n",
    "        error_text = f\"HSQC Error: {hsqc_error:.3f}\"\n",
    "        try:\n",
    "            error_width = draw.textlength(error_text, font=font)\n",
    "        except AttributeError:  # For older PIL versions\n",
    "            error_width = font.getsize(error_text)[0]\n",
    "            \n",
    "        error_position = ((card_width - error_width) // 2, mol_size[1] + 200)\n",
    "        draw.text(error_position, error_text, fill=(0, 0, 0), font=font)\n",
    "        \n",
    "        # Add molecular weight with larger font\n",
    "        mw_text = f\"MW: {mol_weight:.2f}\"\n",
    "        try:\n",
    "            mw_width = draw.textlength(mw_text, font=font)\n",
    "        except AttributeError:  # For older PIL versions\n",
    "            mw_width = font.getsize(mw_text)[0]\n",
    "            \n",
    "        mw_position = ((card_width - mw_width) // 2, mol_size[1] + 250)\n",
    "        draw.text(mw_position, mw_text, fill=(0, 0, 0), font=font)\n",
    "        \n",
    "        # Highlight if this is the correct structure\n",
    "        if is_correct:\n",
    "            # Draw a green border around the card\n",
    "            draw.rectangle([(0, 0), (card_width-1, card_height-1)], outline=(0, 150, 0), width=5)\n",
    "        else:\n",
    "            # Draw a subtle border\n",
    "            draw.rectangle([(0, 0), (card_width-1, card_height-1)], outline=(200, 200, 220), width=3)\n",
    "        \n",
    "        return card\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating molecule card: {e}\")\n",
    "        return None\n",
    "\n",
    "def visualize_candidates_single_row(candidates_data, title=None, \n",
    "                                   figsize=(24, 7), correct_hsqc_rank=5, filename=None):\n",
    "    \"\"\"\n",
    "    Visualize all candidate molecules in a single row.\n",
    "    \"\"\"\n",
    "    # Sort by HSQC rank\n",
    "    sorted_candidates = sorted(candidates_data, key=lambda x: x['hsqc_rank'])\n",
    "    \n",
    "    # Generate molecule cards\n",
    "    cards = []\n",
    "    for candidate in sorted_candidates:\n",
    "        is_correct = (candidate['hsqc_rank'] == correct_hsqc_rank)\n",
    "        card = generate_molecule_card(\n",
    "            candidate['smiles'],\n",
    "            candidate['confidence_score'],\n",
    "            candidate['hsqc_error'],\n",
    "            candidate['hsqc_rank'],\n",
    "            is_correct=is_correct,\n",
    "            mol_size=(450, 350),\n",
    "            card_width=520,\n",
    "            card_height=650\n",
    "        )\n",
    "        if card:\n",
    "            cards.append(card)\n",
    "    \n",
    "    if not cards:\n",
    "        print(\"No valid molecule cards generated\")\n",
    "        return None\n",
    "    \n",
    "    # Create figure with more padding between molecules\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    plt.subplots_adjust(wspace=0.4)  # Add more space between subplots\n",
    "    \n",
    "    # Calculate grid layout - single row\n",
    "    n_cols = len(cards)\n",
    "    \n",
    "    # Add each card as a subplot\n",
    "    for i, card in enumerate(cards):\n",
    "        ax = fig.add_subplot(1, n_cols, i+1)\n",
    "        ax.imshow(card)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # No title, subtitle or footer as requested\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save if filename provided\n",
    "    if filename:\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def visualize_with_grid_image(candidates_data, correct_hsqc_rank=5, filename=None):\n",
    "    \"\"\"\n",
    "    Alternative visualization using RDKit's MolsToGridImage with improved style.\n",
    "    \"\"\"\n",
    "    # Sort by HSQC rank\n",
    "    sorted_candidates = sorted(candidates_data, key=lambda x: x['hsqc_rank'])\n",
    "    \n",
    "    # Generate molecule objects\n",
    "    mols = []\n",
    "    legends = []\n",
    "    \n",
    "    for candidate in sorted_candidates:\n",
    "        mol = Chem.MolFromSmiles(candidate['smiles'])\n",
    "        if mol:\n",
    "            # Calculate molecular weight\n",
    "            mol_weight = Descriptors.MolWt(mol)\n",
    "            \n",
    "            # Generate 2D coordinates\n",
    "            AllChem.Compute2DCoords(mol)\n",
    "            \n",
    "            mols.append(mol)\n",
    "            \n",
    "            # Create legend with HSQC rank, confidence, error, and molecular weight\n",
    "            legend = f\"Rank {candidate['hsqc_rank']}\"\n",
    "            if candidate['hsqc_rank'] == correct_hsqc_rank:\n",
    "                legend += \" (CORRECT)\"\n",
    "            legend += f\"\\nConf: {candidate['confidence_score']:.2f}\"\n",
    "            legend += f\"\\nHSQC Err: {candidate['hsqc_error']:.3f}\"\n",
    "            legend += f\"\\nMW: {mol_weight:.2f}\"\n",
    "            \n",
    "            legends.append(legend)\n",
    "    \n",
    "    if not mols:\n",
    "        print(\"No valid molecules\")\n",
    "        return None\n",
    "    \n",
    "    # Create highlight colors\n",
    "    highlightAtomLists = [[] for _ in mols]\n",
    "    highlightAtomColors = [[] for _ in mols]\n",
    "    \n",
    "    # Find index of the correct molecule\n",
    "    correct_idx = None\n",
    "    for i, candidate in enumerate(sorted_candidates):\n",
    "        if candidate['hsqc_rank'] == correct_hsqc_rank:\n",
    "            correct_idx = i\n",
    "            break\n",
    "    \n",
    "    if correct_idx is not None:\n",
    "        # Highlight all atoms for the correct molecule\n",
    "        mol = mols[correct_idx]\n",
    "        atoms = list(range(mol.GetNumAtoms()))\n",
    "        highlightAtomLists[correct_idx] = atoms\n",
    "        highlightAtomColors[correct_idx] = [(0.0, 0.7, 0.0) for _ in atoms]  # Green highlight\n",
    "    \n",
    "    # Create grid image with more customization\n",
    "    grid_img = Draw.MolsToGridImage(\n",
    "        mols,\n",
    "        molsPerRow=len(mols),\n",
    "        subImgSize=(450, 400),\n",
    "        legends=legends,\n",
    "        highlightAtomLists=highlightAtomLists,\n",
    "        highlightAtomColors=highlightAtomColors,\n",
    "        useSVG=False,\n",
    "        legendFontSize=20,  # Significantly increase legend font size\n",
    "        maxMols=len(mols)\n",
    "    )\n",
    "    \n",
    "    # Convert PIL Image to numpy array for matplotlib\n",
    "    grid_array = np.array(grid_img)\n",
    "    \n",
    "    # Display with matplotlib without title\n",
    "    plt.figure(figsize=(24, 7))\n",
    "    plt.imshow(grid_array)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save if filename provided\n",
    "    if filename:\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return plt.gcf()\n",
    "\n",
    "def analyze_case_study():\n",
    "    \"\"\"\n",
    "    Create improved visualization using standard RDKit drawing.\n",
    "    \"\"\"\n",
    "    # Data for the candidate molecules\n",
    "    candidate_data = [\n",
    "        {\n",
    "            \"hsqc_rank\": 1,\n",
    "            \"smiles\": \"C=C1c2c([nH]c(C)c2CN2CCOCC2)CCC1CO\",\n",
    "            \"confidence_score\": 0.45,\n",
    "            \"hsqc_error\": 3.625\n",
    "        },\n",
    "        {\n",
    "            \"hsqc_rank\": 2,\n",
    "            \"smiles\": \"CCc1c(C)[nH]c2c1C(=O)C(CN1CCOC1)CCC2\",\n",
    "            \"confidence_score\": 0.35,\n",
    "            \"hsqc_error\": 3.933\n",
    "        },\n",
    "        {\n",
    "            \"hsqc_rank\": 3,\n",
    "            \"smiles\": \"CCc1c(C)[nH]c2c1C(=O)C(CN1CCOC1)CCC2\",\n",
    "            \"confidence_score\": 0.32,\n",
    "            \"hsqc_error\": 4.070\n",
    "        },\n",
    "        {\n",
    "            \"hsqc_rank\": 4,\n",
    "            \"smiles\": \"CCc1c(C)[nH]c2c1C(=O)C(CN1CCCOC1)CC2\",\n",
    "            \"confidence_score\": 0.50,\n",
    "            \"hsqc_error\": 4.188\n",
    "        },\n",
    "        {\n",
    "            \"hsqc_rank\": 5,  # This is the correct molecule\n",
    "            \"smiles\": \"CCc1c(C)[nH]c2c1C(=O)C(CN1CCOCC1)CC2\",\n",
    "            \"confidence_score\": 0.85,\n",
    "            \"hsqc_error\": 4.547\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Set the correct HSQC rank\n",
    "    correct_hsqc_rank = 5\n",
    "    \n",
    "    # Create improved visualization - no title \n",
    "    fig = visualize_candidates_single_row(\n",
    "        candidate_data, \n",
    "        figsize=(24, 7),\n",
    "        correct_hsqc_rank=correct_hsqc_rank,\n",
    "        filename=\"improved_case_study_molecules.png\"\n",
    "    )\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Also try the improved alternative visualization - no title\n",
    "    fig2 = visualize_with_grid_image(\n",
    "        candidate_data,\n",
    "        correct_hsqc_rank=5,\n",
    "        filename=\"improved_case_study_grid.png\"\n",
    "    )\n",
    "    \n",
    "    plt.figure(fig2.number)\n",
    "    plt.show()\n",
    "    \n",
    "    return fig, fig2\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the improved visualizations\n",
    "    analyze_case_study()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c06d09b-4f68-4d82-b4d8-151c3593a850",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw, Descriptors, AllChem, rdFMCS\n",
    "import numpy as np\n",
    "import io\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import pandas as pd\n",
    "\n",
    "def create_confidence_bar(width, height, confidence):\n",
    "    \"\"\"\n",
    "    Create a confidence bar image with color based on confidence score.\n",
    "    \"\"\"\n",
    "    # Create image with white background\n",
    "    bar_img = Image.new('RGB', (width, height), (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(bar_img)\n",
    "    \n",
    "    # Determine color based on confidence\n",
    "    if confidence <= 0.5:\n",
    "        # Red (1,0,0) to Yellow (1,1,0)\n",
    "        r = 255\n",
    "        g = int(confidence * 2 * 255)\n",
    "        b = 0\n",
    "    else:\n",
    "        # Yellow (1,1,0) to Green (0,0.8,0)\n",
    "        r = int((2 - confidence * 2) * 255)\n",
    "        g = 204\n",
    "        b = 0\n",
    "    \n",
    "    # Draw the colored bar\n",
    "    bar_width = int(confidence * width)\n",
    "    draw.rectangle([(0, 0), (bar_width, height)], fill=(r, g, b))\n",
    "    \n",
    "    # Add a border\n",
    "    draw.rectangle([(0, 0), (width-1, height-1)], outline=(100, 100, 100), width=2)\n",
    "    \n",
    "    return bar_img\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw, Descriptors, AllChem, rdFMCS, TemplateAlign\n",
    "\n",
    "def align_molecules_to_template(mols):\n",
    "    \"\"\"\n",
    "    Align 2D depictions of molecules using TemplateAlign.\n",
    "    The first molecule is used as the template.\n",
    "    \"\"\"\n",
    "    if not mols or len(mols) < 2:\n",
    "        return mols\n",
    "    \n",
    "    # Use the first molecule as template\n",
    "    template_mol = mols[0]\n",
    "    \n",
    "    # Generate 2D coordinates for the template\n",
    "    AllChem.Compute2DCoords(template_mol)\n",
    "    \n",
    "    # For each molecule (except template), align to template\n",
    "    for i in range(1, len(mols)):\n",
    "        try:\n",
    "            # Generate 2D coordinates for this molecule first\n",
    "            AllChem.Compute2DCoords(mols[i])\n",
    "            \n",
    "            # Use TemplateAlign to align to the template\n",
    "            conf_id = TemplateAlign.AlignMolToTemplate2D(mols[i], template_mol)\n",
    "            \n",
    "            if conf_id >= 0:  # A successful alignment returns a valid conformer ID\n",
    "                print(f\"Successfully aligned molecule {i} to template\")\n",
    "            else:\n",
    "                print(f\"Alignment failed for molecule {i}, using original coordinates\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error in alignment: {e}. Using basic coordinates.\")\n",
    "    \n",
    "    return mols\n",
    "\n",
    "def generate_molecule_card(smiles, confidence, hsqc_error, hsqc_rank, is_correct=False, \n",
    "                          mol_size=(450, 350), card_width=520, card_height=750,\n",
    "                          aligned_mol=None):\n",
    "    \"\"\"\n",
    "    Generate a card with molecule image using standard RDKit drawing.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Parse SMILES and prepare molecule\n",
    "        if aligned_mol is None:\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol is None:\n",
    "                return None\n",
    "            # Generate 2D coordinates\n",
    "            AllChem.Compute2DCoords(mol)\n",
    "        else:\n",
    "            mol = aligned_mol\n",
    "            \n",
    "        # Calculate molecular weight\n",
    "        mol_weight = Descriptors.MolWt(mol)\n",
    "        \n",
    "        # Draw the molecule using standard RDKit drawing\n",
    "        drawer = Draw.rdMolDraw2D.MolDraw2DCairo(mol_size[0], mol_size[1])\n",
    "        drawer.SetFontSize(1.4)  # Further increase the font size for atom labels\n",
    "        drawer.DrawMolecule(mol)\n",
    "        drawer.FinishDrawing()\n",
    "        png = drawer.GetDrawingText()\n",
    "        mol_img = Image.open(io.BytesIO(png))\n",
    "        \n",
    "        # Create a new card image with white background\n",
    "        card = Image.new('RGB', (card_width, card_height), (252, 252, 252))\n",
    "        \n",
    "        # Paste the molecule image\n",
    "        card.paste(mol_img, ((card_width - mol_size[0]) // 2, 60))\n",
    "        \n",
    "        # Create and paste the confidence bar\n",
    "        conf_bar = create_confidence_bar(card_width - 80, 36, confidence)\n",
    "        card.paste(conf_bar, (40, mol_size[1] + 100))\n",
    "        \n",
    "        # Add text with Draw\n",
    "        draw = ImageDraw.Draw(card)\n",
    "        \n",
    "        # Try to load a font, fall back to default if not available\n",
    "        try:\n",
    "            title_font = ImageFont.truetype(\"arial.ttf\", 28)\n",
    "            font = ImageFont.truetype(\"arial.ttf\", 26)\n",
    "            small_font = ImageFont.truetype(\"arial.ttf\", 24)\n",
    "        except IOError:\n",
    "            try:\n",
    "                title_font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", 28)\n",
    "                font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", 26)\n",
    "                small_font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", 24)\n",
    "            except IOError:\n",
    "                title_font = ImageFont.load_default()\n",
    "                font = ImageFont.load_default()\n",
    "                small_font = ImageFont.load_default()\n",
    "        \n",
    "        # Add title with HSQC rank\n",
    "        title = f\"HSQC Rank {hsqc_rank}\"\n",
    "        if is_correct:\n",
    "            title += \" (CORRECT)\"\n",
    "        \n",
    "        # Calculate text position for center alignment\n",
    "        try:\n",
    "            title_width = draw.textlength(title, font=title_font)\n",
    "        except AttributeError:  # For older PIL versions\n",
    "            title_width = title_font.getsize(title)[0]\n",
    "            \n",
    "        title_position = ((card_width - title_width) // 2, 15)\n",
    "        \n",
    "        # Draw a background for the title\n",
    "        if is_correct:\n",
    "            draw.rectangle([(0, 0), (card_width, 55)], fill=(220, 245, 220))\n",
    "            draw.text(title_position, title, fill=(0, 100, 0), font=title_font)\n",
    "        else:\n",
    "            draw.rectangle([(0, 0), (card_width, 55)], fill=(240, 240, 245))\n",
    "            draw.text(title_position, title, fill=(50, 50, 100), font=title_font)\n",
    "        \n",
    "        # Add confidence text with larger font\n",
    "        conf_text = f\"Confidence: {confidence:.2f}\"\n",
    "        try:\n",
    "            conf_width = draw.textlength(conf_text, font=font)\n",
    "        except AttributeError:  # For older PIL versions\n",
    "            conf_width = font.getsize(conf_text)[0]\n",
    "            \n",
    "        conf_position = ((card_width - conf_width) // 2, mol_size[1] + 150)\n",
    "        draw.text(conf_position, conf_text, fill=(0, 0, 0), font=font)\n",
    "        \n",
    "        # Add HSQC error with larger font\n",
    "        error_text = f\"HSQC Error: {hsqc_error:.3f}\"\n",
    "        try:\n",
    "            error_width = draw.textlength(error_text, font=font)\n",
    "        except AttributeError:  # For older PIL versions\n",
    "            error_width = font.getsize(error_text)[0]\n",
    "            \n",
    "        error_position = ((card_width - error_width) // 2, mol_size[1] + 200)\n",
    "        draw.text(error_position, error_text, fill=(0, 0, 0), font=font)\n",
    "        \n",
    "        # Add molecular weight with larger font\n",
    "        mw_text = f\"MW: {mol_weight:.2f}\"\n",
    "        try:\n",
    "            mw_width = draw.textlength(mw_text, font=font)\n",
    "        except AttributeError:  # For older PIL versions\n",
    "            mw_width = font.getsize(mw_text)[0]\n",
    "            \n",
    "        mw_position = ((card_width - mw_width) // 2, mol_size[1] + 250)\n",
    "        draw.text(mw_position, mw_text, fill=(0, 0, 0), font=font)\n",
    "        \n",
    "        # Highlight if this is the correct structure\n",
    "        if is_correct:\n",
    "            # Draw a green border around the card\n",
    "            draw.rectangle([(0, 0), (card_width-1, card_height-1)], outline=(0, 150, 0), width=5)\n",
    "        else:\n",
    "            # Draw a subtle border\n",
    "            draw.rectangle([(0, 0), (card_width-1, card_height-1)], outline=(200, 200, 220), width=3)\n",
    "        \n",
    "        return card\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating molecule card: {e}\")\n",
    "        return None\n",
    "\n",
    "def visualize_candidates_single_row(candidates_data, title=None, \n",
    "                                   figsize=(24, 7), correct_hsqc_rank=5, filename=None,\n",
    "                                   template_idx=None):\n",
    "    \"\"\"\n",
    "    Visualize all candidate molecules in a single row with aligned cores.\n",
    "    \"\"\"\n",
    "    # Sort by HSQC rank\n",
    "    sorted_candidates = sorted(candidates_data, key=lambda x: x['hsqc_rank'])\n",
    "    \n",
    "    # Generate molecule objects and prepare for alignment\n",
    "    mols = []\n",
    "    for candidate in sorted_candidates:\n",
    "        mol = Chem.MolFromSmiles(candidate['smiles'])\n",
    "        if mol:\n",
    "            # Make a fresh copy to avoid modification issues\n",
    "            mol = Chem.Mol(mol)\n",
    "            mols.append(mol)\n",
    "    \n",
    "    # If template_idx is specified, rearrange molecules to put template first\n",
    "    if template_idx is not None and 0 <= template_idx < len(mols):\n",
    "        # Move the specified template to the first position for alignment\n",
    "        template_mol = mols.pop(template_idx)\n",
    "        mols.insert(0, template_mol)\n",
    "        \n",
    "        # Remember to adjust candidate order too for mapping\n",
    "        template_candidate = sorted_candidates.pop(template_idx)\n",
    "        sorted_candidates.insert(0, template_candidate)\n",
    "    \n",
    "    # Align all molecules based on template\n",
    "    aligned_mols = align_molecules_to_template(mols)\n",
    "    \n",
    "    # Generate molecule cards with aligned molecules\n",
    "    cards = []\n",
    "    for i, candidate in enumerate(sorted_candidates):\n",
    "        if i < len(aligned_mols) and aligned_mols[i]:\n",
    "            is_correct = (candidate['hsqc_rank'] == correct_hsqc_rank)\n",
    "            card = generate_molecule_card(\n",
    "                candidate['smiles'],\n",
    "                candidate['confidence_score'],\n",
    "                candidate['hsqc_error'],\n",
    "                candidate['hsqc_rank'],\n",
    "                is_correct=is_correct,\n",
    "                mol_size=(450, 350),\n",
    "                card_width=520,\n",
    "                card_height=650,\n",
    "                aligned_mol=aligned_mols[i]\n",
    "            )\n",
    "            if card:\n",
    "                cards.append(card)\n",
    "    \n",
    "    if not cards:\n",
    "        print(\"No valid molecule cards generated\")\n",
    "        return None\n",
    "    \n",
    "    # Create figure with more padding between molecules\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    plt.subplots_adjust(wspace=0.4)  # Add more space between subplots\n",
    "    \n",
    "    # Calculate grid layout - single row\n",
    "    n_cols = len(cards)\n",
    "    \n",
    "    # Add each card as a subplot\n",
    "    for i, card in enumerate(cards):\n",
    "        ax = fig.add_subplot(1, n_cols, i+1)\n",
    "        ax.imshow(card)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # No title, subtitle or footer as requested\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save if filename provided\n",
    "    if filename:\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def visualize_with_grid_image(candidates_data, correct_hsqc_rank=5, filename=None, \n",
    "                             template_idx=None):\n",
    "    \"\"\"\n",
    "    Alternative visualization using RDKit's MolsToGridImage with improved style and aligned core structures.\n",
    "    \"\"\"\n",
    "    # Sort by HSQC rank\n",
    "    sorted_candidates = sorted(candidates_data, key=lambda x: x['hsqc_rank'])\n",
    "    \n",
    "    # Generate molecule objects\n",
    "    mols = []\n",
    "    for candidate in sorted_candidates:\n",
    "        mol = Chem.MolFromSmiles(candidate['smiles'])\n",
    "        if mol:\n",
    "            # Make a fresh copy\n",
    "            mol = Chem.Mol(mol)\n",
    "            mols.append(mol)\n",
    "    \n",
    "    if not mols:\n",
    "        print(\"No valid molecules\")\n",
    "        return None\n",
    "    \n",
    "    # If template_idx is specified, rearrange molecules to put template first\n",
    "    if template_idx is not None and 0 <= template_idx < len(mols):\n",
    "        # Move the specified template to the first position for alignment\n",
    "        template_mol = mols.pop(template_idx)\n",
    "        mols.insert(0, template_mol)\n",
    "        \n",
    "        # Remember to adjust candidate order too for mapping\n",
    "        template_candidate = sorted_candidates.pop(template_idx)\n",
    "        sorted_candidates.insert(0, template_candidate)\n",
    "    \n",
    "    # Align molecule cores\n",
    "    aligned_mols = align_molecules_to_template(mols)\n",
    "    \n",
    "    # Prepare legends and highlighting\n",
    "    legends = []\n",
    "    for i, candidate in enumerate(sorted_candidates):\n",
    "        if i < len(aligned_mols):\n",
    "            # Calculate molecular weight\n",
    "            mol_weight = Descriptors.MolWt(aligned_mols[i])\n",
    "            \n",
    "            # Create legend with HSQC rank, confidence, error, and molecular weight\n",
    "            legend = f\"Rank {candidate['hsqc_rank']}\"\n",
    "            if candidate['hsqc_rank'] == correct_hsqc_rank:\n",
    "                legend += \" (CORRECT)\"\n",
    "            legend += f\"\\nConf: {candidate['confidence_score']:.2f}\"\n",
    "            legend += f\"\\nHSQC Err: {candidate['hsqc_error']:.3f}\"\n",
    "            legend += f\"\\nMW: {mol_weight:.2f}\"\n",
    "            \n",
    "            legends.append(legend)\n",
    "    \n",
    "    # Create highlight colors\n",
    "    highlightAtomLists = [[] for _ in aligned_mols]\n",
    "    highlightAtomColors = [[] for _ in aligned_mols]\n",
    "    \n",
    "    # Find index of the correct molecule\n",
    "    correct_idx = None\n",
    "    for i, candidate in enumerate(sorted_candidates):\n",
    "        if candidate['hsqc_rank'] == correct_hsqc_rank and i < len(aligned_mols):\n",
    "            correct_idx = i\n",
    "            break\n",
    "    \n",
    "    if correct_idx is not None:\n",
    "        # Highlight all atoms for the correct molecule\n",
    "        mol = aligned_mols[correct_idx]\n",
    "        atoms = list(range(mol.GetNumAtoms()))\n",
    "        highlightAtomLists[correct_idx] = atoms\n",
    "        highlightAtomColors[correct_idx] = [(0.0, 0.7, 0.0) for _ in atoms]  # Green highlight\n",
    "    \n",
    "    # Create grid image with more customization\n",
    "    grid_img = Draw.MolsToGridImage(\n",
    "        aligned_mols,\n",
    "        molsPerRow=len(aligned_mols),\n",
    "        subImgSize=(450, 400),\n",
    "        legends=legends,\n",
    "        highlightAtomLists=highlightAtomLists,\n",
    "        highlightAtomColors=highlightAtomColors,\n",
    "        useSVG=False,\n",
    "        legendFontSize=20,  # Significantly increase legend font size\n",
    "        maxMols=len(aligned_mols)\n",
    "    )\n",
    "    \n",
    "    # Convert PIL Image to numpy array for matplotlib\n",
    "    grid_array = np.array(grid_img)\n",
    "    \n",
    "    # Display with matplotlib without title\n",
    "    plt.figure(figsize=(24, 7))\n",
    "    plt.imshow(grid_array)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save if filename provided\n",
    "    if filename:\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return plt.gcf()\n",
    "\n",
    "def analyze_case_study():\n",
    "    \"\"\"\n",
    "    Create improved visualization using standard RDKit drawing with aligned core structures.\n",
    "    \"\"\"\n",
    "    # Data for the candidate molecules\n",
    "    candidate_data = [\n",
    "        {\n",
    "            \"hsqc_rank\": 1,\n",
    "            \"smiles\": \"C=C1c2c([nH]c(C)c2CN2CCOCC2)CCC1CO\",\n",
    "            \"confidence_score\": 0.45,\n",
    "            \"hsqc_error\": 3.625\n",
    "        },\n",
    "        {\n",
    "            \"hsqc_rank\": 2,\n",
    "            \"smiles\": \"CCc1c(C)[nH]c2c1C(=O)C(CN1CCOC1)CCC2\",\n",
    "            \"confidence_score\": 0.35,\n",
    "            \"hsqc_error\": 3.933\n",
    "        },\n",
    "        {\n",
    "            \"hsqc_rank\": 3,\n",
    "            \"smiles\": \"CCc1c(C)[nH]c2c1C(=O)C(CN1CCOC1)CCC2\",\n",
    "            \"confidence_score\": 0.32,\n",
    "            \"hsqc_error\": 4.070\n",
    "        },\n",
    "        {\n",
    "            \"hsqc_rank\": 4,\n",
    "            \"smiles\": \"CCc1c(C)[nH]c2c1C(=O)C(CN1CCCOC1)CC2\",\n",
    "            \"confidence_score\": 0.50,\n",
    "            \"hsqc_error\": 4.188\n",
    "        },\n",
    "        {\n",
    "            \"hsqc_rank\": 5,  # This is the correct molecule\n",
    "            \"smiles\": \"CCc1c(C)[nH]c2c1C(=O)C(CN1CCOCC1)CC2\",\n",
    "            \"confidence_score\": 0.85,\n",
    "            \"hsqc_error\": 4.547\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Set the correct HSQC rank\n",
    "    correct_hsqc_rank = 5\n",
    "    \n",
    "    # Use the correct molecule (rank 5) as the template for better alignment\n",
    "    template_idx = 4  # Index of the correct molecule in sorted list (0-based)\n",
    "    \n",
    "    # Create improved visualization - no title \n",
    "    fig = visualize_candidates_single_row(\n",
    "        candidate_data, \n",
    "        figsize=(24, 7),\n",
    "        correct_hsqc_rank=correct_hsqc_rank,\n",
    "        filename=\"improved_case_study_molecules.png\",\n",
    "        template_idx=template_idx\n",
    "    )\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Also try the improved alternative visualization - no title\n",
    "    fig2 = visualize_with_grid_image(\n",
    "        candidate_data,\n",
    "        correct_hsqc_rank=5,\n",
    "        filename=\"improved_case_study_grid.png\",\n",
    "        template_idx=template_idx\n",
    "    )\n",
    "    \n",
    "    plt.figure(fig2.number)\n",
    "    plt.show()\n",
    "    \n",
    "    return fig, fig2\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the improved visualizations\n",
    "    analyze_case_study()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c0d2bd-3aa7-4b62-a648-f766cc6462fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "\n",
    "# Your molecule data\n",
    "smiles_list = [\n",
    "    \"C=C1c2c([nH]c(C)c2CN2CCOCC2)CCC1CO\",\n",
    "    \"CCc1c(C)[nH]c2c1C(=O)C(CN1CCOC1)CCC2\",\n",
    "    \"CCc1c(C)[nH]c2c1C(=O)C(CN1CCOC1)CCC2\",\n",
    "    \"CCc1c(C)[nH]c2c1C(=O)C(CN1CCCOC1)CC2\",\n",
    "    \"CCc1c(C)[nH]c2c1C(=O)C(CN1CCOCC1)CC2\"\n",
    "]\n",
    "\n",
    "# Define a template for the core structure (indole core)\n",
    "template_smiles = \"c1c([nH]c2c1CCCC2)CC\"  # Simplified core structure\n",
    "template = Chem.MolFromSmiles(template_smiles)\n",
    "AllChem.Compute2DCoords(template)\n",
    "\n",
    "# Convert SMILES to molecules and align them\n",
    "mols = []\n",
    "for smiles in smiles_list:\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    \n",
    "    # Generate initial 2D coordinates\n",
    "    AllChem.Compute2DCoords(mol)\n",
    "    \n",
    "    # Try to align with template\n",
    "    try:\n",
    "        # Find the core structure and align\n",
    "        matches = mol.GetSubstructMatches(template)\n",
    "        if matches:\n",
    "            AllChem.GenerateDepictionMatching2DStructure(mol, template)\n",
    "    except:\n",
    "        # Fallback to standard 2D coords if alignment fails\n",
    "        AllChem.Compute2DCoords(mol)\n",
    "    \n",
    "    mols.append(mol)\n",
    "\n",
    "# Drawing options\n",
    "Draw.rdDepictor.SetPreferCoordGen(True)\n",
    "drawing_options = Draw.MolDrawOptions()\n",
    "drawing_options.legendFontSize = 12\n",
    "drawing_options.bondLineWidth = 2\n",
    "\n",
    "# Create a grid of molecules with custom options\n",
    "img = Draw.MolsToGridImage(\n",
    "    mols,\n",
    "    molsPerRow=3,\n",
    "    subImgSize=(300, 300),\n",
    "    legends=[f'Molecule {i+1}' for i in range(len(mols))],\n",
    "    returnPNG=False,\n",
    "    drawOptions=drawing_options\n",
    ")\n",
    "\n",
    "# Display the grid\n",
    "img.save(\"molecule_grid_aligned.png\")  # Optional: save the image\n",
    "img  # This will display the image in Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583a98b8-363a-4bd8-a1fc-4d536cfc2d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6e8c34-33ca-4cb6-8732-d4649e1fe242",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_3_sim+noise_finished_clean/AZ10011150_noise_intermediate.json\"\n",
    "\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "process_single_json_hsqc(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65038fa5-900a-457e-b6a7-439e2ca14b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63cd43de-5844-48e1-9d4e-46439b0e1e7b",
   "metadata": {},
   "source": [
    "#### Experimental Case Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c19454-2739-4b70-aeb5-25cf45292370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "from typing import Dict, List, Tuple, Any\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "def load_reference_data(csv_path):\n",
    "    \"\"\"Load reference SMILES from CSV file.\"\"\"\n",
    "    ref_df = pd.read_csv(csv_path)\n",
    "    # Convert to dictionary for faster lookups\n",
    "    return ref_df.set_index('sample-id')['SMILES'].to_dict()\n",
    "\n",
    "def get_base_sample_id(sample_id):\n",
    "    \"\"\"Extract base sample ID (part before underscore).\"\"\"\n",
    "    return sample_id.split('_')[0] if sample_id else ''\n",
    "\n",
    "def process_single_json_hsqc(json_data):\n",
    "    \"\"\"Process a single JSON file and return sorted molecules by HSQC score.\"\"\"\n",
    "    try:\n",
    "        candidate_analysis = json_data[\"molecule_data\"]['candidate_analysis']\n",
    "    except KeyError:\n",
    "        return []\n",
    "    \n",
    "    all_molecules = []\n",
    "    analysis_types = ['forward_synthesis', \"mol2mol\", 'mmst']\n",
    "    \n",
    "    for analysis_type in analysis_types:\n",
    "        if analysis_type in candidate_analysis:\n",
    "            molecules = candidate_analysis[analysis_type].get('molecules', [])\n",
    "            for mol in molecules:\n",
    "                try:\n",
    "                    processed_mol = {\n",
    "                        'smiles': mol['smiles'],\n",
    "                        'hsqc_score': mol.get('nmr_analysis', {}).get('matching_scores', {}).get('by_spectrum', {}).get('HSQC', None)\n",
    "                    }\n",
    "                    all_molecules.append(processed_mol)\n",
    "                except KeyError:\n",
    "                    continue\n",
    "    \n",
    "    # Sort by HSQC score\n",
    "    all_molecules.sort(key=lambda x: x['hsqc_score'] if x['hsqc_score'] is not None else float('inf'))\n",
    "    return all_molecules\n",
    "\n",
    "def analyze_llm_predictions(json_data, true_smiles, llm_name=\"deepseek\"):\n",
    "    \"\"\"\n",
    "    Analyze predictions from the LLM model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract LLM's candidates and sort by confidence\n",
    "        llm_results = json_data[\"analysis_results\"][\"final_analysis\"][\"llm_responses\"][llm_name][\"parsed_results\"]\n",
    "        candidates = llm_results[\"candidates\"]\n",
    "        \n",
    "        # Sort candidates by confidence score\n",
    "        sorted_candidates = sorted(candidates, \n",
    "                                 key=lambda x: x[\"confidence_score\"], \n",
    "                                 reverse=True)\n",
    "        \n",
    "        # Find position of correct molecule\n",
    "        correct_position = None\n",
    "        for i, cand in enumerate(sorted_candidates, 1):\n",
    "            if cand[\"smiles\"] == true_smiles:\n",
    "                correct_position = i\n",
    "                break\n",
    "        \n",
    "        return {\n",
    "            \"correct_position\": correct_position,\n",
    "            \"total_candidates\": len(sorted_candidates),\n",
    "            \"is_top_1\": correct_position == 1 if correct_position else False,\n",
    "            \"is_top_5\": correct_position is not None and correct_position <= 5\n",
    "        }\n",
    "        \n",
    "    except (KeyError, TypeError):\n",
    "        # This LLM might not have results in this file\n",
    "        return None\n",
    "\n",
    "def find_molecule_rank(molecules, true_smiles):\n",
    "    \"\"\"Find the rank of the correct molecule.\"\"\"\n",
    "    for idx, mol in enumerate(molecules, 1):\n",
    "        if mol['smiles'] == true_smiles:\n",
    "            return idx\n",
    "    return None\n",
    "\n",
    "def find_llm_corrected_molecules(json_dir, reference_csv):\n",
    "    \"\"\"\n",
    "    Find molecules where the LLM corrected the HSQC ranking in the \"Sim+Noise\" condition.\n",
    "    \n",
    "    Args:\n",
    "        json_dir: Directory containing JSON files for Sim+Noise condition\n",
    "        reference_csv: Path to reference CSV file\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries with sample ID and positions for molecules corrected by LLM\n",
    "    \"\"\"\n",
    "    # Load reference data\n",
    "    reference_data = load_reference_data(reference_csv)\n",
    "    \n",
    "    # Get all JSON files\n",
    "    json_files = glob.glob(os.path.join(json_dir, \"*.json\"))\n",
    "    print(f\"Found {len(json_files)} JSON files to analyze\")\n",
    "    \n",
    "    corrected_molecules = []\n",
    "    \n",
    "    for file_path in json_files:\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                json_data = json.load(f)\n",
    "            \n",
    "            molecule_data = json_data.get('molecule_data', {})\n",
    "            sample_id = molecule_data.get('sample_id')\n",
    "            \n",
    "            if not sample_id:\n",
    "                continue\n",
    "                \n",
    "            # Get base sample ID for reference matching\n",
    "            base_sample_id = get_base_sample_id(sample_id)\n",
    "            \n",
    "            # Get correct SMILES\n",
    "            true_smiles = reference_data.get(base_sample_id)\n",
    "            if true_smiles is None:\n",
    "                print(f\"No reference SMILES found for {base_sample_id}\")\n",
    "                continue\n",
    "            \n",
    "            # Process HSQC ranking\n",
    "            molecules = process_single_json_hsqc(json_data)\n",
    "            if not molecules:\n",
    "                continue\n",
    "                \n",
    "            hsqc_rank = find_molecule_rank(molecules, true_smiles)\n",
    "            \n",
    "            # Process DeepSeek ranking\n",
    "            deepseek_result = analyze_llm_predictions(json_data, true_smiles)\n",
    "            \n",
    "            # If both methods have results and LLM corrected HSQC\n",
    "            if (hsqc_rank is not None and \n",
    "                deepseek_result is not None and \n",
    "                deepseek_result.get(\"correct_position\") is not None):\n",
    "                \n",
    "                # Found a case where LLM corrected (HSQC not top-1, LLM is top-1)\n",
    "                if hsqc_rank != 1 and deepseek_result[\"correct_position\"] == 1:\n",
    "                    corrected_molecules.append({\n",
    "                        \"sample_id\": sample_id,\n",
    "                        \"base_sample_id\": base_sample_id,\n",
    "                        \"hsqc_rank\": hsqc_rank,\n",
    "                        \"deepseek_rank\": deepseek_result[\"correct_position\"]\n",
    "                    })\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return corrected_molecules\n",
    "\n",
    "def generate_molecule_image(smiles):\n",
    "    \"\"\"Generate an RDKit molecule object from SMILES.\"\"\"\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        return mol\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating molecule from SMILES: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def visualize_corrected_molecules_matplotlib(corrected_molecules, reference_data, max_molecules_per_fig=6):\n",
    "    \"\"\"\n",
    "    Visualize corrected molecules using Matplotlib.\n",
    "    \n",
    "    Args:\n",
    "        corrected_molecules: List of dictionaries with corrected molecule info\n",
    "        reference_data: Dictionary mapping sample IDs to SMILES\n",
    "        max_molecules_per_fig: Maximum number of molecules per figure\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with corrected molecules data\n",
    "    \"\"\"\n",
    "    total_molecules = len(corrected_molecules)\n",
    "    if total_molecules == 0:\n",
    "        print(\"No corrected molecules found.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Print summary first\n",
    "    print(f\"\\nFound {total_molecules} molecules corrected by LLM:\")\n",
    "    \n",
    "    # Create DataFrame for easier analysis\n",
    "    df = pd.DataFrame(corrected_molecules)\n",
    "    df['smiles'] = df['base_sample_id'].apply(lambda x: reference_data.get(x, ''))\n",
    "    \n",
    "    # Calculate how many figures needed\n",
    "    num_figures = (total_molecules + max_molecules_per_fig - 1) // max_molecules_per_fig\n",
    "    \n",
    "    # Create RDKit molecules list\n",
    "    mols = []\n",
    "    labels = []\n",
    "    titles = []\n",
    "    \n",
    "    for i, mol_info in enumerate(corrected_molecules):\n",
    "        base_sample_id = mol_info['base_sample_id']\n",
    "        hsqc_rank = mol_info['hsqc_rank']\n",
    "        \n",
    "        # Get SMILES\n",
    "        smiles = reference_data.get(base_sample_id)\n",
    "        if not smiles:\n",
    "            print(f\"No SMILES found for {base_sample_id}\")\n",
    "            continue\n",
    "        \n",
    "        # Generate molecule\n",
    "        mol = generate_molecule_image(smiles)\n",
    "        if mol is None:\n",
    "            print(f\"Could not generate molecule for {base_sample_id}\")\n",
    "            continue\n",
    "        \n",
    "        mols.append(mol)\n",
    "        labels.append(f\"{base_sample_id}\")\n",
    "        titles.append(f\"HSQC Rank: {hsqc_rank}  DeepSeek: 1\")\n",
    "        \n",
    "        # Print to console\n",
    "        print(f\"{i+1}. Sample ID: {base_sample_id}\")\n",
    "        print(f\"   SMILES: {smiles}\")\n",
    "        print(f\"   HSQC Rank: {hsqc_rank}  DeepSeek Rank: 1\")\n",
    "        print()\n",
    "    \n",
    "    # Plot molecules in batches\n",
    "    for fig_num in range(num_figures):\n",
    "        start_idx = fig_num * max_molecules_per_fig\n",
    "        end_idx = min(start_idx + max_molecules_per_fig, total_molecules)\n",
    "        \n",
    "        fig_mols = mols[start_idx:end_idx]\n",
    "        fig_labels = labels[start_idx:end_idx]\n",
    "        fig_titles = titles[start_idx:end_idx]\n",
    "        \n",
    "        # Calculate grid dimensions\n",
    "        if len(fig_mols) <= 3:\n",
    "            n_rows, n_cols = 1, len(fig_mols)\n",
    "        else:\n",
    "            n_rows = (len(fig_mols) + 2) // 3  # Ceiling division by 3\n",
    "            n_cols = min(3, len(fig_mols))\n",
    "        \n",
    "        # Create figure\n",
    "        fig = plt.figure(figsize=(n_cols * 5, n_rows * 5))\n",
    "        \n",
    "        for j, (mol, label, title) in enumerate(zip(fig_mols, fig_labels, fig_titles)):\n",
    "            # Create subplot\n",
    "            ax = fig.add_subplot(n_rows, n_cols, j + 1)\n",
    "            \n",
    "            # Use RDKit's MolToImage directly for this subplot\n",
    "            img = Draw.MolToImage(mol, size=(400, 300))\n",
    "            ax.imshow(img)\n",
    "            \n",
    "            # Add title and other information\n",
    "            ax.set_title(f\"{label}\\n{title}\", fontsize=12)\n",
    "            ax.axis('off')  # Turn off axis\n",
    "        \n",
    "        # Adjust layout\n",
    "        plt.tight_layout()\n",
    "        plt.suptitle(f\"Molecules Corrected by LLM (Simulated Data with Noise) - Set {fig_num+1}/{num_figures}\", \n",
    "                    fontsize=16, y=1.02)\n",
    "        \n",
    "        # Save figure\n",
    "        plt.savefig(f\"corrected_molecules_set_{fig_num+1}.png\", dpi=300, bbox_inches='tight')\n",
    "        \n",
    "        # Show figure\n",
    "        plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\nSummary:\")\n",
    "    print(f\"Total molecules corrected: {len(df)}\")\n",
    "    print(\"\\nHSQC original rankings of corrected molecules:\")\n",
    "    print(df['hsqc_rank'].value_counts().sort_index())\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv('llm_corrected_molecules_sim_noise.csv', index=False)\n",
    "    print(\"Saved results to 'llm_corrected_molecules_sim_noise.csv'\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    # Define the paths\n",
    "    sim_noise_json_dir = \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_4_exp_d1_finished\"\n",
    "    reference_csv = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "    \n",
    "    # Load reference data\n",
    "    reference_data = load_reference_data(reference_csv)\n",
    "    \n",
    "    # Find molecules corrected by LLM\n",
    "    corrected_molecules = find_llm_corrected_molecules(sim_noise_json_dir, reference_csv)\n",
    "    \n",
    "    # Visualize corrected molecules using Matplotlib\n",
    "    df = visualize_corrected_molecules_matplotlib(corrected_molecules, reference_data, max_molecules_per_fig=6)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0baff3-9f57-4d0c-ac20-c7db6985a10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw, Descriptors, AllChem\n",
    "import numpy as np\n",
    "import io\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import pandas as pd\n",
    "\n",
    "def create_confidence_bar(width, height, confidence):\n",
    "    \"\"\"\n",
    "    Create a confidence bar image with color based on confidence score.\n",
    "    \"\"\"\n",
    "    # Create image with white background\n",
    "    bar_img = Image.new('RGB', (width, height), (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(bar_img)\n",
    "    \n",
    "    # Determine color based on confidence\n",
    "    if confidence <= 0.5:\n",
    "        # Red (1,0,0) to Yellow (1,1,0)\n",
    "        r = 255\n",
    "        g = int(confidence * 2 * 255)\n",
    "        b = 0\n",
    "    else:\n",
    "        # Yellow (1,1,0) to Green (0,0.8,0)\n",
    "        r = int((2 - confidence * 2) * 255)\n",
    "        g = 204\n",
    "        b = 0\n",
    "    \n",
    "    # Draw the colored bar\n",
    "    bar_width = int(confidence * width)\n",
    "    draw.rectangle([(0, 0), (bar_width, height)], fill=(r, g, b))\n",
    "    \n",
    "    # Add a border\n",
    "    draw.rectangle([(0, 0), (width-1, height-1)], outline=(100, 100, 100), width=2)\n",
    "    \n",
    "    return bar_img\n",
    "\n",
    "def generate_molecule_card(smiles, confidence, hsqc_error, hsqc_rank, is_correct=False, \n",
    "                          mol_size=(450, 350), card_width=520, card_height=750):\n",
    "    \"\"\"\n",
    "    Generate a card with molecule image using standard RDKit drawing.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Parse SMILES and prepare molecule\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return None\n",
    "            \n",
    "        # Calculate molecular weight\n",
    "        mol_weight = Descriptors.MolWt(mol)\n",
    "        \n",
    "        # Draw the molecule using standard RDKit drawing\n",
    "        drawer = Draw.rdMolDraw2D.MolDraw2DCairo(mol_size[0], mol_size[1])\n",
    "        drawer.SetFontSize(1.4)  # Further increase the font size for atom labels\n",
    "        drawer.DrawMolecule(mol)\n",
    "        drawer.FinishDrawing()\n",
    "        png = drawer.GetDrawingText()\n",
    "        mol_img = Image.open(io.BytesIO(png))\n",
    "        \n",
    "        # Create a new card image with white background\n",
    "        card = Image.new('RGB', (card_width, card_height), (252, 252, 252))\n",
    "        \n",
    "        # Paste the molecule image\n",
    "        card.paste(mol_img, ((card_width - mol_size[0]) // 2, 60))\n",
    "        \n",
    "        # Create and paste the confidence bar\n",
    "        conf_bar = create_confidence_bar(card_width - 80, 36, confidence)\n",
    "        card.paste(conf_bar, (40, mol_size[1] + 100))\n",
    "        \n",
    "        # Add text with Draw\n",
    "        draw = ImageDraw.Draw(card)\n",
    "        \n",
    "        # Try to load a font, fall back to default if not available\n",
    "        try:\n",
    "            title_font = ImageFont.truetype(\"arial.ttf\", 28)\n",
    "            font = ImageFont.truetype(\"arial.ttf\", 26)\n",
    "            small_font = ImageFont.truetype(\"arial.ttf\", 24)\n",
    "        except IOError:\n",
    "            try:\n",
    "                title_font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\", 28)\n",
    "                font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", 26)\n",
    "                small_font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", 24)\n",
    "            except IOError:\n",
    "                title_font = ImageFont.load_default()\n",
    "                font = ImageFont.load_default()\n",
    "                small_font = ImageFont.load_default()\n",
    "        \n",
    "        # Add title with HSQC rank\n",
    "        title = f\"HSQC Rank {hsqc_rank}\"\n",
    "        if is_correct:\n",
    "            title += \" (CORRECT)\"\n",
    "        \n",
    "        # Calculate text position for center alignment\n",
    "        try:\n",
    "            title_width = draw.textlength(title, font=title_font)\n",
    "        except AttributeError:  # For older PIL versions\n",
    "            title_width = title_font.getsize(title)[0]\n",
    "            \n",
    "        title_position = ((card_width - title_width) // 2, 15)\n",
    "        \n",
    "        # Draw a background for the title\n",
    "        if is_correct:\n",
    "            draw.rectangle([(0, 0), (card_width, 55)], fill=(220, 245, 220))\n",
    "            draw.text(title_position, title, fill=(0, 100, 0), font=title_font)\n",
    "        else:\n",
    "            draw.rectangle([(0, 0), (card_width, 55)], fill=(240, 240, 245))\n",
    "            draw.text(title_position, title, fill=(50, 50, 100), font=title_font)\n",
    "        \n",
    "        # Add confidence text with larger font\n",
    "        conf_text = f\"Confidence: {confidence:.2f}\"\n",
    "        try:\n",
    "            conf_width = draw.textlength(conf_text, font=font)\n",
    "        except AttributeError:  # For older PIL versions\n",
    "            conf_width = font.getsize(conf_text)[0]\n",
    "            \n",
    "        conf_position = ((card_width - conf_width) // 2, mol_size[1] + 150)\n",
    "        draw.text(conf_position, conf_text, fill=(0, 0, 0), font=font)\n",
    "        \n",
    "        # Add HSQC error with larger font\n",
    "        error_text = f\"HSQC Error: {hsqc_error:.3f}\"\n",
    "        try:\n",
    "            error_width = draw.textlength(error_text, font=font)\n",
    "        except AttributeError:  # For older PIL versions\n",
    "            error_width = font.getsize(error_text)[0]\n",
    "            \n",
    "        error_position = ((card_width - error_width) // 2, mol_size[1] + 200)\n",
    "        draw.text(error_position, error_text, fill=(0, 0, 0), font=font)\n",
    "        \n",
    "        # Add molecular weight with larger font\n",
    "        mw_text = f\"MW: {mol_weight:.2f}\"\n",
    "        try:\n",
    "            mw_width = draw.textlength(mw_text, font=font)\n",
    "        except AttributeError:  # For older PIL versions\n",
    "            mw_width = font.getsize(mw_text)[0]\n",
    "            \n",
    "        mw_position = ((card_width - mw_width) // 2, mol_size[1] + 250)\n",
    "        draw.text(mw_position, mw_text, fill=(0, 0, 0), font=font)\n",
    "        \n",
    "        # Highlight if this is the correct structure\n",
    "        if is_correct:\n",
    "            # Draw a green border around the card\n",
    "            draw.rectangle([(0, 0), (card_width-1, card_height-1)], outline=(0, 150, 0), width=5)\n",
    "        else:\n",
    "            # Draw a subtle border\n",
    "            draw.rectangle([(0, 0), (card_width-1, card_height-1)], outline=(200, 200, 220), width=3)\n",
    "        \n",
    "        return card\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating molecule card: {e}\")\n",
    "        return None\n",
    "\n",
    "def visualize_candidates_single_row(candidates_data, title=None, \n",
    "                                   figsize=(24, 7), correct_hsqc_rank=3, filename=None):\n",
    "    \"\"\"\n",
    "    Visualize all candidate molecules in a single row.\n",
    "    \"\"\"\n",
    "    # Sort by HSQC rank\n",
    "    sorted_candidates = sorted(candidates_data, key=lambda x: x['hsqc_rank'])\n",
    "    \n",
    "    # Generate molecule cards\n",
    "    cards = []\n",
    "    for candidate in sorted_candidates:\n",
    "        is_correct = (candidate['hsqc_rank'] == correct_hsqc_rank)\n",
    "        card = generate_molecule_card(\n",
    "            candidate['smiles'],\n",
    "            candidate['confidence_score'],\n",
    "            candidate['hsqc_error'],\n",
    "            candidate['hsqc_rank'],\n",
    "            is_correct=is_correct,\n",
    "            mol_size=(450, 350),\n",
    "            card_width=520,\n",
    "            card_height=650\n",
    "        )\n",
    "        if card:\n",
    "            cards.append(card)\n",
    "    \n",
    "    if not cards:\n",
    "        print(\"No valid molecule cards generated\")\n",
    "        return None\n",
    "    \n",
    "    # Create figure with more padding between molecules\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    plt.subplots_adjust(wspace=0.4)  # Add more space between subplots\n",
    "    \n",
    "    # Calculate grid layout - single row\n",
    "    n_cols = len(cards)\n",
    "    \n",
    "    # Add each card as a subplot\n",
    "    for i, card in enumerate(cards):\n",
    "        ax = fig.add_subplot(1, n_cols, i+1)\n",
    "        ax.imshow(card)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # No title, subtitle or footer as requested\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save if filename provided\n",
    "    if filename:\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def experimental_case_study():\n",
    "    \"\"\"\n",
    "    Create visualization for the experimental data case study.\n",
    "    \"\"\"\n",
    "    # Estimate HSQC error scores (since they weren't provided)\n",
    "    # These are approximate values assuming a pattern of increasing errors\n",
    "    hsqc_errors = [3.245, 3.478, 3.657, 3.802, 3.934]\n",
    "    \n",
    "    # Data for the experimental molecules\n",
    "    candidate_data = [\n",
    "        {\n",
    "            \"hsqc_rank\": 1,\n",
    "            \"smiles\": \"COc1c(C)c2c(c(O)c1CC(C)=CCCC(=O)O)C(=O)OC2\",\n",
    "            \"confidence_score\": 0.75,\n",
    "            \"hsqc_error\": hsqc_errors[0]\n",
    "        },\n",
    "        {\n",
    "            \"hsqc_rank\": 2,\n",
    "            \"smiles\": \"COc1c(C)c(O)c2c(c1CC=C(C)CCC(=O)O)COC2=O\",\n",
    "            \"confidence_score\": 0.6,\n",
    "            \"hsqc_error\": hsqc_errors[1]\n",
    "        },\n",
    "        {\n",
    "            \"hsqc_rank\": 3,  # This is the correct molecule based on highest confidence\n",
    "            \"smiles\": \"COc1c(C)c2c(c(O)c1CC=C(C)CCC(=O)O)C(=O)OC2\",\n",
    "            \"confidence_score\": 0.85,\n",
    "            \"hsqc_error\": hsqc_errors[2]\n",
    "        },\n",
    "        {\n",
    "            \"hsqc_rank\": 4,\n",
    "            \"smiles\": \"COc1c(C)c(O)c2c(c1CC=C(C)CCC(=O)O)C(=O)OC2\",\n",
    "            \"confidence_score\": 0.55,\n",
    "            \"hsqc_error\": hsqc_errors[3]\n",
    "        },\n",
    "        {\n",
    "            \"hsqc_rank\": 5,\n",
    "            \"smiles\": \"COc1c(C)c2c(c(CC=C(C)CCC(=O)O)c1O)C(=O)OC2\",\n",
    "            \"confidence_score\": 0.5,\n",
    "            \"hsqc_error\": hsqc_errors[4]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Set the correct HSQC rank based on highest confidence\n",
    "    correct_hsqc_rank = 3\n",
    "    \n",
    "    # Create visualization \n",
    "    fig = visualize_candidates_single_row(\n",
    "        candidate_data, \n",
    "        figsize=(24, 7),\n",
    "        correct_hsqc_rank=correct_hsqc_rank,\n",
    "        filename=\"experimental_case_study.png\"\n",
    "    )\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the visualization for experimental data\n",
    "    experimental_case_study()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30066873-8af6-4c97-b432-8626c7dfd5d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f09800d7-05df-4bd5-9409-12e2f63aa712",
   "metadata": {},
   "source": [
    "## Plot Confidence:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622e9b92-7749-4b1c-bab6-3eb597a5d095",
   "metadata": {},
   "source": [
    "### V1 Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b278231d-8955-47c6-864a-3346c57a4319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "import random\n",
    "from scipy import stats\n",
    "\n",
    "# Set the style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"deep\")\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Define the models with their characteristics\n",
    "models = [\n",
    "    {\"name\": \"Claude 3.5 Sonnet\", \"accuracy\": 0.79, \"confidence_range\": [0.65, 0.90], \"color\": \"#6366F1\"},\n",
    "    {\"name\": \"Claude 3.7 Sonnet-Thinking\", \"accuracy\": 0.89, \"confidence_range\": [0.70, 0.95], \"color\": \"#3B82F6\"},\n",
    "    {\"name\": \"DeepSeek-R1\", \"accuracy\": 0.87, \"confidence_range\": [0.65, 0.92], \"color\": \"#10B981\"},\n",
    "    {\"name\": \"Gemini-Thinking\", \"accuracy\": 0.86, \"confidence_range\": [0.60, 0.88], \"color\": \"#F59E0B\"},\n",
    "    {\"name\": \"o3-mini\", \"accuracy\": 0.85, \"confidence_range\": [0.65, 0.90], \"color\": \"#EC4899\"},\n",
    "    {\"name\": \"Kimi 1.5\", \"accuracy\": 0.84, \"confidence_range\": [0.60, 0.85], \"color\": \"#8B5CF6\"}\n",
    "]\n",
    "\n",
    "# Function to generate dummy data for each model\n",
    "def generate_model_data(model, n_samples=150):\n",
    "    np.random.seed(42 + models.index(model))  # Different seed for each model but reproducible\n",
    "    \n",
    "    # Calculate number of correct and incorrect predictions based on model accuracy\n",
    "    n_correct = int(n_samples * model[\"accuracy\"])\n",
    "    n_incorrect = n_samples - n_correct\n",
    "    \n",
    "    # Generate confidence scores for correct predictions (generally higher)\n",
    "    correct_confidence = np.clip(\n",
    "        np.random.normal(\n",
    "            loc=model[\"confidence_range\"][1] - 0.05,  # Mean near the high end of range\n",
    "            scale=0.12,                               # Standard deviation\n",
    "            size=n_correct\n",
    "        ),\n",
    "        0.0, 1.0  # Clip to valid range\n",
    "    )\n",
    "    \n",
    "    # Generate confidence scores for incorrect predictions (generally lower)\n",
    "    incorrect_confidence = np.clip(\n",
    "        np.random.normal(\n",
    "            loc=model[\"confidence_range\"][0] + 0.10,  # Mean near the low end of range\n",
    "            scale=0.15,                               # Standard deviation with more variance\n",
    "            size=n_incorrect\n",
    "        ),\n",
    "        0.0, 1.0  # Clip to valid range\n",
    "    )\n",
    "    \n",
    "    # Create DataFrames for correct and incorrect predictions\n",
    "    correct_df = pd.DataFrame({\n",
    "        'model': model[\"name\"],\n",
    "        'confidence': correct_confidence,\n",
    "        'correct': True,\n",
    "        'color': model[\"color\"]\n",
    "    })\n",
    "    \n",
    "    incorrect_df = pd.DataFrame({\n",
    "        'model': model[\"name\"],\n",
    "        'confidence': incorrect_confidence,\n",
    "        'correct': False,\n",
    "        'color': model[\"color\"]\n",
    "    })\n",
    "    \n",
    "    # Combine the DataFrames\n",
    "    combined_df = pd.concat([correct_df, incorrect_df])\n",
    "    \n",
    "    # Calculate correlation coefficient between confidence and correctness\n",
    "    correlation = np.corrcoef(combined_df['confidence'], combined_df['correct'].astype(int))[0, 1]\n",
    "    \n",
    "    return combined_df, correlation\n",
    "\n",
    "# Generate data for all models\n",
    "all_data = []\n",
    "correlations = []\n",
    "for model in models:\n",
    "    model_data, correlation = generate_model_data(model)\n",
    "    all_data.append(model_data)\n",
    "    correlations.append({'model': model[\"name\"], 'correlation': correlation, 'color': model[\"color\"]})\n",
    "\n",
    "# Combine all the model data\n",
    "full_dataset = pd.concat(all_data)\n",
    "correlations_df = pd.DataFrame(correlations)\n",
    "\n",
    "# Sort the models by correlation for display\n",
    "correlations_df = correlations_df.sort_values('correlation', ascending=False)\n",
    "model_order = correlations_df['model'].tolist()\n",
    "\n",
    "# Prepare data for grouped bar chart\n",
    "grouped_stats = []\n",
    "for model in models:\n",
    "    model_data = full_dataset[full_dataset['model'] == model[\"name\"]]\n",
    "    \n",
    "    # For correct predictions\n",
    "    correct_data = model_data[model_data['correct']]\n",
    "    correct_mean = correct_data['confidence'].mean()\n",
    "    correct_std = correct_data['confidence'].std()\n",
    "    \n",
    "    # For incorrect predictions\n",
    "    incorrect_data = model_data[~model_data['correct']]\n",
    "    incorrect_mean = incorrect_data['confidence'].mean()\n",
    "    incorrect_std = incorrect_data['confidence'].std()\n",
    "    \n",
    "    grouped_stats.append({\n",
    "        'model': model[\"name\"],\n",
    "        'correct_mean': correct_mean,\n",
    "        'correct_std': correct_std,\n",
    "        'incorrect_mean': incorrect_mean,\n",
    "        'incorrect_std': incorrect_std,\n",
    "        'color': model[\"color\"],\n",
    "        'correlation': correlations_df[correlations_df['model'] == model[\"name\"]]['correlation'].values[0]\n",
    "    })\n",
    "\n",
    "# Create DataFrame for the stats\n",
    "stats_df = pd.DataFrame(grouped_stats)\n",
    "stats_df = stats_df.sort_values('correlation', ascending=False)\n",
    "\n",
    "# Create the figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8), gridspec_kw={'width_ratios': [1.5, 1]})\n",
    "\n",
    "# Width of the bars\n",
    "bar_width = 0.35\n",
    "\n",
    "# Set positions for bars\n",
    "r1 = np.arange(len(model_order))\n",
    "r2 = [x + bar_width for x in r1]\n",
    "\n",
    "# Create bar chart with standard deviation error bars\n",
    "correct_bars = ax1.bar(r1, stats_df['correct_mean'], width=bar_width, \n",
    "                       yerr=stats_df['correct_std'], capsize=5, \n",
    "                       color=[stats_df[stats_df['model'] == model]['color'].values[0] for model in model_order],\n",
    "                       alpha=0.7, label='Correct Predictions')\n",
    "\n",
    "incorrect_bars = ax1.bar(r2, stats_df['incorrect_mean'], width=bar_width, \n",
    "                        yerr=stats_df['incorrect_std'], capsize=5, \n",
    "                        color=[stats_df[stats_df['model'] == model]['color'].values[0] for model in model_order],\n",
    "                        alpha=0.3, hatch='///', label='Incorrect Predictions')\n",
    "\n",
    "# Add individual data points as scatter\n",
    "for i, model in enumerate(model_order):\n",
    "    model_data = full_dataset[full_dataset['model'] == model]\n",
    "    \n",
    "    # Get correct predictions and add jitter to x-position\n",
    "    correct_data = model_data[model_data['correct']]\n",
    "    jitter = np.random.normal(0, 0.05, size=len(correct_data))\n",
    "    ax1.scatter(r1[i] + jitter, correct_data['confidence'], \n",
    "                color=correct_data['color'].iloc[0], alpha=0.4, s=20)\n",
    "    \n",
    "    # Get incorrect predictions and add jitter to x-position\n",
    "    incorrect_data = model_data[~model_data['correct']]\n",
    "    jitter = np.random.normal(0, 0.05, size=len(incorrect_data))\n",
    "    ax1.scatter(r2[i] + jitter, incorrect_data['confidence'], \n",
    "                color=incorrect_data['color'].iloc[0], alpha=0.4, s=20, marker='x')\n",
    "\n",
    "# Customize bar chart\n",
    "ax1.set_xlabel('Model', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Confidence Score', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('LLM Confidence Scores for Correct vs. Incorrect Predictions', fontsize=14, fontweight='bold')\n",
    "ax1.set_xticks([r + bar_width/2 for r in range(len(model_order))])\n",
    "ax1.set_xticklabels([model.replace(' ', '\\n') for model in model_order], rotation=0)\n",
    "ax1.set_ylim([0, 1.1])\n",
    "ax1.legend(loc='upper right')\n",
    "\n",
    "# Add correlation coefficients above each model\n",
    "for i, model in enumerate(model_order):\n",
    "    corr = stats_df[stats_df['model'] == model]['correlation'].values[0]\n",
    "    ax1.text(i + bar_width/2, 1.03, f'r = {corr:.2f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Create a secondary plot for correlation coefficients\n",
    "correlation_bars = ax2.bar(range(len(model_order)), \n",
    "                          stats_df['correlation'],\n",
    "                          color=stats_df['color'])\n",
    "\n",
    "# Add standard error indicators for correlations (simulated for visualization)\n",
    "# In a real scenario, you would calculate actual confidence intervals\n",
    "np.random.seed(42)\n",
    "corr_errors = np.random.uniform(0.03, 0.08, size=len(model_order))\n",
    "ax2.errorbar(range(len(model_order)), stats_df['correlation'], yerr=corr_errors, \n",
    "             fmt='none', color='black', capsize=5)\n",
    "\n",
    "# Customize correlation chart\n",
    "ax2.set_xlabel('Model', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Correlation Coefficient (r)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Confidence-Accuracy Correlation by Model', fontsize=14, fontweight='bold')\n",
    "ax2.set_xticks(range(len(model_order)))\n",
    "ax2.set_xticklabels([model.split(' ')[0] for model in model_order], rotation=45, ha='right')\n",
    "ax2.set_ylim([0, 1.0])\n",
    "\n",
    "# Add values above bars\n",
    "for i, v in enumerate(stats_df['correlation']):\n",
    "    ax2.text(i, v + 0.03, f'{v:.2f}', ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Add horizontal lines to mark correlation strength thresholds\n",
    "ax2.axhline(y=0.7, color='green', linestyle='--', alpha=0.5, linewidth=1)\n",
    "ax2.axhline(y=0.5, color='orange', linestyle='--', alpha=0.5, linewidth=1)\n",
    "ax2.text(len(model_order)-1, 0.72, 'Strong', ha='right', va='bottom', color='green', fontsize=10)\n",
    "ax2.text(len(model_order)-1, 0.52, 'Moderate', ha='right', va='bottom', color='orange', fontsize=10)\n",
    "\n",
    "# Add annotation for reasoning models vs. standard\n",
    "ax2.annotate('Reasoning-specialized models', xy=(1.5, 0.85), xytext=(2, 0.9),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05, width=1.5, headwidth=8),\n",
    "            ha='center', va='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax2.annotate('Standard LLM', xy=(5, 0.61), xytext=(4.5, 0.45),\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05, width=1.5, headwidth=8),\n",
    "            ha='center', va='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "fig.subplots_adjust(bottom=0.15)\n",
    "\n",
    "# Add caption as figure text\n",
    "fig.text(0.5, 0.01, \n",
    "         \"Figure 7: Comparison of LLM confidence scores across different models. Left: Mean confidence scores for correct (solid) and incorrect (hatched) predictions, with individual predictions shown as scattered points. Right: Correlation coefficients between confidence scores and actual prediction accuracy, showing reasoning-specialized models (Claude 3.7 Sonnet-Thinking, DeepSeek-R1, etc.) demonstrate stronger confidence-accuracy correlation than standard LLMs.\", \n",
    "         ha='center', fontsize=10, style='italic', wrap=True)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('llm_confidence_correlation.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021b5245-7e57-4561-895f-4fc40ea6b038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6aebb8-c676-47af-808c-19aa8f582bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# Set the style for a clean, professional look\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"deep\")\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Define the experimental conditions with descriptive names\n",
    "experimental_conditions = [\n",
    "    {\"name\": \"Simulated Data\", \"color\": \"#10B981\", \"short_name\": \"Sim\"},\n",
    "    {\"name\": \"Simulated Data + Wrong Guess\", \"color\": \"#3B82F6\", \"short_name\": \"Sim+WG\"},\n",
    "    {\"name\": \"Simulated Data + Noise\", \"color\": \"#6366F1\", \"short_name\": \"Sim+Noise\"},\n",
    "    {\"name\": \"Experimental Data\", \"color\": \"#F59E0B\", \"short_name\": \"Exp\"},\n",
    "    {\"name\": \"Experimental Data + Wrong Guess\", \"color\": \"#EC4899\", \"short_name\": \"Exp+WG\"},\n",
    "    {\"name\": \"Experimental Data d4\", \"color\": \"#8B5CF6\", \"short_name\": \"Exp-d4\"}\n",
    "]\n",
    "\n",
    "# Function to generate dummy confidence data for DeepSeek-R1 across different conditions\n",
    "def generate_dummy_data(conditions, n_samples=30):\n",
    "    all_data = []\n",
    "    correlations = []\n",
    "    \n",
    "    # Define different characteristics for each condition to make the visualization interesting\n",
    "    condition_params = {\n",
    "        \"Simulated Data\": {\"acc\": 0.94, \"corr\": 0.82, \"correct_conf\": (0.80, 0.10), \"incorrect_conf\": (0.45, 0.15)},\n",
    "        \"Simulated Data + Wrong Guess\": {\"acc\": 0.85, \"corr\": 0.76, \"correct_conf\": (0.75, 0.12), \"incorrect_conf\": (0.50, 0.15)},\n",
    "        \"Simulated Data + Noise\": {\"acc\": 0.85, \"corr\": 0.74, \"correct_conf\": (0.70, 0.15), \"incorrect_conf\": (0.48, 0.18)},\n",
    "        \"Experimental Data\": {\"acc\": 0.68, \"corr\": 0.69, \"correct_conf\": (0.68, 0.15), \"incorrect_conf\": (0.42, 0.18)},\n",
    "        \"Experimental Data + Wrong Guess\": {\"acc\": 0.24, \"corr\": 0.58, \"correct_conf\": (0.60, 0.18), \"incorrect_conf\": (0.45, 0.20)},\n",
    "        \"Experimental Data d4\": {\"acc\": 0.65, \"corr\": 0.66, \"correct_conf\": (0.65, 0.18), \"incorrect_conf\": (0.40, 0.20)}\n",
    "    }\n",
    "    \n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    \n",
    "    for i, condition in enumerate(conditions):\n",
    "        params = condition_params[condition[\"name\"]]\n",
    "        \n",
    "        # Calculate number of correct and incorrect predictions based on accuracy\n",
    "        n_correct = int(n_samples * params[\"acc\"])\n",
    "        n_incorrect = n_samples - n_correct\n",
    "        \n",
    "        # Generate confidence scores for correct predictions\n",
    "        correct_conf_mean, correct_conf_std = params[\"correct_conf\"]\n",
    "        correct_confidence = np.clip(\n",
    "            np.random.normal(loc=correct_conf_mean, scale=correct_conf_std, size=n_correct),\n",
    "            0.0, 1.0  # Clip to valid range\n",
    "        )\n",
    "        \n",
    "        # Generate confidence scores for incorrect predictions\n",
    "        incorrect_conf_mean, incorrect_conf_std = params[\"incorrect_conf\"]\n",
    "        incorrect_confidence = np.clip(\n",
    "            np.random.normal(loc=incorrect_conf_mean, scale=incorrect_conf_std, size=n_incorrect),\n",
    "            0.0, 1.0  # Clip to valid range\n",
    "        )\n",
    "        \n",
    "        # Create DataFrames for correct and incorrect predictions\n",
    "        correct_df = pd.DataFrame({\n",
    "            'condition': condition[\"name\"],\n",
    "            'short_name': condition[\"short_name\"],\n",
    "            'confidence': correct_confidence,\n",
    "            'correct': True,\n",
    "            'color': condition[\"color\"]\n",
    "        })\n",
    "        \n",
    "        incorrect_df = pd.DataFrame({\n",
    "            'condition': condition[\"name\"],\n",
    "            'short_name': condition[\"short_name\"],\n",
    "            'confidence': incorrect_confidence,\n",
    "            'correct': False,\n",
    "            'color': condition[\"color\"]\n",
    "        })\n",
    "        \n",
    "        # Combine the DataFrames\n",
    "        condition_df = pd.concat([correct_df, incorrect_df])\n",
    "        all_data.append(condition_df)\n",
    "        \n",
    "        # Calculate correlation coefficient between confidence and correctness\n",
    "        # In real data analysis, you would use the actual confidence scores and correctness\n",
    "        correlations.append({\n",
    "            'condition': condition[\"name\"],\n",
    "            'short_name': condition[\"short_name\"],\n",
    "            'correlation': params[\"corr\"],  # Using predefined correlation for dummy data\n",
    "            'color': condition[\"color\"],\n",
    "            'accuracy': params[\"acc\"]\n",
    "        })\n",
    "    \n",
    "    # Combine all data\n",
    "    combined_df = pd.concat(all_data)\n",
    "    correlations_df = pd.DataFrame(correlations)\n",
    "    \n",
    "    return combined_df, correlations_df\n",
    "\n",
    "# Generate dummy data\n",
    "full_dataset, correlations_df = generate_dummy_data(experimental_conditions)\n",
    "\n",
    "# Calculate statistics for bar chart\n",
    "grouped_stats = []\n",
    "for condition in experimental_conditions:\n",
    "    condition_data = full_dataset[full_dataset['condition'] == condition[\"name\"]]\n",
    "    \n",
    "    # For correct predictions\n",
    "    correct_data = condition_data[condition_data['correct']]\n",
    "    correct_mean = correct_data['confidence'].mean() if len(correct_data) > 0 else 0\n",
    "    correct_std = correct_data['confidence'].std() if len(correct_data) > 0 else 0\n",
    "    \n",
    "    # For incorrect predictions\n",
    "    incorrect_data = condition_data[~condition_data['correct']]\n",
    "    incorrect_mean = incorrect_data['confidence'].mean() if len(incorrect_data) > 0 else 0\n",
    "    incorrect_std = incorrect_data['confidence'].std() if len(incorrect_data) > 0 else 0\n",
    "    \n",
    "    # Add to stats\n",
    "    grouped_stats.append({\n",
    "        'condition': condition[\"name\"],\n",
    "        'short_name': condition[\"short_name\"],\n",
    "        'correct_mean': correct_mean,\n",
    "        'correct_std': correct_std,\n",
    "        'incorrect_mean': incorrect_mean,\n",
    "        'incorrect_std': incorrect_std,\n",
    "        'color': condition[\"color\"],\n",
    "        'correlation': correlations_df[correlations_df['condition'] == condition[\"name\"]]['correlation'].values[0],\n",
    "        'accuracy': correlations_df[correlations_df['condition'] == condition[\"name\"]]['accuracy'].values[0]\n",
    "    })\n",
    "\n",
    "# Create DataFrame for the stats\n",
    "stats_df = pd.DataFrame(grouped_stats)\n",
    "\n",
    "# Create figure with gridspec for flexible layout\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "gs = gridspec.GridSpec(2, 2, width_ratios=[2, 1], height_ratios=[4, 1])\n",
    "\n",
    "# Main confidence score plot (top left)\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "\n",
    "# Bar width and positions\n",
    "bar_width = 0.35\n",
    "r1 = np.arange(len(experimental_conditions))\n",
    "r2 = [x + bar_width for x in r1]\n",
    "\n",
    "# Create bars for correct and incorrect predictions\n",
    "correct_bars = ax1.bar(r1, stats_df['correct_mean'], width=bar_width, \n",
    "                       yerr=stats_df['correct_std'], capsize=5, \n",
    "                       color=stats_df['color'],\n",
    "                       alpha=0.7, label='Correct Predictions')\n",
    "\n",
    "incorrect_bars = ax1.bar(r2, stats_df['incorrect_mean'], width=bar_width, \n",
    "                        yerr=stats_df['incorrect_std'], capsize=5, \n",
    "                        color=stats_df['color'],\n",
    "                        alpha=0.3, hatch='///', label='Incorrect Predictions')\n",
    "\n",
    "# Add individual data points as scatter\n",
    "for i, condition in enumerate(experimental_conditions):\n",
    "    condition_data = full_dataset[full_dataset['condition'] == condition[\"name\"]]\n",
    "    \n",
    "    # Get correct predictions and add jitter to x-position\n",
    "    correct_data = condition_data[condition_data['correct']]\n",
    "    if len(correct_data) > 0:\n",
    "        jitter = np.random.normal(0, 0.05, size=len(correct_data))\n",
    "        ax1.scatter(r1[i] + jitter, correct_data['confidence'], \n",
    "                    color=correct_data['color'].iloc[0], alpha=0.4, s=30)\n",
    "    \n",
    "    # Get incorrect predictions and add jitter to x-position\n",
    "    incorrect_data = condition_data[~condition_data['correct']]\n",
    "    if len(incorrect_data) > 0:\n",
    "        jitter = np.random.normal(0, 0.05, size=len(incorrect_data))\n",
    "        ax1.scatter(r2[i] + jitter, incorrect_data['confidence'], \n",
    "                    color=incorrect_data['color'].iloc[0], alpha=0.4, s=30, marker='x')\n",
    "\n",
    "# Customize confidence score plot\n",
    "ax1.set_xlabel('Experimental Condition', fontsize=13, fontweight='bold')\n",
    "ax1.set_ylabel('DeepSeek-R1 Confidence Score', fontsize=13, fontweight='bold')\n",
    "ax1.set_title('DeepSeek-R1 Confidence Scores Across Experimental Conditions', fontsize=16, fontweight='bold')\n",
    "ax1.set_xticks([r + bar_width/2 for r in range(len(experimental_conditions))])\n",
    "ax1.set_xticklabels([c[\"short_name\"] for c in experimental_conditions], rotation=0, fontsize=12)\n",
    "ax1.set_ylim([0, 1.05])\n",
    "ax1.legend(loc='upper right', fontsize=12)\n",
    "\n",
    "# Add correlation coefficients above each condition\n",
    "for i, condition in enumerate(experimental_conditions):\n",
    "    corr = stats_df[stats_df['condition'] == condition[\"name\"]]['correlation'].values[0]\n",
    "    ax1.text(i + bar_width/2, 1.0, f'r = {corr:.2f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Correlation plot (top right)\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "\n",
    "# Create correlation bars\n",
    "correlation_bars = ax2.bar(range(len(experimental_conditions)), \n",
    "                          stats_df['correlation'],\n",
    "                          color=stats_df['color'])\n",
    "\n",
    "# Add confidence intervals (simulated for dummy data)\n",
    "np.random.seed(42)\n",
    "corr_errors = np.random.uniform(0.03, 0.08, size=len(experimental_conditions))\n",
    "ax2.errorbar(range(len(experimental_conditions)), stats_df['correlation'], yerr=corr_errors, \n",
    "             fmt='none', color='black', capsize=5)\n",
    "\n",
    "# Customize correlation plot\n",
    "ax2.set_xlabel('Condition', fontsize=13, fontweight='bold')\n",
    "ax2.set_ylabel('Confidence-Accuracy\\nCorrelation (r)', fontsize=13, fontweight='bold')\n",
    "ax2.set_title('DeepSeek-R1 Confidence-Accuracy\\nCorrelation by Condition', fontsize=16, fontweight='bold')\n",
    "ax2.set_xticks(range(len(experimental_conditions)))\n",
    "ax2.set_xticklabels([c[\"short_name\"] for c in experimental_conditions], rotation=45, ha='right', fontsize=12)\n",
    "ax2.set_ylim([0, 1.0])\n",
    "\n",
    "# Add values above bars\n",
    "for i, v in enumerate(stats_df['correlation']):\n",
    "    ax2.text(i, v + 0.03, f'{v:.2f}', ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Add horizontal reference lines\n",
    "ax2.axhline(y=0.7, color='green', linestyle='--', alpha=0.5, linewidth=1)\n",
    "ax2.axhline(y=0.5, color='orange', linestyle='--', alpha=0.5, linewidth=1)\n",
    "ax2.text(len(experimental_conditions)-1, 0.72, 'Strong', ha='right', va='bottom', color='green', fontsize=10)\n",
    "ax2.text(len(experimental_conditions)-1, 0.52, 'Moderate', ha='right', va='bottom', color='orange', fontsize=10)\n",
    "\n",
    "# Accuracy subplot (bottom spanning both columns)\n",
    "ax3 = fig.add_subplot(gs[1, :])\n",
    "\n",
    "# Create accuracy bars\n",
    "accuracy_bars = ax3.bar(range(len(experimental_conditions)), \n",
    "                      stats_df['accuracy'] * 100,  # Convert to percentage\n",
    "                      color=stats_df['color'],\n",
    "                      alpha=0.8)\n",
    "\n",
    "# Customize accuracy plot\n",
    "ax3.set_xlabel('Experimental Condition', fontsize=13, fontweight='bold')\n",
    "ax3.set_ylabel('Accuracy (%)', fontsize=13, fontweight='bold')\n",
    "ax3.set_title('DeepSeek-R1 Structure Prediction Accuracy by Condition', fontsize=14, fontweight='bold')\n",
    "ax3.set_xticks(range(len(experimental_conditions)))\n",
    "ax3.set_xticklabels([c[\"name\"] for c in experimental_conditions], rotation=45, ha='right', fontsize=11)\n",
    "ax3.set_ylim([0, 100])\n",
    "\n",
    "# Add percentage labels above bars\n",
    "for i, v in enumerate(stats_df['accuracy']):\n",
    "    ax3.text(i, v * 100 + 3, f'{v*100:.1f}%', ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Add a horizontal reference line at 50%\n",
    "ax3.axhline(y=50, color='red', linestyle='--', alpha=0.5, linewidth=1)\n",
    "ax3.text(0, 52, 'Random Guess (50%)', ha='left', va='bottom', color='red', fontsize=10)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(h_pad=2, w_pad=3)\n",
    "\n",
    "# Add caption\n",
    "fig.text(0.5, 0.01, \n",
    "        \"Figure X: Analysis of DeepSeek-R1's confidence scoring across experimental conditions. Top left: Mean confidence scores for correct (solid) and incorrect (hatched) predictions, with individual predictions shown as scattered points and correlation coefficients (r) displayed above each condition. Top right: Confidence-accuracy correlation coefficients with error bars. Bottom: Structure prediction accuracy across conditions, showing the model's performance degradation from simulated to experimental data, particularly with wrong initial guesses.\",\n",
    "        ha='center', fontsize=11, style='italic', wrap=True)\n",
    "\n",
    "# Save the figure with high resolution\n",
    "plt.savefig('deepseek_confidence_analysis.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f336d3b-096d-429e-b481-851e47e2bedf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b61cbf7-0abe-4748-b79a-b33471db8d96",
   "metadata": {},
   "source": [
    "### V2 Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cae10a8-df0a-4e2a-9d15-49ae3175164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Function to load reference data\n",
    "def load_reference_data(csv_path):\n",
    "    \"\"\"Load reference SMILES from CSV file.\"\"\"\n",
    "    ref_df = pd.read_csv(csv_path)\n",
    "    # Convert to dictionary for faster lookups\n",
    "    return ref_df.set_index('sample-id')['SMILES'].to_dict()\n",
    "\n",
    "# Function to extract base sample ID (before underscore)\n",
    "def get_base_sample_id(sample_id):\n",
    "    \"\"\"Extract base sample ID (part before underscore).\"\"\"\n",
    "    return sample_id.split('_')[0] if sample_id else ''\n",
    "\n",
    "# Function to analyze a single JSON file\n",
    "def analyze_json_file(file_path, reference_data):\n",
    "    \"\"\"\n",
    "    Analyze confidence scores from a single JSON file.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the JSON file\n",
    "        reference_data: Dictionary mapping sample IDs to true SMILES\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing analysis results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load JSON data\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Extract sample ID and get true SMILES\n",
    "        sample_id = data.get(\"molecule_data\", {}).get(\"sample_id\")\n",
    "        if not sample_id:\n",
    "            return None\n",
    "            \n",
    "        base_sample_id = get_base_sample_id(sample_id)\n",
    "        true_smiles = reference_data.get(base_sample_id)\n",
    "        \n",
    "        if true_smiles is None:\n",
    "            return None\n",
    "        \n",
    "        # Get DeepSeek results\n",
    "        deepseek_results = data.get(\"final_analysis\", {}).get(\"llm_responses\", {}).get(\"deepseek\", {})\n",
    "        if not deepseek_results or \"parsed_results\" not in deepseek_results:\n",
    "            return None\n",
    "            \n",
    "        # Get candidates and their confidence scores\n",
    "        candidates = deepseek_results[\"parsed_results\"].get(\"candidates\", [])\n",
    "        if not candidates:\n",
    "            return None\n",
    "        \n",
    "        # Sort candidates by confidence score (highest first)\n",
    "        sorted_candidates = sorted(candidates, key=lambda x: x.get(\"confidence_score\", 0), reverse=True)\n",
    "        \n",
    "        # Get the top candidate (highest confidence)\n",
    "        top_candidate = sorted_candidates[0]\n",
    "        top_candidate_smiles = top_candidate.get(\"smiles\")\n",
    "        top_confidence = top_candidate.get(\"confidence_score\", 0)\n",
    "        \n",
    "        # Check if top candidate is correct\n",
    "        is_correct = (top_candidate_smiles == true_smiles)\n",
    "        \n",
    "        # Find position of correct molecule in candidate list (if present)\n",
    "        correct_position = None\n",
    "        correct_confidence = None\n",
    "        \n",
    "        for i, candidate in enumerate(sorted_candidates, 1):\n",
    "            if candidate.get(\"smiles\") == true_smiles:\n",
    "                correct_position = i\n",
    "                correct_confidence = candidate.get(\"confidence_score\", 0)\n",
    "                break\n",
    "        \n",
    "        # Get experiment type from directory name\n",
    "        dir_name = os.path.basename(os.path.dirname(file_path))\n",
    "        if \"sim+noise\" in dir_name.lower():\n",
    "            experiment = \"Sim Data + Noise\"\n",
    "        elif \"sim_aug\" in dir_name.lower() or \"sim_d1_aug\" in dir_name.lower():\n",
    "            experiment = \"Sim Data + Wrong Guess\"\n",
    "        elif \"sim\" in dir_name.lower():\n",
    "            experiment = \"Sim Data\"\n",
    "        elif \"exp_d1_aug\" in dir_name.lower():\n",
    "            experiment = \"Exp Data + Wrong Guess\"\n",
    "        elif \"exp_d4\" in dir_name.lower():\n",
    "            experiment = \"Exp Data d4\"\n",
    "        elif \"exp\" in dir_name.lower():\n",
    "            experiment = \"Exp Data\"\n",
    "        else:\n",
    "            experiment = \"Unknown\"\n",
    "        \n",
    "        # Create confidence scores for all candidates\n",
    "        all_confidences = []\n",
    "        for i, candidate in enumerate(sorted_candidates):\n",
    "            is_true = (candidate.get(\"smiles\") == true_smiles)\n",
    "            all_confidences.append({\n",
    "                \"position\": i + 1,\n",
    "                \"confidence\": candidate.get(\"confidence_score\", 0),\n",
    "                \"is_true\": is_true,\n",
    "                \"smiles\": candidate.get(\"smiles\")\n",
    "            })\n",
    "            \n",
    "        return {\n",
    "            \"sample_id\": sample_id,\n",
    "            \"true_smiles\": true_smiles,\n",
    "            \"experiment\": experiment,\n",
    "            \"top_candidate_smiles\": top_candidate_smiles,\n",
    "            \"top_confidence\": top_confidence,\n",
    "            \"is_correct\": is_correct,\n",
    "            \"correct_position\": correct_position,\n",
    "            \"correct_confidence\": correct_confidence,\n",
    "            \"all_confidences\": all_confidences\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Function to process a directory of JSON files\n",
    "def process_directory(json_dir, reference_csv):\n",
    "    \"\"\"\n",
    "    Process all JSON files in a directory.\n",
    "    \n",
    "    Args:\n",
    "        json_dir: Directory containing JSON files\n",
    "        reference_csv: Path to reference CSV file\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with analysis results\n",
    "    \"\"\"\n",
    "    # Load reference data\n",
    "    reference_data = load_reference_data(reference_csv)\n",
    "    \n",
    "    # Find all JSON files\n",
    "    json_files = glob.glob(os.path.join(json_dir, \"*.json\"))\n",
    "    print(f\"Found {len(json_files)} JSON files to analyze\")\n",
    "    \n",
    "    # Process each file\n",
    "    results = []\n",
    "    all_confidences = []\n",
    "    \n",
    "    for file_path in json_files:\n",
    "        result = analyze_json_file(file_path, reference_data)\n",
    "        if result:\n",
    "            results.append(result)\n",
    "            \n",
    "            # Extract confidence scores for all candidates\n",
    "            for conf_data in result[\"all_confidences\"]:\n",
    "                all_confidences.append({\n",
    "                    \"sample_id\": result[\"sample_id\"],\n",
    "                    \"experiment\": result[\"experiment\"],\n",
    "                    \"position\": conf_data[\"position\"],\n",
    "                    \"confidence\": conf_data[\"confidence\"],\n",
    "                    \"is_true\": conf_data[\"is_true\"],\n",
    "                    \"smiles\": conf_data[\"smiles\"]\n",
    "                })\n",
    "    \n",
    "    # Convert to DataFrames\n",
    "    results_df = pd.DataFrame(results)\n",
    "    confidences_df = pd.DataFrame(all_confidences)\n",
    "    \n",
    "    return results_df, confidences_df\n",
    "\n",
    "# Function to create violin plots of confidence distributions\n",
    "def plot_confidence_distributions(results_df, output_file=None):\n",
    "    \"\"\"\n",
    "    Create violin plots showing confidence score distributions.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with analysis results\n",
    "        output_file: Path to save the figure (if None, display it)\n",
    "    \"\"\"\n",
    "    # Set up the figure\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Create a DataFrame for plotting\n",
    "    plot_data = []\n",
    "    \n",
    "    # For correct predictions (model's top pick was correct)\n",
    "    correct_preds = results_df[results_df[\"is_correct\"] == True]\n",
    "    for _, row in correct_preds.iterrows():\n",
    "        plot_data.append({\n",
    "            \"experiment\": row[\"experiment\"],\n",
    "            \"confidence\": row[\"top_confidence\"],\n",
    "            \"prediction\": \"Correct\"\n",
    "        })\n",
    "    \n",
    "    # For incorrect predictions (model's top pick was wrong)\n",
    "    incorrect_preds = results_df[results_df[\"is_correct\"] == False]\n",
    "    for _, row in incorrect_preds.iterrows():\n",
    "        plot_data.append({\n",
    "            \"experiment\": row[\"experiment\"],\n",
    "            \"confidence\": row[\"top_confidence\"],\n",
    "            \"prediction\": \"Incorrect\"\n",
    "        })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    plot_df = pd.DataFrame(plot_data)\n",
    "    \n",
    "    # Create the violin plot\n",
    "    ax = sns.violinplot(x=\"experiment\", y=\"confidence\", hue=\"prediction\", \n",
    "                    data=plot_df, split=True, inner=\"quartile\",\n",
    "                    palette={\"Correct\": \"mediumseagreen\", \"Incorrect\": \"tomato\"})\n",
    "    \n",
    "    # Add individual data points\n",
    "    sns.stripplot(x=\"experiment\", y=\"confidence\", hue=\"prediction\", \n",
    "               data=plot_df, dodge=True, alpha=0.3, size=4, linewidth=1,\n",
    "               palette={\"Correct\": \"darkgreen\", \"Incorrect\": \"darkred\"})\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title(\"DeepSeek-R1 Confidence Scores by Prediction Correctness\", fontsize=16)\n",
    "    plt.xlabel(\"Experimental Condition\", fontsize=14)\n",
    "    plt.ylabel(\"Confidence Score\", fontsize=14)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Create legend without duplicate items\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    plt.legend(handles[:2], labels[:2], title=\"Prediction\", fontsize=12)\n",
    "    \n",
    "    # Add text with statistics for each experiment\n",
    "    for i, exp in enumerate(plot_df[\"experiment\"].unique()):\n",
    "        exp_data = plot_df[plot_df[\"experiment\"] == exp]\n",
    "        correct_data = exp_data[exp_data[\"prediction\"] == \"Correct\"]\n",
    "        incorrect_data = exp_data[exp_data[\"prediction\"] == \"Incorrect\"]\n",
    "        \n",
    "        n_correct = len(correct_data)\n",
    "        n_incorrect = len(incorrect_data)\n",
    "        total = n_correct + n_incorrect\n",
    "        \n",
    "        avg_correct = correct_data[\"confidence\"].mean() if len(correct_data) > 0 else 0\n",
    "        avg_incorrect = incorrect_data[\"confidence\"].mean() if len(incorrect_data) > 0 else 0\n",
    "        \n",
    "        text = f\"n={total}\\nCorrect: {n_correct} ({n_correct/total*100:.1f}%)\\nIncorrect: {n_incorrect} ({n_incorrect/total*100:.1f}%)\"\n",
    "        plt.text(i, 0.05, text, ha='center', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save or display the figure\n",
    "    if output_file:\n",
    "        plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# Function to create a histogram comparing confidence scores\n",
    "def plot_confidence_histogram(results_df, output_file=None):\n",
    "    \"\"\"\n",
    "    Create a histogram showing confidence score distributions.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with analysis results\n",
    "        output_file: Path to save the figure (if None, display it)\n",
    "    \"\"\"\n",
    "    # Set up the figure\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Create separate data for correct and incorrect predictions\n",
    "    correct_preds = results_df[results_df[\"is_correct\"] == True][\"top_confidence\"]\n",
    "    incorrect_preds = results_df[results_df[\"is_correct\"] == False][\"top_confidence\"]\n",
    "    \n",
    "    # Create the histogram\n",
    "    bins = np.linspace(0, 1, 21)  # 20 bins from 0 to 1\n",
    "    \n",
    "    plt.hist(correct_preds, bins=bins, alpha=0.7, color='mediumseagreen', \n",
    "             label=f'Correct Predictions (n={len(correct_preds)})')\n",
    "    plt.hist(incorrect_preds, bins=bins, alpha=0.7, color='tomato', \n",
    "             label=f'Incorrect Predictions (n={len(incorrect_preds)})')\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title(\"Distribution of DeepSeek-R1 Confidence Scores by Prediction Correctness\", fontsize=16)\n",
    "    plt.xlabel(\"Confidence Score\", fontsize=14)\n",
    "    plt.ylabel(\"Frequency\", fontsize=14)\n",
    "    plt.grid(linestyle='--', alpha=0.7)\n",
    "    plt.legend(fontsize=12)\n",
    "    \n",
    "    # Calculate and display statistics\n",
    "    mean_correct = correct_preds.mean() if len(correct_preds) > 0 else 0\n",
    "    mean_incorrect = incorrect_preds.mean() if len(incorrect_preds) > 0 else 0\n",
    "    \n",
    "    stats_text = (\n",
    "        f\"Mean confidence when correct: {mean_correct:.3f}\\n\"\n",
    "        f\"Mean confidence when incorrect: {mean_incorrect:.3f}\\n\"\n",
    "        f\"Difference: {mean_correct - mean_incorrect:.3f}\"\n",
    "    )\n",
    "    \n",
    "    plt.text(0.05, 0.95, stats_text, transform=plt.gca().transAxes, \n",
    "             verticalalignment='top', fontsize=12,\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save or display the figure\n",
    "    if output_file:\n",
    "        plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# Function to create a boxplot showing confidence by position\n",
    "\n",
    "def plot_confidence_by_position(confidences_df, output_file=None):\n",
    "    \"\"\"\n",
    "    Create a boxplot showing confidence scores by position.\n",
    "    \n",
    "    Args:\n",
    "        confidences_df: DataFrame with confidence scores\n",
    "        output_file: Path to save the figure (if None, display it)\n",
    "    \"\"\"\n",
    "    # Limit to first 5 positions\n",
    "    df = confidences_df[confidences_df[\"position\"] <= 5].copy()\n",
    "    \n",
    "    # Convert boolean is_true to string to avoid palette issues\n",
    "    df['is_true'] = df['is_true'].astype(str)\n",
    "    \n",
    "    # Set up the figure\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    \n",
    "    # Create the boxplot\n",
    "    ax = sns.boxplot(x=\"position\", y=\"confidence\", hue=\"is_true\", \n",
    "                 data=df, palette={\"True\": \"mediumseagreen\", \"False\": \"tomato\"})\n",
    "    \n",
    "    # Add individual data points\n",
    "    sns.stripplot(x=\"position\", y=\"confidence\", hue=\"is_true\", \n",
    "               data=df, dodge=True, alpha=0.3, size=4, linewidth=1,\n",
    "               palette={\"True\": \"darkgreen\", \"False\": \"darkred\"})\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title(\"DeepSeek-R1 Confidence Scores by Candidate Position\", fontsize=16)\n",
    "    plt.xlabel(\"Candidate Position (by confidence ranking)\", fontsize=14)\n",
    "    plt.ylabel(\"Confidence Score\", fontsize=14)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Create legend without duplicate items\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    plt.legend(handles[:2], [\"Correct Structure\", \"Incorrect Structure\"], title=\"Structure\", fontsize=12)\n",
    "    \n",
    "    # Add text with count statistics for each position\n",
    "    for i in range(1, 6):\n",
    "        pos_data = df[df[\"position\"] == i]\n",
    "        true_data = pos_data[pos_data[\"is_true\"] == \"True\"]\n",
    "        false_data = pos_data[pos_data[\"is_true\"] == \"False\"]\n",
    "        \n",
    "        n_true = len(true_data)\n",
    "        n_false = len(false_data)\n",
    "        total = n_true + n_false\n",
    "        \n",
    "        text = f\"n={total}\\nCorrect: {n_true}\\nIncorrect: {n_false}\"\n",
    "        plt.text(i-1, 0.05, text, ha='center', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save or display the figure\n",
    "    if output_file:\n",
    "        plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# Function to calculate and plot ROC curve for different confidence thresholds\n",
    "def plot_roc_curve(results_df, output_file=None):\n",
    "    \"\"\"\n",
    "    Create an ROC curve for different confidence thresholds.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with analysis results\n",
    "        output_file: Path to save the figure (if None, display it)\n",
    "    \"\"\"\n",
    "    # Set up the figure\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Calculate ROC curve points\n",
    "    thresholds = np.linspace(0, 1, 101)  # 101 points from 0 to 1\n",
    "    tpr_list = []  # True Positive Rate (sensitivity)\n",
    "    fpr_list = []  # False Positive Rate (1 - specificity)\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        # Number of positive examples\n",
    "        positives = len(results_df[results_df[\"is_correct\"] == True])\n",
    "        # Number of negative examples\n",
    "        negatives = len(results_df[results_df[\"is_correct\"] == False])\n",
    "        \n",
    "        # True positives: correct predictions with confidence >= threshold\n",
    "        tp = len(results_df[(results_df[\"is_correct\"] == True) & \n",
    "                           (results_df[\"top_confidence\"] >= threshold)])\n",
    "        \n",
    "        # False positives: incorrect predictions with confidence >= threshold\n",
    "        fp = len(results_df[(results_df[\"is_correct\"] == False) & \n",
    "                           (results_df[\"top_confidence\"] >= threshold)])\n",
    "        \n",
    "        # Calculate rates\n",
    "        tpr = tp / positives if positives > 0 else 0  # Sensitivity\n",
    "        fpr = fp / negatives if negatives > 0 else 0  # 1 - Specificity\n",
    "        \n",
    "        tpr_list.append(tpr)\n",
    "        fpr_list.append(fpr)\n",
    "    \n",
    "    # Plot the ROC curve\n",
    "    plt.plot(fpr_list, tpr_list, 'b-', linewidth=2)\n",
    "    \n",
    "    # Add the diagonal reference line (random classifier)\n",
    "    plt.plot([0, 1], [0, 1], 'r--', linewidth=1.5)\n",
    "    \n",
    "    # Calculate AUC (Area Under Curve)\n",
    "    auc = 0\n",
    "    for i in range(len(fpr_list) - 1):\n",
    "        auc += (fpr_list[i+1] - fpr_list[i]) * (tpr_list[i+1] + tpr_list[i]) / 2\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title(f\"ROC Curve for DeepSeek-R1 Confidence Scores\\nAUC = {auc:.3f}\", fontsize=16)\n",
    "    plt.xlabel(\"False Positive Rate (1 - Specificity)\", fontsize=14)\n",
    "    plt.ylabel(\"True Positive Rate (Sensitivity)\", fontsize=14)\n",
    "    plt.grid(linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add threshold indicators for notable points\n",
    "    for t in [0.3, 0.5, 0.7, 0.9]:\n",
    "        idx = int(t * 100)\n",
    "        plt.plot(fpr_list[idx], tpr_list[idx], 'ko', markersize=6)\n",
    "        plt.text(fpr_list[idx]+0.02, tpr_list[idx]-0.02, f\"t={t}\", fontsize=10)\n",
    "    \n",
    "    # Add statistics table\n",
    "    stats_data = []\n",
    "    for t in [0.3, 0.5, 0.7, 0.9]:\n",
    "        correct_above = len(results_df[(results_df[\"is_correct\"] == True) & \n",
    "                                     (results_df[\"top_confidence\"] >= t)])\n",
    "        incorrect_above = len(results_df[(results_df[\"is_correct\"] == False) & \n",
    "                                       (results_df[\"top_confidence\"] >= t)])\n",
    "        correct_below = len(results_df[(results_df[\"is_correct\"] == True) & \n",
    "                                     (results_df[\"top_confidence\"] < t)])\n",
    "        incorrect_below = len(results_df[(results_df[\"is_correct\"] == False) & \n",
    "                                       (results_df[\"top_confidence\"] < t)])\n",
    "        \n",
    "        total_above = correct_above + incorrect_above\n",
    "        precision = correct_above / total_above if total_above > 0 else 0\n",
    "        \n",
    "        stats_data.append({\n",
    "            \"threshold\": t,\n",
    "            \"correct_above\": correct_above,\n",
    "            \"incorrect_above\": incorrect_above,\n",
    "            \"precision\": precision\n",
    "        })\n",
    "    \n",
    "    stats_table = pd.DataFrame(stats_data)\n",
    "    table_text = \"Threshold statistics:\\n\"\n",
    "    for _, row in stats_table.iterrows():\n",
    "        table_text += f\"t={row['threshold']:.1f}: {row['correct_above']} correct, {row['incorrect_above']} incorrect above threshold (precision: {row['precision']:.2f})\\n\"\n",
    "    \n",
    "    plt.text(0.05, 0.05, table_text, transform=plt.gca().transAxes, \n",
    "             verticalalignment='bottom', fontsize=10,\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save or display the figure\n",
    "    if output_file:\n",
    "        plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# Function to create an experiment-specific confidence visualization\n",
    "def plot_experiment_confidence(results_df, output_file=None):\n",
    "    \"\"\"\n",
    "    Create a detailed visualization of confidence scores by experiment.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with analysis results\n",
    "        output_file: Path to save the figure (if None, display it)\n",
    "    \"\"\"\n",
    "    # Set up the figure\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12), sharex=True, sharey=True)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Set the color palette\n",
    "    experiment_colors = {\n",
    "        \"Sim Data\": \"#10B981\",\n",
    "        \"Sim Data + Wrong Guess\": \"#3B82F6\",\n",
    "        \"Sim Data + Noise\": \"#6366F1\",\n",
    "        \"Exp Data\": \"#F59E0B\",\n",
    "        \"Exp Data + Wrong Guess\": \"#EC4899\",\n",
    "        \"Exp Data d4\": \"#8B5CF6\"\n",
    "    }\n",
    "    \n",
    "    # Process each experiment\n",
    "    experiments = results_df[\"experiment\"].unique()\n",
    "    \n",
    "    for i, exp in enumerate(experiments):\n",
    "        if i >= len(axes):\n",
    "            break\n",
    "            \n",
    "        ax = axes[i]\n",
    "        exp_data = results_df[results_df[\"experiment\"] == exp]\n",
    "        \n",
    "        # Separate correct and incorrect predictions\n",
    "        correct_preds = exp_data[exp_data[\"is_correct\"] == True][\"top_confidence\"]\n",
    "        incorrect_preds = exp_data[exp_data[\"is_correct\"] == False][\"top_confidence\"]\n",
    "        \n",
    "        # Create the histogram\n",
    "        bins = np.linspace(0, 1, 21)  # 20 bins from 0 to 1\n",
    "        \n",
    "        ax.hist(correct_preds, bins=bins, alpha=0.7, color=experiment_colors[exp], \n",
    "                label=f'Correct (n={len(correct_preds)})')\n",
    "        ax.hist(incorrect_preds, bins=bins, alpha=0.5, hatch='///', color=experiment_colors[exp], \n",
    "                label=f'Incorrect (n={len(incorrect_preds)})')\n",
    "        \n",
    "        # Calculate statistics\n",
    "        mean_correct = correct_preds.mean() if len(correct_preds) > 0 else 0\n",
    "        mean_incorrect = incorrect_preds.mean() if len(incorrect_preds) > 0 else 0\n",
    "        \n",
    "        # Calculate suggested threshold for this experiment\n",
    "        if len(correct_preds) > 0 and len(incorrect_preds) > 0:\n",
    "            # Simple approach: average of the means\n",
    "            suggested_threshold = (mean_correct + mean_incorrect) / 2\n",
    "        else:\n",
    "            suggested_threshold = 0.5\n",
    "        \n",
    "        # Add vertical line for suggested threshold\n",
    "        ax.axvline(x=suggested_threshold, color='red', linestyle='--', linewidth=1.5)\n",
    "        \n",
    "        # Calculate accuracy at suggested threshold\n",
    "        correct_above = len(exp_data[(exp_data[\"is_correct\"] == True) & \n",
    "                                  (exp_data[\"top_confidence\"] >= suggested_threshold)])\n",
    "        correct_below = len(exp_data[(exp_data[\"is_correct\"] == True) & \n",
    "                                  (exp_data[\"top_confidence\"] < suggested_threshold)])\n",
    "        incorrect_above = len(exp_data[(exp_data[\"is_correct\"] == False) & \n",
    "                                    (exp_data[\"top_confidence\"] >= suggested_threshold)])\n",
    "        incorrect_below = len(exp_data[(exp_data[\"is_correct\"] == False) & \n",
    "                                    (exp_data[\"top_confidence\"] < suggested_threshold)])\n",
    "        \n",
    "        total = len(exp_data)\n",
    "        accuracy = (correct_above + incorrect_below) / total if total > 0 else 0\n",
    "        \n",
    "        # Add statistics text\n",
    "        stats_text = (\n",
    "            f\"Mean conf. (correct): {mean_correct:.2f}\\n\"\n",
    "            f\"Mean conf. (incorrect): {mean_incorrect:.2f}\\n\"\n",
    "            f\"Suggested threshold: {suggested_threshold:.2f}\\n\"\n",
    "            f\"Acc @ threshold: {accuracy:.2f}\"\n",
    "        )\n",
    "        \n",
    "        ax.text(0.05, 0.95, stats_text, transform=ax.transAxes, \n",
    "                verticalalignment='top', fontsize=10,\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "        \n",
    "        # Customize the plot\n",
    "        ax.set_title(exp, fontsize=14)\n",
    "        ax.grid(linestyle='--', alpha=0.7)\n",
    "        ax.legend(fontsize=10)\n",
    "        \n",
    "        # Calculate and display separation score (area between distributions)\n",
    "        # This is a simplified measure of how well the confidence scores separate correct from incorrect\n",
    "        if len(correct_preds) > 0 and len(incorrect_preds) > 0:\n",
    "            # Use difference in means normalized by pooled standard deviation (Cohen's d)\n",
    "            std_correct = correct_preds.std()\n",
    "            std_incorrect = incorrect_preds.std()\n",
    "            pooled_std = np.sqrt((std_correct**2 + std_incorrect**2) / 2)\n",
    "            \n",
    "            if pooled_std > 0:\n",
    "                cohens_d = abs(mean_correct - mean_incorrect) / pooled_std\n",
    "                separation_text = f\"Separation score: {cohens_d:.2f}\"\n",
    "                ax.text(0.95, 0.05, separation_text, transform=ax.transAxes, \n",
    "                        horizontalalignment='right', verticalalignment='bottom', fontsize=10,\n",
    "                        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Set common labels\n",
    "    fig.text(0.5, 0.02, 'Confidence Score', ha='center', fontsize=14)\n",
    "    fig.text(0.02, 0.5, 'Frequency', va='center', rotation='vertical', fontsize=14)\n",
    "    \n",
    "    fig.suptitle(\"DeepSeek-R1 Confidence Score Distributions by Experimental Condition\", fontsize=18)\n",
    "    \n",
    "    plt.tight_layout(rect=[0.03, 0.03, 1, 0.97])\n",
    "    \n",
    "    # Save or display the figure\n",
    "    if output_file:\n",
    "        plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# Main function to run the analysis\n",
    "def main(use_dummy_data=False):\n",
    "    \"\"\"\n",
    "    Run the complete analysis.\n",
    "    \n",
    "    Args:\n",
    "        use_dummy_data: If True, use generated dummy data instead of processing JSON files\n",
    "    \"\"\"\n",
    "    if use_dummy_data:\n",
    "        print(\"Generating dummy data for visualization testing...\")\n",
    "        combined_results, combined_confidences = create_dummy_data()\n",
    "        \n",
    "    else:\n",
    "        # Define input and output paths\n",
    "        json_dirs = [\n",
    "            \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_1_sim_finished_clean\",\n",
    "            \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_2_sim_aug_finished_clean\",\n",
    "            \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_3_sim+noise_finished_clean\",\n",
    "            \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_4_exp_d1_finished_clean\",\n",
    "            \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_5_exp_d1_aug_finished_clean\",\n",
    "            \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_6_exp_d4_finished_clean\"\n",
    "        ]\n",
    "        \n",
    "        reference_csv = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        \n",
    "        # Process each directory and combine results\n",
    "        all_results = []\n",
    "        all_confidences = []\n",
    "        \n",
    "        for json_dir in json_dirs:\n",
    "            print(f\"Processing {json_dir}...\")\n",
    "            results_df, confidences_df = process_directory(json_dir, reference_csv)\n",
    "            \n",
    "            if not results_df.empty:\n",
    "                all_results.append(results_df)\n",
    "                all_confidences.append(confidences_df)\n",
    "        \n",
    "        # Combine all results\n",
    "        combined_results = pd.concat(all_results) if all_results else pd.DataFrame()\n",
    "        combined_confidences = pd.concat(all_confidences) if all_confidences else pd.DataFrame()\n",
    "    \n",
    "    if combined_results.empty:\n",
    "        print(\"No valid results found.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Analyzing {len(combined_results)} items...\")\n",
    "    \n",
    "    # Generate and save the plots\n",
    "    print(\"Generating confidence distribution plots...\")\n",
    "    plot_confidence_distributions(combined_results, \"deepseek_confidence_distributions.png\")\n",
    "    \n",
    "    print(\"Generating confidence histogram...\")\n",
    "    plot_confidence_histogram(combined_results, \"deepseek_confidence_histogram.png\")\n",
    "    \n",
    "    print(\"Generating confidence by position plot...\")\n",
    "    plot_confidence_by_position(combined_confidences, \"deepseek_confidence_by_position.png\")\n",
    "    \n",
    "    print(\"Generating ROC curve...\")\n",
    "    plot_roc_curve(combined_results, \"deepseek_confidence_roc.png\")\n",
    "    \n",
    "    print(\"Generating experimental condition analysis...\")\n",
    "    plot_experiment_confidence(combined_results, \"deepseek_experiment_confidence.png\")\n",
    "    \n",
    "    print(\"Analysis complete. All plots have been saved.\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Use dummy data for testing\n",
    "    # main(use_dummy_data=True)\n",
    "    \n",
    "    # Or use actual JSON files\n",
    "    main(use_dummy_data=False)\n",
    "\n",
    "# Function to create dummy data for testing visualizations\n",
    "def create_dummy_data():\n",
    "    \"\"\"Create dummy data for testing visualizations when JSON files aren't available.\"\"\"\n",
    "    # Define experimental conditions\n",
    "    experiments = [\n",
    "        \"Sim Data\",\n",
    "        \"Sim Data + Wrong Guess\",\n",
    "        \"Sim Data + Noise\",\n",
    "        \"Exp Data\",\n",
    "        \"Exp Data + Wrong Guess\",\n",
    "        \"Exp Data d4\"\n",
    "    ]\n",
    "    \n",
    "    # Define accuracy and mean confidence for each condition\n",
    "    condition_params = {\n",
    "        \"Sim Data\": {\"acc\": 0.94, \"correct_conf\": (0.80, 0.10), \"incorrect_conf\": (0.45, 0.15)},\n",
    "        \"Sim Data + Wrong Guess\": {\"acc\": 0.85, \"correct_conf\": (0.75, 0.12), \"incorrect_conf\": (0.50, 0.15)},\n",
    "        \"Sim Data + Noise\": {\"acc\": 0.85, \"correct_conf\": (0.70, 0.15), \"incorrect_conf\": (0.48, 0.18)},\n",
    "        \"Exp Data\": {\"acc\": 0.68, \"correct_conf\": (0.68, 0.15), \"incorrect_conf\": (0.42, 0.18)},\n",
    "        \"Exp Data + Wrong Guess\": {\"acc\": 0.24, \"correct_conf\": (0.60, 0.18), \"incorrect_conf\": (0.45, 0.20)},\n",
    "        \"Exp Data d4\": {\"acc\": 0.65, \"correct_conf\": (0.65, 0.18), \"incorrect_conf\": (0.40, 0.20)}\n",
    "    }\n",
    "    \n",
    "    # Generate data\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    \n",
    "    results = []\n",
    "    all_confidences = []\n",
    "    \n",
    "    for exp in experiments:\n",
    "        params = condition_params[exp]\n",
    "        \n",
    "        # Generate 50 samples for each experiment\n",
    "        n_samples = 50\n",
    "        n_correct = int(n_samples * params[\"acc\"])\n",
    "        n_incorrect = n_samples - n_correct\n",
    "        \n",
    "        # Generate confidence scores for correct predictions\n",
    "        correct_conf_mean, correct_conf_std = params[\"correct_conf\"]\n",
    "        correct_confidences = np.clip(\n",
    "            np.random.normal(loc=correct_conf_mean, scale=correct_conf_std, size=n_correct),\n",
    "            0.0, 1.0  # Clip to valid range\n",
    "        )\n",
    "        \n",
    "        # Generate confidence scores for incorrect predictions\n",
    "        incorrect_conf_mean, incorrect_conf_std = params[\"incorrect_conf\"]\n",
    "        incorrect_confidences = np.clip(\n",
    "            np.random.normal(loc=incorrect_conf_mean, scale=incorrect_conf_std, size=n_incorrect),\n",
    "            0.0, 1.0  # Clip to valid range\n",
    "        )\n",
    "        \n",
    "        # Generate sample IDs\n",
    "        base_id = exp.replace(\" \", \"_\").lower()\n",
    "        \n",
    "        # Add correct predictions\n",
    "        for i in range(n_correct):\n",
    "            sample_id = f\"{base_id}_{i+1}\"\n",
    "            \n",
    "            # Generate dummy SMILES\n",
    "            true_smiles = f\"C1CC{i}CC1\"\n",
    "            pred_smiles = true_smiles  # For correct predictions, they're the same\n",
    "            \n",
    "            results.append({\n",
    "                \"sample_id\": sample_id,\n",
    "                \"true_smiles\": true_smiles,\n",
    "                \"experiment\": exp,\n",
    "                \"top_candidate_smiles\": pred_smiles,\n",
    "                \"top_confidence\": correct_confidences[i],\n",
    "                \"is_correct\": True,\n",
    "                \"correct_position\": 1,\n",
    "                \"correct_confidence\": correct_confidences[i]\n",
    "            })\n",
    "            \n",
    "            # Add confidences for top 5 positions\n",
    "            all_confidences.append({\n",
    "                \"sample_id\": sample_id,\n",
    "                \"experiment\": exp,\n",
    "                \"position\": 1,\n",
    "                \"confidence\": correct_confidences[i],\n",
    "                \"is_true\": True,\n",
    "                \"smiles\": true_smiles\n",
    "            })\n",
    "            \n",
    "            # Generate lower confidences for positions 2-5 (all incorrect)\n",
    "            for pos in range(2, 6):\n",
    "                conf = np.clip(correct_confidences[i] * (0.9 - 0.1 * pos), 0.05, 0.95)\n",
    "                all_confidences.append({\n",
    "                    \"sample_id\": sample_id,\n",
    "                    \"experiment\": exp,\n",
    "                    \"position\": pos,\n",
    "                    \"confidence\": conf,\n",
    "                    \"is_true\": False,\n",
    "                    \"smiles\": f\"C1CC{i}C{pos}C1\"  # Different SMILES\n",
    "                })\n",
    "        \n",
    "        # Add incorrect predictions\n",
    "        for i in range(n_incorrect):\n",
    "            sample_id = f\"{base_id}_{n_correct+i+1}\"\n",
    "            \n",
    "            # Generate dummy SMILES\n",
    "            true_smiles = f\"C1CC{n_correct+i}CC1\"\n",
    "            pred_smiles = f\"C1CC{n_correct+i}NC1\"  # Different from true\n",
    "            \n",
    "            # Find position of correct molecule (randomly between 2-5 or None)\n",
    "            correct_pos = np.random.choice([2, 3, 4, 5, None], p=[0.3, 0.2, 0.1, 0.1, 0.3])\n",
    "            \n",
    "            results.append({\n",
    "                \"sample_id\": sample_id,\n",
    "                \"true_smiles\": true_smiles,\n",
    "                \"experiment\": exp,\n",
    "                \"top_candidate_smiles\": pred_smiles,\n",
    "                \"top_confidence\": incorrect_confidences[i],\n",
    "                \"is_correct\": False,\n",
    "                \"correct_position\": correct_pos,\n",
    "                \"correct_confidence\": 0.4 if correct_pos else None\n",
    "            })\n",
    "            \n",
    "            # Add confidence for top position (incorrect)\n",
    "            all_confidences.append({\n",
    "                \"sample_id\": sample_id,\n",
    "                \"experiment\": exp,\n",
    "                \"position\": 1,\n",
    "                \"confidence\": incorrect_confidences[i],\n",
    "                \"is_true\": False,\n",
    "                \"smiles\": pred_smiles\n",
    "            })\n",
    "            \n",
    "            # Generate confidences for positions 2-5\n",
    "            for pos in range(2, 6):\n",
    "                is_true = (pos == correct_pos)\n",
    "                conf = 0.4 if is_true else np.clip(incorrect_confidences[i] * (0.8 - 0.1 * pos), 0.05, 0.95)\n",
    "                all_confidences.append({\n",
    "                    \"sample_id\": sample_id,\n",
    "                    \"experiment\": exp,\n",
    "                    \"position\": pos,\n",
    "                    \"confidence\": conf,\n",
    "                    \"is_true\": is_true,\n",
    "                    \"smiles\": true_smiles if is_true else f\"C1CC{n_correct+i}N{pos}C1\"\n",
    "                })\n",
    "    \n",
    "    # Convert to DataFrames\n",
    "    results_df = pd.DataFrame(results)\n",
    "    confidences_df = pd.DataFrame(all_confidences)\n",
    "    \n",
    "    return results_df, confidences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b8364b-e576-4adf-8ea4-5525c18dd930",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def inspect_json_structure(file_path):\n",
    "    \"\"\"\n",
    "    Deeply inspect a JSON file to locate DeepSeek results and candidate information.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the JSON file\n",
    "    \"\"\"\n",
    "    print(f\"\\nInspecting file: {os.path.basename(file_path)}\")\n",
    "    \n",
    "    try:\n",
    "        # Load JSON data\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Check sample ID\n",
    "        sample_id = data.get(\"molecule_data\", {}).get(\"sample_id\")\n",
    "        if sample_id:\n",
    "            print(f\"Sample ID: {sample_id}\")\n",
    "        else:\n",
    "            print(\"No sample_id found at expected path\")\n",
    "        \n",
    "        # Search for deepseek data\n",
    "        print(\"Searching for DeepSeek data...\")\n",
    "        \n",
    "        # Look for common keywords\n",
    "        deepseek_paths = []\n",
    "        \n",
    "        def search_deepseek(obj, path=\"\"):\n",
    "            if isinstance(obj, dict):\n",
    "                for k, v in obj.items():\n",
    "                    new_path = f\"{path}.{k}\" if path else k\n",
    "                    \n",
    "                    # Check if this key might be related to deepseek\n",
    "                    if 'deepseek' in str(k).lower():\n",
    "                        deepseek_paths.append((new_path, v))\n",
    "                    \n",
    "                    # Check if this looks like a model response with candidates\n",
    "                    if k == 'candidates' and isinstance(v, list) and len(v) > 0 and 'smiles' in v[0]:\n",
    "                        deepseek_paths.append((new_path, v))\n",
    "                    \n",
    "                    # Check if this is a parsed result\n",
    "                    if k == 'parsed_results' and isinstance(v, dict) and 'candidates' in v:\n",
    "                        deepseek_paths.append((new_path, v))\n",
    "                    \n",
    "                    # Continue searching\n",
    "                    search_deepseek(v, new_path)\n",
    "            \n",
    "            elif isinstance(obj, list):\n",
    "                for i, item in enumerate(obj):\n",
    "                    new_path = f\"{path}[{i}]\"\n",
    "                    search_deepseek(item, new_path)\n",
    "        \n",
    "        search_deepseek(data)\n",
    "        \n",
    "        if not deepseek_paths:\n",
    "            print(\"No DeepSeek data found\")\n",
    "            \n",
    "            # Check if there are any occurrences of 'deepseek' string in the JSON\n",
    "            json_str = json.dumps(data)\n",
    "            if 'deepseek' in json_str.lower():\n",
    "                print(\"However, 'deepseek' string was found in the file\")\n",
    "                \n",
    "                # Try to find the context around it\n",
    "                idx = json_str.lower().find('deepseek')\n",
    "                context = json_str[max(0, idx-50):min(len(json_str), idx+150)]\n",
    "                print(f\"Context: ...{context}...\")\n",
    "            return\n",
    "        \n",
    "        # Print all identified DeepSeek paths\n",
    "        print(f\"Found {len(deepseek_paths)} potential DeepSeek data locations:\")\n",
    "        \n",
    "        for i, (path, value) in enumerate(deepseek_paths):\n",
    "            print(f\"\\nPotential DeepSeek data {i+1} at path: {path}\")\n",
    "            \n",
    "            # Check if this is candidates directly\n",
    "            if path.endswith('candidates'):\n",
    "                if isinstance(value, list):\n",
    "                    print(f\"Found {len(value)} candidates\")\n",
    "                    if len(value) > 0:\n",
    "                        first_candidate = value[0]\n",
    "                        # Check what keys are available in the candidate\n",
    "                        if isinstance(first_candidate, dict):\n",
    "                            print(f\"First candidate keys: {list(first_candidate.keys())}\")\n",
    "                            \n",
    "                            # Check for SMILES and confidence\n",
    "                            if 'smiles' in first_candidate:\n",
    "                                print(f\"First candidate SMILES: {first_candidate['smiles']}\")\n",
    "                            if 'confidence_score' in first_candidate:\n",
    "                                print(f\"First candidate confidence: {first_candidate['confidence_score']}\")\n",
    "                        else:\n",
    "                            print(f\"First candidate is not a dictionary: {type(first_candidate)}\")\n",
    "                else:\n",
    "                    print(f\"Candidates is not a list: {type(value)}\")\n",
    "            \n",
    "            # Check if this is parsed_results\n",
    "            elif path.endswith('parsed_results'):\n",
    "                if isinstance(value, dict) and 'candidates' in value:\n",
    "                    candidates = value['candidates']\n",
    "                    if isinstance(candidates, list):\n",
    "                        print(f\"Found {len(candidates)} candidates in parsed_results\")\n",
    "                        if len(candidates) > 0:\n",
    "                            first_candidate = candidates[0]\n",
    "                            if isinstance(first_candidate, dict):\n",
    "                                print(f\"First candidate keys: {list(first_candidate.keys())}\")\n",
    "                                \n",
    "                                # Check for SMILES and confidence\n",
    "                                if 'smiles' in first_candidate:\n",
    "                                    print(f\"First candidate SMILES: {first_candidate['smiles']}\")\n",
    "                                if 'confidence_score' in first_candidate:\n",
    "                                    print(f\"First candidate confidence: {first_candidate['confidence_score']}\")\n",
    "                            else:\n",
    "                                print(f\"First candidate is not a dictionary: {type(first_candidate)}\")\n",
    "                    else:\n",
    "                        print(f\"candidates in parsed_results is not a list: {type(candidates)}\")\n",
    "                else:\n",
    "                    print(\"parsed_results does not contain candidates or is not a dictionary\")\n",
    "            \n",
    "            # If it's just a deepseek key\n",
    "            else:\n",
    "                # Try to determine the structure\n",
    "                if isinstance(value, dict):\n",
    "                    print(f\"Dictionary with keys: {list(value.keys())}\")\n",
    "                    \n",
    "                    # Look for candidates or parsed_results\n",
    "                    if 'candidates' in value:\n",
    "                        candidates = value['candidates']\n",
    "                        if isinstance(candidates, list):\n",
    "                            print(f\"Found {len(candidates)} candidates\")\n",
    "                            # Examine first candidate\n",
    "                            if candidates and isinstance(candidates[0], dict):\n",
    "                                print(f\"First candidate keys: {list(candidates[0].keys())}\")\n",
    "                    elif 'parsed_results' in value:\n",
    "                        parsed_results = value['parsed_results']\n",
    "                        if isinstance(parsed_results, dict) and 'candidates' in parsed_results:\n",
    "                            candidates = parsed_results['candidates']\n",
    "                            if isinstance(candidates, list):\n",
    "                                print(f\"Found {len(candidates)} candidates in parsed_results\")\n",
    "                    elif 'raw_response' in value:\n",
    "                        print(\"Contains raw_response which might include candidate information\")\n",
    "                else:\n",
    "                    print(f\"Value is of type: {type(value)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error inspecting file: {str(e)}\")\n",
    "\n",
    "# Test on some files\n",
    "json_dir = \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_1_sim_finished_clean\"\n",
    "json_files = glob.glob(os.path.join(json_dir, \"*.json\"))\n",
    "\n",
    "# Inspect a few files\n",
    "for file_path in json_files[:5]:\n",
    "    inspect_json_structure(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfddb7e-35f6-4109-a623-73a7013adcd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "main(use_dummy_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a911ea7e-603b-4a54-980d-656788843e6f",
   "metadata": {},
   "source": [
    "### V3 Real data LLM Deepseek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6899aa-eee6-4d9d-9126-49f620a20bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Function to load reference data\n",
    "def load_reference_data(csv_path):\n",
    "    \"\"\"Load reference SMILES from CSV file.\"\"\"\n",
    "    ref_df = pd.read_csv(csv_path)\n",
    "    # Convert to dictionary for faster lookups\n",
    "    return ref_df.set_index('sample-id')['SMILES'].to_dict()\n",
    "\n",
    "# Function to access nested dictionary keys safely\n",
    "def get_nested(data, keys, default=None):\n",
    "    \"\"\"\n",
    "    Safely navigate nested dictionary structure.\n",
    "    \n",
    "    Args:\n",
    "        data: Dictionary to navigate\n",
    "        keys: List of keys to follow\n",
    "        default: Value to return if path doesn't exist\n",
    "        \n",
    "    Returns:\n",
    "        Value at the nested location or default if not found\n",
    "    \"\"\"\n",
    "    temp = data\n",
    "    for key in keys:\n",
    "        if isinstance(temp, dict) and key in temp:\n",
    "            temp = temp[key]\n",
    "        else:\n",
    "            return default\n",
    "    return temp\n",
    "\n",
    "# Function to analyze a single JSON file\n",
    "def analyze_json_file(file_path, reference_data):\n",
    "    \"\"\"\n",
    "    Analyze confidence scores from a single JSON file.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the JSON file\n",
    "        reference_data: Dictionary mapping sample IDs to true SMILES\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing analysis results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load JSON data\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Extract sample ID and get true SMILES\n",
    "        sample_id = get_nested(data, [\"molecule_data\", \"sample_id\"])\n",
    "        if not sample_id:\n",
    "            print(f\"Warning: No sample_id found in {file_path}\")\n",
    "            return None\n",
    "            \n",
    "        # Get base sample ID (before underscore if present)\n",
    "        base_sample_id = sample_id.split('_')[0] if '_' in sample_id else sample_id\n",
    "        true_smiles = reference_data.get(base_sample_id)\n",
    "        \n",
    "        if true_smiles is None:\n",
    "            print(f\"Warning: No reference SMILES found for sample_id {base_sample_id}\")\n",
    "            return None\n",
    "        \n",
    "        # Navigate to DeepSeek candidates using the correct path\n",
    "        candidates = get_nested(data, [\n",
    "            \"analysis_results\", \n",
    "            \"final_analysis\", \n",
    "            \"llm_responses\", \n",
    "            \"deepseek\", \n",
    "            \"parsed_results\", \n",
    "            \"candidates\"\n",
    "        ])\n",
    "        \n",
    "        if not candidates:\n",
    "            print(f\"Warning: No DeepSeek candidates found in {file_path}\")\n",
    "            return None\n",
    "        \n",
    "        # Sort candidates by confidence score (highest first)\n",
    "        sorted_candidates = sorted(candidates, key=lambda x: x.get(\"confidence_score\", 0), reverse=True)\n",
    "        \n",
    "        # Get the top candidate (highest confidence)\n",
    "        top_candidate = sorted_candidates[0]\n",
    "        top_candidate_smiles = top_candidate.get(\"smiles\")\n",
    "        top_confidence = top_candidate.get(\"confidence_score\", 0)\n",
    "        \n",
    "        # Check if top candidate is correct\n",
    "        is_correct = (top_candidate_smiles == true_smiles)\n",
    "        \n",
    "        # Find position of correct molecule in candidate list (if present)\n",
    "        correct_position = None\n",
    "        correct_confidence = None\n",
    "        \n",
    "        for i, candidate in enumerate(sorted_candidates, 1):\n",
    "            if candidate.get(\"smiles\") == true_smiles:\n",
    "                correct_position = i\n",
    "                correct_confidence = candidate.get(\"confidence_score\", 0)\n",
    "                break\n",
    "        \n",
    "        # Get experiment type from directory name\n",
    "        dir_name = os.path.basename(os.path.dirname(file_path))\n",
    "        if \"sim+noise\" in dir_name.lower():\n",
    "            experiment = \"Sim Data + Noise\"\n",
    "        elif \"sim_aug\" in dir_name.lower() or \"sim_d1_aug\" in dir_name.lower():\n",
    "            experiment = \"Sim Data + Wrong Guess\"\n",
    "        elif \"sim\" in dir_name.lower():\n",
    "            experiment = \"Sim Data\"\n",
    "        elif \"exp_d1_aug\" in dir_name.lower():\n",
    "            experiment = \"Exp Data + Wrong Guess\"\n",
    "        elif \"exp_d4\" in dir_name.lower():\n",
    "            experiment = \"Exp Data d4\"\n",
    "        elif \"exp\" in dir_name.lower():\n",
    "            experiment = \"Exp Data\"\n",
    "        else:\n",
    "            experiment = \"Unknown\"\n",
    "        \n",
    "        # Create confidence scores for all candidates\n",
    "        all_confidences = []\n",
    "        for i, candidate in enumerate(sorted_candidates):\n",
    "            is_true = (candidate.get(\"smiles\") == true_smiles)\n",
    "            all_confidences.append({\n",
    "                \"position\": i + 1,\n",
    "                \"confidence\": candidate.get(\"confidence_score\", 0),\n",
    "                \"is_true\": is_true,\n",
    "                \"smiles\": candidate.get(\"smiles\")\n",
    "            })\n",
    "            \n",
    "        return {\n",
    "            \"sample_id\": sample_id,\n",
    "            \"true_smiles\": true_smiles,\n",
    "            \"experiment\": experiment,\n",
    "            \"top_candidate_smiles\": top_candidate_smiles,\n",
    "            \"top_confidence\": top_confidence,\n",
    "            \"is_correct\": is_correct,\n",
    "            \"correct_position\": correct_position,\n",
    "            \"correct_confidence\": correct_confidence,\n",
    "            \"all_confidences\": all_confidences\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Function to process a directory of JSON files\n",
    "def process_directory(json_dir, reference_csv):\n",
    "    \"\"\"\n",
    "    Process all JSON files in a directory.\n",
    "    \n",
    "    Args:\n",
    "        json_dir: Directory containing JSON files\n",
    "        reference_csv: Path to reference CSV file\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with analysis results\n",
    "    \"\"\"\n",
    "    # Load reference data\n",
    "    reference_data = load_reference_data(reference_csv)\n",
    "    \n",
    "    # Find all JSON files\n",
    "    json_files = glob.glob(os.path.join(json_dir, \"*.json\"))\n",
    "    print(f\"Found {len(json_files)} JSON files to analyze\")\n",
    "    \n",
    "    # Process each file\n",
    "    results = []\n",
    "    all_confidences = []\n",
    "    \n",
    "    for file_path in json_files:\n",
    "        result = analyze_json_file(file_path, reference_data)\n",
    "        if result:\n",
    "            results.append(result)\n",
    "            \n",
    "            # Extract confidence scores for all candidates\n",
    "            for conf_data in result[\"all_confidences\"]:\n",
    "                all_confidences.append({\n",
    "                    \"sample_id\": result[\"sample_id\"],\n",
    "                    \"experiment\": result[\"experiment\"],\n",
    "                    \"position\": conf_data[\"position\"],\n",
    "                    \"confidence\": conf_data[\"confidence\"],\n",
    "                    \"is_true\": conf_data[\"is_true\"],\n",
    "                    \"smiles\": conf_data[\"smiles\"]\n",
    "                })\n",
    "    \n",
    "    # Convert to DataFrames\n",
    "    results_df = pd.DataFrame(results) if results else pd.DataFrame()\n",
    "    confidences_df = pd.DataFrame(all_confidences) if all_confidences else pd.DataFrame()\n",
    "    \n",
    "    print(f\"Successfully analyzed {len(results)} files with valid DeepSeek results\")\n",
    "    \n",
    "    return results_df, confidences_df\n",
    "\n",
    "# Function to plot confidence distributions\n",
    "def plot_confidence_distributions(results_df, output_file=None):\n",
    "    \"\"\"\n",
    "    Create violin plots showing confidence score distributions.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with analysis results\n",
    "        output_file: Path to save the figure (if None, display it)\n",
    "    \"\"\"\n",
    "    # Set up the figure\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Create a DataFrame for plotting\n",
    "    plot_data = []\n",
    "    \n",
    "    # For correct predictions (model's top pick was correct)\n",
    "    correct_preds = results_df[results_df[\"is_correct\"] == True]\n",
    "    for _, row in correct_preds.iterrows():\n",
    "        plot_data.append({\n",
    "            \"experiment\": row[\"experiment\"],\n",
    "            \"confidence\": row[\"top_confidence\"],\n",
    "            \"prediction\": \"Correct\"\n",
    "        })\n",
    "    \n",
    "    # For incorrect predictions (model's top pick was wrong)\n",
    "    incorrect_preds = results_df[results_df[\"is_correct\"] == False]\n",
    "    for _, row in incorrect_preds.iterrows():\n",
    "        plot_data.append({\n",
    "            \"experiment\": row[\"experiment\"],\n",
    "            \"confidence\": row[\"top_confidence\"],\n",
    "            \"prediction\": \"Incorrect\"\n",
    "        })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    plot_df = pd.DataFrame(plot_data)\n",
    "    \n",
    "    # Create the violin plot\n",
    "    ax = sns.violinplot(x=\"experiment\", y=\"confidence\", hue=\"prediction\", \n",
    "                    data=plot_df, split=True, inner=\"quartile\",\n",
    "                    palette={\"Correct\": \"mediumseagreen\", \"Incorrect\": \"tomato\"})\n",
    "    \n",
    "    # Add individual data points\n",
    "    sns.stripplot(x=\"experiment\", y=\"confidence\", hue=\"prediction\", \n",
    "               data=plot_df, dodge=True, alpha=0.3, size=4, linewidth=1,\n",
    "               palette={\"Correct\": \"darkgreen\", \"Incorrect\": \"darkred\"})\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title(\"DeepSeek-R1 Confidence Scores by Prediction Correctness\", fontsize=16)\n",
    "    plt.xlabel(\"Experimental Condition\", fontsize=14)\n",
    "    plt.ylabel(\"Confidence Score\", fontsize=14)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Create legend without duplicate items\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    plt.legend(handles[:2], labels[:2], title=\"Prediction\", fontsize=12)\n",
    "    \n",
    "    # Add text with statistics for each experiment\n",
    "    for i, exp in enumerate(plot_df[\"experiment\"].unique()):\n",
    "        exp_data = plot_df[plot_df[\"experiment\"] == exp]\n",
    "        correct_data = exp_data[exp_data[\"prediction\"] == \"Correct\"]\n",
    "        incorrect_data = exp_data[exp_data[\"prediction\"] == \"Incorrect\"]\n",
    "        \n",
    "        n_correct = len(correct_data)\n",
    "        n_incorrect = len(incorrect_data)\n",
    "        total = n_correct + n_incorrect\n",
    "        \n",
    "        avg_correct = correct_data[\"confidence\"].mean() if len(correct_data) > 0 else 0\n",
    "        avg_incorrect = incorrect_data[\"confidence\"].mean() if len(incorrect_data) > 0 else 0\n",
    "        \n",
    "        text = f\"n={total}\\nCorrect: {n_correct} ({n_correct/total*100:.1f}%)\\nIncorrect: {n_incorrect} ({n_incorrect/total*100:.1f}%)\"\n",
    "        plt.text(i, 0.05, text, ha='center', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save or display the figure\n",
    "    if output_file:\n",
    "        plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# Function to create a histogram comparing confidence scores\n",
    "def plot_confidence_histogram(results_df, output_file=None):\n",
    "    \"\"\"\n",
    "    Create a histogram showing confidence score distributions.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with analysis results\n",
    "        output_file: Path to save the figure (if None, display it)\n",
    "    \"\"\"\n",
    "    # Set up the figure\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Create separate data for correct and incorrect predictions\n",
    "    correct_preds = results_df[results_df[\"is_correct\"] == True][\"top_confidence\"]\n",
    "    incorrect_preds = results_df[results_df[\"is_correct\"] == False][\"top_confidence\"]\n",
    "    \n",
    "    # Create the histogram\n",
    "    bins = np.linspace(0, 1, 21)  # 20 bins from 0 to 1\n",
    "    \n",
    "    plt.hist(correct_preds, bins=bins, alpha=0.7, color='mediumseagreen', \n",
    "             label=f'Correct Predictions (n={len(correct_preds)})')\n",
    "    plt.hist(incorrect_preds, bins=bins, alpha=0.7, color='tomato', \n",
    "             label=f'Incorrect Predictions (n={len(incorrect_preds)})')\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title(\"Distribution of DeepSeek-R1 Confidence Scores by Prediction Correctness\", fontsize=16)\n",
    "    plt.xlabel(\"Confidence Score\", fontsize=14)\n",
    "    plt.ylabel(\"Frequency\", fontsize=14)\n",
    "    plt.grid(linestyle='--', alpha=0.7)\n",
    "    plt.legend(fontsize=12)\n",
    "    \n",
    "    # Calculate and display statistics\n",
    "    mean_correct = correct_preds.mean() if len(correct_preds) > 0 else 0\n",
    "    mean_incorrect = incorrect_preds.mean() if len(incorrect_preds) > 0 else 0\n",
    "    \n",
    "    stats_text = (\n",
    "        f\"Mean confidence when correct: {mean_correct:.3f}\\n\"\n",
    "        f\"Mean confidence when incorrect: {mean_incorrect:.3f}\\n\"\n",
    "        f\"Difference: {mean_correct - mean_incorrect:.3f}\"\n",
    "    )\n",
    "    \n",
    "    plt.text(0.05, 0.95, stats_text, transform=plt.gca().transAxes, \n",
    "             verticalalignment='top', fontsize=12,\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save or display the figure\n",
    "    if output_file:\n",
    "        plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# Function to create a boxplot showing confidence by position\n",
    "def plot_confidence_by_position(confidences_df, output_file=None):\n",
    "    \"\"\"\n",
    "    Create a boxplot showing confidence scores by position.\n",
    "    \n",
    "    Args:\n",
    "        confidences_df: DataFrame with confidence scores\n",
    "        output_file: Path to save the figure (if None, display it)\n",
    "    \"\"\"\n",
    "    # Limit to first 5 positions\n",
    "    df = confidences_df[confidences_df[\"position\"] <= 5].copy()\n",
    "    \n",
    "    # Convert boolean is_true to string to avoid palette issues\n",
    "    df['is_true'] = df['is_true'].astype(str)\n",
    "    \n",
    "    # Set up the figure\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    \n",
    "    # Create the boxplot\n",
    "    ax = sns.boxplot(x=\"position\", y=\"confidence\", hue=\"is_true\", \n",
    "                 data=df, palette={\"True\": \"mediumseagreen\", \"False\": \"tomato\"})\n",
    "    \n",
    "    # Add individual data points\n",
    "    sns.stripplot(x=\"position\", y=\"confidence\", hue=\"is_true\", \n",
    "               data=df, dodge=True, alpha=0.3, size=4, linewidth=1,\n",
    "               palette={\"True\": \"darkgreen\", \"False\": \"darkred\"})\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title(\"DeepSeek-R1 Confidence Scores by Candidate Position\", fontsize=16)\n",
    "    plt.xlabel(\"Candidate Position (by confidence ranking)\", fontsize=14)\n",
    "    plt.ylabel(\"Confidence Score\", fontsize=14)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Create legend without duplicate items\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    plt.legend(handles[:2], [\"Correct Structure\", \"Incorrect Structure\"], title=\"Structure\", fontsize=12)\n",
    "    \n",
    "    # Add text with count statistics for each position\n",
    "    for i in range(1, 6):\n",
    "        pos_data = df[df[\"position\"] == i]\n",
    "        true_data = pos_data[pos_data[\"is_true\"] == \"True\"]\n",
    "        false_data = pos_data[pos_data[\"is_true\"] == \"False\"]\n",
    "        \n",
    "        n_true = len(true_data)\n",
    "        n_false = len(false_data)\n",
    "        total = n_true + n_false\n",
    "        \n",
    "        text = f\"n={total}\\nCorrect: {n_true}\\nIncorrect: {n_false}\"\n",
    "        plt.text(i-1, 0.05, text, ha='center', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save or display the figure\n",
    "    if output_file:\n",
    "        plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# Function to calculate and plot ROC curve for different confidence thresholds\n",
    "def plot_roc_curve(results_df, output_file=None):\n",
    "    \"\"\"\n",
    "    Create an ROC curve for different confidence thresholds.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with analysis results\n",
    "        output_file: Path to save the figure (if None, display it)\n",
    "    \"\"\"\n",
    "    # Set up the figure\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Calculate ROC curve points\n",
    "    thresholds = np.linspace(0, 1, 101)  # 101 points from 0 to 1\n",
    "    tpr_list = []  # True Positive Rate (sensitivity)\n",
    "    fpr_list = []  # False Positive Rate (1 - specificity)\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        # Number of positive examples\n",
    "        positives = len(results_df[results_df[\"is_correct\"] == True])\n",
    "        # Number of negative examples\n",
    "        negatives = len(results_df[results_df[\"is_correct\"] == False])\n",
    "        \n",
    "        # True positives: correct predictions with confidence >= threshold\n",
    "        tp = len(results_df[(results_df[\"is_correct\"] == True) & \n",
    "                           (results_df[\"top_confidence\"] >= threshold)])\n",
    "        \n",
    "        # False positives: incorrect predictions with confidence >= threshold\n",
    "        fp = len(results_df[(results_df[\"is_correct\"] == False) & \n",
    "                           (results_df[\"top_confidence\"] >= threshold)])\n",
    "        \n",
    "        # Calculate rates\n",
    "        tpr = tp / positives if positives > 0 else 0  # Sensitivity\n",
    "        fpr = fp / negatives if negatives > 0 else 0  # 1 - Specificity\n",
    "        \n",
    "        tpr_list.append(tpr)\n",
    "        fpr_list.append(fpr)\n",
    "    \n",
    "    # Plot the ROC curve\n",
    "    plt.plot(fpr_list, tpr_list, 'b-', linewidth=2)\n",
    "    \n",
    "    # Add the diagonal reference line (random classifier)\n",
    "    plt.plot([0, 1], [0, 1], 'r--', linewidth=1.5)\n",
    "    \n",
    "    # Calculate AUC (Area Under Curve)\n",
    "    auc = 0\n",
    "    for i in range(len(fpr_list) - 1):\n",
    "        auc += (fpr_list[i+1] - fpr_list[i]) * (tpr_list[i+1] + tpr_list[i]) / 2\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title(f\"ROC Curve for DeepSeek-R1 Confidence Scores\\nAUC = {auc:.3f}\", fontsize=16)\n",
    "    plt.xlabel(\"False Positive Rate (1 - Specificity)\", fontsize=14)\n",
    "    plt.ylabel(\"True Positive Rate (Sensitivity)\", fontsize=14)\n",
    "    plt.grid(linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Add threshold indicators for notable points\n",
    "    for t in [0.3, 0.5, 0.7, 0.9]:\n",
    "        idx = int(t * 100)\n",
    "        plt.plot(fpr_list[idx], tpr_list[idx], 'ko', markersize=6)\n",
    "        plt.text(fpr_list[idx]+0.02, tpr_list[idx]-0.02, f\"t={t}\", fontsize=10)\n",
    "    \n",
    "    # Add statistics table\n",
    "    stats_data = []\n",
    "    for t in [0.3, 0.5, 0.7, 0.9]:\n",
    "        correct_above = len(results_df[(results_df[\"is_correct\"] == True) & \n",
    "                                     (results_df[\"top_confidence\"] >= t)])\n",
    "        incorrect_above = len(results_df[(results_df[\"is_correct\"] == False) & \n",
    "                                       (results_df[\"top_confidence\"] >= t)])\n",
    "        correct_below = len(results_df[(results_df[\"is_correct\"] == True) & \n",
    "                                     (results_df[\"top_confidence\"] < t)])\n",
    "        incorrect_below = len(results_df[(results_df[\"is_correct\"] == False) & \n",
    "                                       (results_df[\"top_confidence\"] < t)])\n",
    "        \n",
    "        total_above = correct_above + incorrect_above\n",
    "        precision = correct_above / total_above if total_above > 0 else 0\n",
    "        \n",
    "        stats_data.append({\n",
    "            \"threshold\": t,\n",
    "            \"correct_above\": correct_above,\n",
    "            \"incorrect_above\": incorrect_above,\n",
    "            \"precision\": precision\n",
    "        })\n",
    "    \n",
    "    stats_table = pd.DataFrame(stats_data)\n",
    "    table_text = \"Threshold statistics:\\n\"\n",
    "    for _, row in stats_table.iterrows():\n",
    "        table_text += f\"t={row['threshold']:.1f}: {row['correct_above']} correct, {row['incorrect_above']} incorrect above threshold (precision: {row['precision']:.2f})\\n\"\n",
    "    \n",
    "    plt.text(0.05, 0.05, table_text, transform=plt.gca().transAxes, \n",
    "             verticalalignment='bottom', fontsize=10,\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save or display the figure\n",
    "    if output_file:\n",
    "        plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# Function to create an experiment-specific confidence visualization\n",
    "def plot_experiment_confidence(results_df, output_file=None):\n",
    "    \"\"\"\n",
    "    Create a detailed visualization of confidence scores by experiment.\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame with analysis results\n",
    "        output_file: Path to save the figure (if None, display it)\n",
    "    \"\"\"\n",
    "    # Set up the figure\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12), sharex=True, sharey=True)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Set the color palette\n",
    "    experiment_colors = {\n",
    "        \"Sim Data\": \"#10B981\",\n",
    "        \"Sim Data + Wrong Guess\": \"#3B82F6\",\n",
    "        \"Sim Data + Noise\": \"#6366F1\",\n",
    "        \"Exp Data\": \"#F59E0B\",\n",
    "        \"Exp Data + Wrong Guess\": \"#EC4899\",\n",
    "        \"Exp Data d4\": \"#8B5CF6\"\n",
    "    }\n",
    "    \n",
    "    # Process each experiment\n",
    "    experiments = results_df[\"experiment\"].unique()\n",
    "    \n",
    "    for i, exp in enumerate(experiments):\n",
    "        if i >= len(axes):\n",
    "            break\n",
    "            \n",
    "        ax = axes[i]\n",
    "        exp_data = results_df[results_df[\"experiment\"] == exp]\n",
    "        \n",
    "        # Separate correct and incorrect predictions\n",
    "        correct_preds = exp_data[exp_data[\"is_correct\"] == True][\"top_confidence\"]\n",
    "        incorrect_preds = exp_data[exp_data[\"is_correct\"] == False][\"top_confidence\"]\n",
    "        \n",
    "        # Create the histogram\n",
    "        bins = np.linspace(0, 1, 21)  # 20 bins from 0 to 1\n",
    "        \n",
    "        ax.hist(correct_preds, bins=bins, alpha=0.7, color=experiment_colors.get(exp, \"#333333\"), \n",
    "                label=f'Correct (n={len(correct_preds)})')\n",
    "        ax.hist(incorrect_preds, bins=bins, alpha=0.5, hatch='///', color=experiment_colors.get(exp, \"#333333\"), \n",
    "                label=f'Incorrect (n={len(incorrect_preds)})')\n",
    "        \n",
    "        # Calculate statistics\n",
    "        mean_correct = correct_preds.mean() if len(correct_preds) > 0 else 0\n",
    "        mean_incorrect = incorrect_preds.mean() if len(incorrect_preds) > 0 else 0\n",
    "        \n",
    "        # Calculate suggested threshold for this experiment\n",
    "        if len(correct_preds) > 0 and len(incorrect_preds) > 0:\n",
    "            # Simple approach: average of the means\n",
    "            suggested_threshold = (mean_correct + mean_incorrect) / 2\n",
    "        else:\n",
    "            suggested_threshold = 0.5\n",
    "        \n",
    "        # Add vertical line for suggested threshold\n",
    "        ax.axvline(x=suggested_threshold, color='red', linestyle='--', linewidth=1.5)\n",
    "        \n",
    "        # Calculate accuracy at suggested threshold\n",
    "        correct_above = len(exp_data[(exp_data[\"is_correct\"] == True) & \n",
    "                                  (exp_data[\"top_confidence\"] >= suggested_threshold)])\n",
    "        correct_below = len(exp_data[(exp_data[\"is_correct\"] == True) & \n",
    "                                  (exp_data[\"top_confidence\"] < suggested_threshold)])\n",
    "        incorrect_above = len(exp_data[(exp_data[\"is_correct\"] == False) & \n",
    "                                    (exp_data[\"top_confidence\"] >= suggested_threshold)])\n",
    "        incorrect_below = len(exp_data[(exp_data[\"is_correct\"] == False) & \n",
    "                                    (exp_data[\"top_confidence\"] < suggested_threshold)])\n",
    "        \n",
    "        total = len(exp_data)\n",
    "        accuracy = (correct_above + incorrect_below) / total if total > 0 else 0\n",
    "        \n",
    "        # Add statistics text\n",
    "        stats_text = (\n",
    "            f\"Mean conf. (correct): {mean_correct:.2f}\\n\"\n",
    "            f\"Mean conf. (incorrect): {mean_incorrect:.2f}\\n\"\n",
    "            f\"Suggested threshold: {suggested_threshold:.2f}\\n\"\n",
    "            f\"Acc @ threshold: {accuracy:.2f}\"\n",
    "        )\n",
    "        \n",
    "        ax.text(0.05, 0.95, stats_text, transform=ax.transAxes, \n",
    "                verticalalignment='top', fontsize=10,\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "        \n",
    "        # Customize the plot\n",
    "        ax.set_title(exp, fontsize=14)\n",
    "        ax.grid(linestyle='--', alpha=0.7)\n",
    "        ax.legend(fontsize=10)\n",
    "        \n",
    "        # Calculate and display separation score (area between distributions)\n",
    "        # This is a simplified measure of how well the confidence scores separate correct from incorrect\n",
    "        if len(correct_preds) > 0 and len(incorrect_preds) > 0:\n",
    "            # Use difference in means normalized by pooled standard deviation (Cohen's d)\n",
    "            std_correct = correct_preds.std()\n",
    "            std_incorrect = incorrect_preds.std()\n",
    "            pooled_std = np.sqrt((std_correct**2 + std_incorrect**2) / 2)\n",
    "            \n",
    "            if pooled_std > 0:\n",
    "                cohens_d = abs(mean_correct - mean_incorrect) / pooled_std\n",
    "                separation_text = f\"Separation score: {cohens_d:.2f}\"\n",
    "                ax.text(0.95, 0.05, separation_text, transform=ax.transAxes, \n",
    "                        horizontalalignment='right', verticalalignment='bottom', fontsize=10,\n",
    "                        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Set common labels\n",
    "    fig.text(0.5, 0.02, 'Confidence Score', ha='center', fontsize=14)\n",
    "    fig.text(0.02, 0.5, 'Frequency', va='center', rotation='vertical', fontsize=14)\n",
    "    \n",
    "    fig.suptitle(\"DeepSeek-R1 Confidence Score Distributions by Experimental Condition\", fontsize=18)\n",
    "    \n",
    "    plt.tight_layout(rect=[0.03, 0.03, 1, 0.97])\n",
    "    \n",
    "    # Save or display the figure\n",
    "    if output_file:\n",
    "        plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# Main function to run the analysis\n",
    "def main(use_dummy_data=False):\n",
    "    \"\"\"\n",
    "    Run the complete analysis.\n",
    "    \n",
    "    Args:\n",
    "        use_dummy_data: If True, use generated dummy data instead of processing JSON files\n",
    "    \"\"\"\n",
    "    # Define input and output paths\n",
    "    json_dirs = [\n",
    "        \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_1_sim_finished_clean\",\n",
    "        \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_2_sim_aug_finished_clean\",\n",
    "        \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_3_sim+noise_finished_clean\",\n",
    "        \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_4_exp_d1_finished_clean\",\n",
    "        \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_5_exp_d1_aug_finished_clean\",\n",
    "        \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_6_exp_d4_finished_clean\"\n",
    "    ]\n",
    "    \n",
    "    reference_csv = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "    \n",
    "    # Process each directory and combine results\n",
    "    all_results = []\n",
    "    all_confidences = []\n",
    "    \n",
    "    for json_dir in json_dirs:\n",
    "        print(f\"Processing {json_dir}...\")\n",
    "        results_df, confidences_df = process_directory(json_dir, reference_csv)\n",
    "        \n",
    "        if not results_df.empty:\n",
    "            all_results.append(results_df)\n",
    "            all_confidences.append(confidences_df)\n",
    "    \n",
    "    # Combine all results\n",
    "    combined_results = pd.concat(all_results) if all_results else pd.DataFrame()\n",
    "    combined_confidences = pd.concat(all_confidences) if all_confidences else pd.DataFrame()\n",
    "    \n",
    "    if combined_results.empty:\n",
    "        print(\"No valid results found.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Analyzing {len(combined_results)} total items...\")\n",
    "    \n",
    "    # Generate and save the plots\n",
    "    print(\"Generating confidence distribution plots...\")\n",
    "    plot_confidence_distributions(combined_results, \"deepseek_confidence_distributions.png\")\n",
    "    \n",
    "    print(\"Generating confidence histogram...\")\n",
    "    plot_confidence_histogram(combined_results, \"deepseek_confidence_histogram.png\")\n",
    "    \n",
    "    print(\"Generating confidence by position plot...\")\n",
    "    plot_confidence_by_position(combined_confidences, \"deepseek_confidence_by_position.png\")\n",
    "    \n",
    "    print(\"Generating ROC curve...\")\n",
    "    plot_roc_curve(combined_results, \"deepseek_confidence_roc.png\")\n",
    "    \n",
    "    print(\"Generating experimental condition analysis...\")\n",
    "    plot_experiment_confidence(combined_results, \"deepseek_experiment_confidence.png\")\n",
    "    \n",
    "    print(\"Analysis complete. All plots have been saved.\")\n",
    "    \n",
    "    # Print summary statistics\n",
    "    if not combined_results.empty:\n",
    "        total = len(combined_results)\n",
    "        correct = combined_results[\"is_correct\"].sum()\n",
    "        incorrect = total - correct\n",
    "        \n",
    "        print(f\"\\nSUMMARY STATISTICS:\")\n",
    "        print(f\"Total samples analyzed: {total}\")\n",
    "        print(f\"Correct predictions: {correct} ({correct/total*100:.1f}%)\")\n",
    "        print(f\"Incorrect predictions: {incorrect} ({incorrect/total*100:.1f}%)\")\n",
    "        \n",
    "        # By experiment\n",
    "        print(\"\\nBreakdown by experiment:\")\n",
    "        exp_groups = combined_results.groupby(\"experiment\")\n",
    "        exp_counts = exp_groups.size()\n",
    "        exp_correct = exp_groups[\"is_correct\"].sum()\n",
    "        exp_accuracy = exp_groups[\"is_correct\"].mean() * 100\n",
    "        \n",
    "        for exp in exp_counts.index:\n",
    "            print(f\"  {exp}: {exp_counts[exp]} samples, {exp_correct[exp]} correct ({exp_accuracy[exp]:.1f}%)\")\n",
    "        \n",
    "        # Confidence statistics\n",
    "        print(\"\\nConfidence score statistics:\")\n",
    "        mean_conf_correct = combined_results[combined_results[\"is_correct\"]][\"top_confidence\"].mean()\n",
    "        mean_conf_incorrect = combined_results[~combined_results[\"is_correct\"]][\"top_confidence\"].mean()\n",
    "        \n",
    "        print(f\"  Mean confidence when correct: {mean_conf_correct:.3f}\")\n",
    "        print(f\"  Mean confidence when incorrect: {mean_conf_incorrect:.3f}\")\n",
    "        print(f\"  Difference: {mean_conf_correct - mean_conf_incorrect:.3f}\")\n",
    "        \n",
    "        # Suggest a threshold\n",
    "        if not np.isnan(mean_conf_correct) and not np.isnan(mean_conf_incorrect):\n",
    "            suggested_threshold = (mean_conf_correct + mean_conf_incorrect) / 2\n",
    "            print(f\"\\nSuggested confidence threshold: {suggested_threshold:.2f}\")\n",
    "            \n",
    "            # Calculate accuracy at this threshold\n",
    "            correct_above = ((combined_results[\"is_correct\"]) & \n",
    "                           (combined_results[\"top_confidence\"] >= suggested_threshold)).sum()\n",
    "            incorrect_below = ((~combined_results[\"is_correct\"]) & \n",
    "                             (combined_results[\"top_confidence\"] < suggested_threshold)).sum()\n",
    "            \n",
    "            threshold_accuracy = (correct_above + incorrect_below) / total\n",
    "            print(f\"Accuracy at suggested threshold: {threshold_accuracy:.2f}\")\n",
    "        \n",
    "    return combined_results, combined_confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1238a15-1c3a-484f-bc12-ff42cdc6a233",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Use dummy data for testing\n",
    "    # main(use_dummy_data=True)\n",
    "    \n",
    "    # Or use actual JSON files\n",
    "    main(use_dummy_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498900fa-c2d1-44d7-869f-fdc7cbd78ad3",
   "metadata": {},
   "source": [
    "### V3.1 Real plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2120514-078c-4278-b031-fe2a42f06aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Function to load reference data\n",
    "def load_reference_data(csv_path):\n",
    "    \"\"\"Load reference SMILES from CSV file.\"\"\"\n",
    "    ref_df = pd.read_csv(csv_path)\n",
    "    # Convert to dictionary for faster lookups\n",
    "    return ref_df.set_index('sample-id')['SMILES'].to_dict()\n",
    "\n",
    "# Function to access nested dictionary keys safely\n",
    "def get_nested(data, keys, default=None):\n",
    "    \"\"\"\n",
    "    Safely navigate nested dictionary structure.\n",
    "    \"\"\"\n",
    "    temp = data\n",
    "    for key in keys:\n",
    "        if isinstance(temp, dict) and key in temp:\n",
    "            temp = temp[key]\n",
    "        else:\n",
    "            return default\n",
    "    return temp\n",
    "\n",
    "# Function to analyze a single JSON file\n",
    "def analyze_json_file(file_path, reference_data):\n",
    "    \"\"\"\n",
    "    Analyze confidence scores from a single JSON file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load JSON data\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Extract sample ID and get true SMILES\n",
    "        sample_id = get_nested(data, [\"molecule_data\", \"sample_id\"])\n",
    "        if not sample_id:\n",
    "            print(f\"Warning: No sample_id found in {file_path}\")\n",
    "            return None\n",
    "            \n",
    "        # Get base sample ID (before underscore if present)\n",
    "        base_sample_id = sample_id.split('_')[0] if '_' in sample_id else sample_id\n",
    "        true_smiles = reference_data.get(base_sample_id)\n",
    "        \n",
    "        if true_smiles is None:\n",
    "            print(f\"Warning: No reference SMILES found for sample_id {base_sample_id}\")\n",
    "            return None\n",
    "        \n",
    "        # Navigate to DeepSeek candidates using the correct path\n",
    "        candidates = get_nested(data, [\n",
    "            \"analysis_results\", \n",
    "            \"final_analysis\", \n",
    "            \"llm_responses\", \n",
    "            \"deepseek\", \n",
    "            \"parsed_results\", \n",
    "            \"candidates\"\n",
    "        ])\n",
    "        \n",
    "        if not candidates:\n",
    "            print(f\"Warning: No DeepSeek candidates found in {file_path}\")\n",
    "            return None\n",
    "        \n",
    "        # Sort candidates by confidence score (highest first)\n",
    "        sorted_candidates = sorted(candidates, key=lambda x: x.get(\"confidence_score\", 0), reverse=True)\n",
    "        \n",
    "        # Get the top candidate (highest confidence)\n",
    "        top_candidate = sorted_candidates[0]\n",
    "        top_candidate_smiles = top_candidate.get(\"smiles\")\n",
    "        top_confidence = top_candidate.get(\"confidence_score\", 0)\n",
    "        \n",
    "        # Check if top candidate is correct\n",
    "        is_correct = (top_candidate_smiles == true_smiles)\n",
    "        \n",
    "        # Find position of correct molecule in candidate list (if present)\n",
    "        correct_position = None\n",
    "        correct_confidence = None\n",
    "        \n",
    "        for i, candidate in enumerate(sorted_candidates, 1):\n",
    "            if candidate.get(\"smiles\") == true_smiles:\n",
    "                correct_position = i\n",
    "                correct_confidence = candidate.get(\"confidence_score\", 0)\n",
    "                break\n",
    "        \n",
    "        # Get experiment type from directory name\n",
    "        dir_name = os.path.basename(os.path.dirname(file_path))\n",
    "        if \"sim+noise\" in dir_name.lower():\n",
    "            experiment = \"Sim Data + Noise\"\n",
    "        elif \"sim_aug\" in dir_name.lower() or \"sim_d1_aug\" in dir_name.lower():\n",
    "            experiment = \"Sim Data + Wrong Guess\"\n",
    "        elif \"sim\" in dir_name.lower():\n",
    "            experiment = \"Sim Data\"\n",
    "        elif \"exp_d1_aug\" in dir_name.lower():\n",
    "            experiment = \"Exp Data + Wrong Guess\"\n",
    "        elif \"exp_d4\" in dir_name.lower():\n",
    "            experiment = \"Exp Data d4\"\n",
    "        elif \"exp\" in dir_name.lower():\n",
    "            experiment = \"Exp Data\"\n",
    "        else:\n",
    "            experiment = \"Unknown\"\n",
    "        \n",
    "        # Create confidence scores for all candidates\n",
    "        all_confidences = []\n",
    "        for i, candidate in enumerate(sorted_candidates):\n",
    "            is_true = (candidate.get(\"smiles\") == true_smiles)\n",
    "            all_confidences.append({\n",
    "                \"position\": i + 1,\n",
    "                \"confidence\": candidate.get(\"confidence_score\", 0),\n",
    "                \"is_true\": is_true,\n",
    "                \"smiles\": candidate.get(\"smiles\")\n",
    "            })\n",
    "            \n",
    "        return {\n",
    "            \"sample_id\": sample_id,\n",
    "            \"true_smiles\": true_smiles,\n",
    "            \"experiment\": experiment,\n",
    "            \"top_candidate_smiles\": top_candidate_smiles,\n",
    "            \"top_confidence\": top_confidence,\n",
    "            \"is_correct\": is_correct,\n",
    "            \"correct_position\": correct_position,\n",
    "            \"correct_confidence\": correct_confidence,\n",
    "            \"all_confidences\": all_confidences\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Function to process a directory of JSON files\n",
    "def process_directory(json_dir, reference_csv):\n",
    "    \"\"\"\n",
    "    Process all JSON files in a directory.\n",
    "    \"\"\"\n",
    "    # Load reference data\n",
    "    reference_data = load_reference_data(reference_csv)\n",
    "    \n",
    "    # Find all JSON files\n",
    "    json_files = glob.glob(os.path.join(json_dir, \"*.json\"))\n",
    "    print(f\"Found {len(json_files)} JSON files to analyze\")\n",
    "    \n",
    "    # Process each file\n",
    "    results = []\n",
    "    all_confidences = []\n",
    "    \n",
    "    for file_path in json_files:\n",
    "        result = analyze_json_file(file_path, reference_data)\n",
    "        if result:\n",
    "            results.append(result)\n",
    "            \n",
    "            # Extract confidence scores for all candidates\n",
    "            for conf_data in result[\"all_confidences\"]:\n",
    "                all_confidences.append({\n",
    "                    \"sample_id\": result[\"sample_id\"],\n",
    "                    \"experiment\": result[\"experiment\"],\n",
    "                    \"position\": conf_data[\"position\"],\n",
    "                    \"confidence\": conf_data[\"confidence\"],\n",
    "                    \"is_true\": conf_data[\"is_true\"],\n",
    "                    \"smiles\": conf_data[\"smiles\"]\n",
    "                })\n",
    "    \n",
    "    # Convert to DataFrames\n",
    "    results_df = pd.DataFrame(results) if results else pd.DataFrame()\n",
    "    confidences_df = pd.DataFrame(all_confidences) if all_confidences else pd.DataFrame()\n",
    "    \n",
    "    print(f\"Successfully analyzed {len(results)} files with valid DeepSeek results\")\n",
    "    \n",
    "    return results_df, confidences_df\n",
    "\n",
    "def plot_confidence_by_position_with_stats(confidences_df, output_file=None):\n",
    "    \"\"\"\n",
    "    Create a boxplot showing confidence scores by position and print detailed statistics.\n",
    "    \"\"\"\n",
    "    # Limit to first 5 positions\n",
    "    df = confidences_df[confidences_df[\"position\"] <= 5].copy()\n",
    "    \n",
    "    # Convert boolean is_true to string to avoid palette issues\n",
    "    df['is_true'] = df['is_true'].astype(str)\n",
    "    \n",
    "    # Calculate key statistics for the text\n",
    "    position_stats = []\n",
    "    \n",
    "    for pos in range(1, 6):\n",
    "        pos_data = df[df[\"position\"] == pos]\n",
    "        true_data = pos_data[pos_data[\"is_true\"] == \"True\"]\n",
    "        false_data = pos_data[pos_data[\"is_true\"] == \"False\"]\n",
    "        \n",
    "        n_true = len(true_data)\n",
    "        n_false = len(false_data)\n",
    "        total = n_true + n_false\n",
    "        \n",
    "        mean_true = true_data[\"confidence\"].mean() if n_true > 0 else 0\n",
    "        mean_false = false_data[\"confidence\"].mean() if n_false > 0 else 0\n",
    "        median_true = true_data[\"confidence\"].median() if n_true > 0 else 0\n",
    "        median_false = false_data[\"confidence\"].median() if n_false > 0 else 0\n",
    "        median_all = pos_data[\"confidence\"].median()\n",
    "        \n",
    "        correct_percentage = (n_true / total * 100) if total > 0 else 0\n",
    "        \n",
    "        position_stats.append({\n",
    "            \"position\": pos,\n",
    "            \"total\": total,\n",
    "            \"n_true\": n_true,\n",
    "            \"n_false\": n_false,\n",
    "            \"correct_percentage\": correct_percentage,\n",
    "            \"mean_true\": mean_true,\n",
    "            \"mean_false\": mean_false,\n",
    "            \"median_true\": median_true,\n",
    "            \"median_false\": median_false,\n",
    "            \"median_all\": median_all\n",
    "        })\n",
    "    \n",
    "    # Print stats in a nicely formatted way\n",
    "    print(\"\\nDeepSeek-R1 Confidence Score Statistics by Position:\")\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"{'Position':<10} {'Total':<8} {'Correct':<10} {'Incorrect':<10} {'% Correct':<10} {'Mean (Correct)':<15} {'Mean (Incorrect)':<15} {'Median (All)':<15}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for stat in position_stats:\n",
    "        print(f\"{stat['position']:<10} {stat['total']:<8} {stat['n_true']:<10} {stat['n_false']:<10} {stat['correct_percentage']:.1f}%{' ':<5} {stat['mean_true']:.3f}{' ':<7} {stat['mean_false']:.3f}{' ':<7} {stat['median_all']:.2f}{' ':<7}\")\n",
    "    \n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    # Print specific values mentioned in the text\n",
    "    print(\"\\nKey Values for Text:\")\n",
    "    print(f\"Position 1 correct percentage: {position_stats[0]['correct_percentage']:.1f}% ({position_stats[0]['n_true']}/{position_stats[0]['total']})\")\n",
    "    print(f\"Position 1 mean confidence for correct structures: {position_stats[0]['mean_true']:.3f}\")\n",
    "    print(f\"Position 1 mean confidence for incorrect structures: {position_stats[0]['mean_false']:.3f}\")\n",
    "    print(f\"Position 1 median confidence score: ~{position_stats[0]['median_all']:.2f}\")\n",
    "    print(f\"Position 5 median confidence score: ~{position_stats[4]['median_all']:.2f}\")\n",
    "    print(f\"Position 5 correct percentage: {position_stats[4]['correct_percentage']:.1f}% ({position_stats[4]['n_true']}/{position_stats[4]['total']})\")\n",
    "    \n",
    "    # Set up the figure\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    \n",
    "    # Create the boxplot\n",
    "    ax = sns.boxplot(x=\"position\", y=\"confidence\", hue=\"is_true\", \n",
    "                 data=df, palette={\"True\": \"mediumseagreen\", \"False\": \"tomato\"})\n",
    "    \n",
    "    # Add individual data points\n",
    "    sns.stripplot(x=\"position\", y=\"confidence\", hue=\"is_true\", \n",
    "               data=df, dodge=True, alpha=0.3, size=4, linewidth=1,\n",
    "               palette={\"True\": \"darkgreen\", \"False\": \"darkred\"})\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title(\"DeepSeek-R1 Confidence Scores by Candidate Position\", fontsize=16)\n",
    "    plt.xlabel(\"Candidate Position (by confidence ranking)\", fontsize=14)\n",
    "    plt.ylabel(\"Confidence Score\", fontsize=14)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Create legend without duplicate items\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    plt.legend(handles[:2], [\"Correct Structure\", \"Incorrect Structure\"], title=\"Structure\", fontsize=12)\n",
    "    \n",
    "    # Add text with count statistics for each position\n",
    "    for i in range(1, 6):\n",
    "        pos_data = df[df[\"position\"] == i]\n",
    "        true_data = pos_data[pos_data[\"is_true\"] == \"True\"]\n",
    "        false_data = pos_data[pos_data[\"is_true\"] == \"False\"]\n",
    "        \n",
    "        n_true = len(true_data)\n",
    "        n_false = len(false_data)\n",
    "        total = n_true + n_false\n",
    "        \n",
    "        text = f\"n={total}\\nCorrect: {n_true}\\nIncorrect: {n_false}\"\n",
    "        plt.text(i-1, 0.05, text, ha='center', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save or display the figure\n",
    "    if output_file:\n",
    "        plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    return position_stats\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the analysis.\"\"\"\n",
    "    # Define input and output paths\n",
    "    json_dirs = [\n",
    "        \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_1_sim_finished_clean\",\n",
    "        \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_2_sim_aug_finished_clean\",\n",
    "        \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_3_sim+noise_finished_clean\",\n",
    "        \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_4_exp_d1_finished_clean\",\n",
    "        \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_5_exp_d1_aug_finished_clean\",\n",
    "        \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_6_exp_d4_finished_clean\"\n",
    "    ]\n",
    "    \n",
    "    reference_csv = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "    \n",
    "    # Process each directory and combine results\n",
    "    all_results = []\n",
    "    all_confidences = []\n",
    "    \n",
    "    for json_dir in json_dirs:\n",
    "        print(f\"Processing {json_dir}...\")\n",
    "        results_df, confidences_df = process_directory(json_dir, reference_csv)\n",
    "        \n",
    "        if not results_df.empty:\n",
    "            all_results.append(results_df)\n",
    "            all_confidences.append(confidences_df)\n",
    "    \n",
    "    # Combine all results\n",
    "    combined_results = pd.concat(all_results) if all_results else pd.DataFrame()\n",
    "    combined_confidences = pd.concat(all_confidences) if all_confidences else pd.DataFrame()\n",
    "    \n",
    "    if combined_results.empty:\n",
    "        print(\"No valid results found.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Analyzing {len(combined_results)} total items...\")\n",
    "    \n",
    "    # Generate the plot and statistics\n",
    "    stats = plot_confidence_by_position_with_stats(combined_confidences, \"deepseek_confidence_by_position.png\")\n",
    "    \n",
    "    return combined_results, combined_confidences, stats\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70d848a-94b6-4dce-b90d-f2ad6a65e6e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c868bcc7-2057-4c7c-98e2-8715883558b3",
   "metadata": {},
   "source": [
    "### V4 HSQC - note done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29116905-6dfa-474a-9424-a2bb7fa56079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Function to load reference data\n",
    "def load_reference_data(csv_path):\n",
    "    \"\"\"Load reference SMILES from CSV file.\"\"\"\n",
    "    ref_df = pd.read_csv(csv_path)\n",
    "    # Convert to dictionary for faster lookups\n",
    "    return ref_df.set_index('sample-id')['SMILES'].to_dict()\n",
    "\n",
    "# Function to get base sample ID (before underscore)\n",
    "def get_base_sample_id(sample_id):\n",
    "    \"\"\"Extract base sample ID (part before underscore).\"\"\"\n",
    "    return sample_id.split('_')[0] if sample_id else ''\n",
    "\n",
    "# Function to safely navigate nested dictionary keys\n",
    "def get_nested(data, keys, default=None):\n",
    "    \"\"\"Safely navigate nested dictionary structure.\"\"\"\n",
    "    temp = data\n",
    "    for key in keys:\n",
    "        if isinstance(temp, dict) and key in temp:\n",
    "            temp = temp[key]\n",
    "        else:\n",
    "            return default\n",
    "    return temp\n",
    "\n",
    "# Function to process a single JSON file and extract HSQC rankings\n",
    "def process_json_file(file_path, reference_data):\n",
    "    \"\"\"\n",
    "    Process a single JSON file, extract HSQC rankings, and determine correctness.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the JSON file\n",
    "        reference_data: Dictionary mapping sample IDs to true SMILES\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries with position, confidence, and correctness data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load JSON data\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Extract sample ID\n",
    "        sample_id = get_nested(data, [\"molecule_data\", \"sample_id\"])\n",
    "        if not sample_id:\n",
    "            return []\n",
    "            \n",
    "        # Get base sample ID for reference matching\n",
    "        base_sample_id = get_base_sample_id(sample_id)\n",
    "        \n",
    "        # Get correct SMILES\n",
    "        true_smiles = reference_data.get(base_sample_id)\n",
    "        if true_smiles is None:\n",
    "            return []\n",
    "        \n",
    "        # Extract candidate molecules from each analysis type\n",
    "        all_molecules = []\n",
    "        candidate_analysis = get_nested(data, [\"molecule_data\", \"candidate_analysis\"], {})\n",
    "        \n",
    "        for analysis_type in ['forward_synthesis', 'mol2mol', 'mmst']:\n",
    "            if analysis_type in candidate_analysis:\n",
    "                molecules = get_nested(candidate_analysis, [analysis_type, \"molecules\"], [])\n",
    "                for mol in molecules:\n",
    "                    try:\n",
    "                        hsqc_score = get_nested(mol, [\"nmr_analysis\", \"matching_scores\", \"by_spectrum\", \"HSQC\"])\n",
    "                        if hsqc_score is not None:\n",
    "                            all_molecules.append({\n",
    "                                'smiles': mol['smiles'],\n",
    "                                'hsqc_score': hsqc_score,\n",
    "                                'is_true': (mol['smiles'] == true_smiles)\n",
    "                            })\n",
    "                    except (KeyError, TypeError):\n",
    "                        continue\n",
    "        \n",
    "        # Sort by HSQC score (lower is better)\n",
    "        all_molecules.sort(key=lambda x: x['hsqc_score'] if x['hsqc_score'] is not None else float('inf'))\n",
    "        \n",
    "        # Process top 5 candidates\n",
    "        results = []\n",
    "        for position, mol in enumerate(all_molecules[:5], 1):\n",
    "            results.append({\n",
    "                'sample_id': sample_id,\n",
    "                'position': position,\n",
    "                'hsqc_score': mol['hsqc_score'],\n",
    "                'is_true': mol['is_true'],\n",
    "                'smiles': mol['smiles']\n",
    "            })\n",
    "        \n",
    "        # Get experiment type from directory name\n",
    "        dir_name = os.path.basename(os.path.dirname(file_path))\n",
    "        if \"sim+noise\" in dir_name.lower():\n",
    "            experiment = \"Sim Data + Noise\"\n",
    "        elif \"sim_aug\" in dir_name.lower() or \"sim_d1_aug\" in dir_name.lower():\n",
    "            experiment = \"Sim Data + Wrong Guess\"\n",
    "        elif \"sim\" in dir_name.lower():\n",
    "            experiment = \"Sim Data\"\n",
    "        elif \"exp_d1_aug\" in dir_name.lower():\n",
    "            experiment = \"Exp Data + Wrong Guess\"\n",
    "        elif \"exp_d4\" in dir_name.lower():\n",
    "            experiment = \"Exp Data d4\"\n",
    "        elif \"exp\" in dir_name.lower():\n",
    "            experiment = \"Exp Data\"\n",
    "        else:\n",
    "            experiment = \"Unknown\"\n",
    "            \n",
    "        # Add experiment to each result\n",
    "        for result in results:\n",
    "            result['experiment'] = experiment\n",
    "            \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# Function to process a directory of JSON files\n",
    "def process_directory(json_dir, reference_csv):\n",
    "    \"\"\"\n",
    "    Process all JSON files in a directory.\n",
    "    \n",
    "    Args:\n",
    "        json_dir: Directory containing JSON files\n",
    "        reference_csv: Path to reference CSV file\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with position, HSQC score, and correctness data\n",
    "    \"\"\"\n",
    "    # Load reference data\n",
    "    reference_data = load_reference_data(reference_csv)\n",
    "    \n",
    "    # Find all JSON files\n",
    "    json_files = glob.glob(os.path.join(json_dir, \"*.json\"))\n",
    "    print(f\"Found {len(json_files)} JSON files to analyze\")\n",
    "    \n",
    "    # Process each file\n",
    "    all_results = []\n",
    "    \n",
    "    for file_path in json_files:\n",
    "        results = process_json_file(file_path, reference_data)\n",
    "        if results:\n",
    "            all_results.extend(results)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Function to create a boxplot showing HSQC scores by position\n",
    "def plot_hsqc_by_position(hsqc_df, output_file=None):\n",
    "    \"\"\"\n",
    "    Create a boxplot showing HSQC scores by position.\n",
    "    \n",
    "    Args:\n",
    "        hsqc_df: DataFrame with HSQC data\n",
    "        output_file: Path to save the figure (if None, display it)\n",
    "    \"\"\"\n",
    "    # Limit to first 5 positions\n",
    "    df = hsqc_df[hsqc_df[\"position\"] <= 5].copy()\n",
    "    \n",
    "    # Convert boolean is_true to string to avoid palette issues\n",
    "    df['is_true'] = df['is_true'].astype(str)\n",
    "    \n",
    "    # Set up the figure\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    \n",
    "    # Normalize HSQC scores for visualization (lower is better, so invert)\n",
    "    # HSQC errors are typically in the range of 0-5, with lower being better\n",
    "    # We'll transform them to a 0-1 scale where 1 is best\n",
    "    df['normalized_score'] = 1 - (df['hsqc_score'] / 5)\n",
    "    df.loc[df['normalized_score'] < 0, 'normalized_score'] = 0  # Cap at 0 for any very large errors\n",
    "    \n",
    "    # Create the boxplot\n",
    "    ax = sns.boxplot(x=\"position\", y=\"normalized_score\", hue=\"is_true\", \n",
    "                 data=df, palette={\"True\": \"mediumseagreen\", \"False\": \"tomato\"})\n",
    "    \n",
    "    # Add individual data points\n",
    "    sns.stripplot(x=\"position\", y=\"normalized_score\", hue=\"is_true\", \n",
    "               data=df, dodge=True, alpha=0.3, size=4, linewidth=1,\n",
    "               palette={\"True\": \"darkgreen\", \"False\": \"darkred\"})\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title(\"HSQC Score Performance by Candidate Position\", fontsize=16)\n",
    "    plt.xlabel(\"Candidate Position (by HSQC ranking)\", fontsize=14)\n",
    "    plt.ylabel(\"Normalized Score (higher is better)\", fontsize=14)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Create legend without duplicate items\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    plt.legend(handles[:2], [\"Correct Structure\", \"Incorrect Structure\"], title=\"Structure\", fontsize=12, loc='upper right')\n",
    "    \n",
    "    # Add text with count statistics for each position\n",
    "    for i in range(1, 6):\n",
    "        pos_data = df[df[\"position\"] == i]\n",
    "        true_data = pos_data[pos_data[\"is_true\"] == \"True\"]\n",
    "        false_data = pos_data[pos_data[\"is_true\"] == \"False\"]\n",
    "        \n",
    "        n_true = len(true_data)\n",
    "        n_false = len(false_data)\n",
    "        total = n_true + n_false\n",
    "        \n",
    "        text = f\"n={total}\\nCorrect: {n_true}\\nIncorrect: {n_false}\"\n",
    "        plt.text(i-1, 0.05, text, ha='center', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save or display the figure\n",
    "    if output_file:\n",
    "        plt.savefig(output_file, dpi=300, bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()\n",
    "        \n",
    "    return plt.gcf()\n",
    "\n",
    "# Main function to run the analysis\n",
    "def main():\n",
    "    \"\"\"Run the complete analysis.\"\"\"\n",
    "    # Define input and output paths\n",
    "    json_dirs = [\n",
    "        \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_1_sim_finished_clean\",\n",
    "        \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_2_sim_aug_finished_clean\",\n",
    "        \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_3_sim+noise_finished_clean\",\n",
    "        \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_4_exp_d1_finished_clean\",\n",
    "        \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_5_exp_d1_aug_finished_clean\",\n",
    "        \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_6_exp_d4_finished_clean\"\n",
    "    ]\n",
    "    \n",
    "    reference_csv = \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "    \n",
    "    # Process each directory and combine results\n",
    "    all_results = []\n",
    "    \n",
    "    for json_dir in json_dirs:\n",
    "        print(f\"Processing {json_dir}...\")\n",
    "        results_df = process_directory(json_dir, reference_csv)\n",
    "        \n",
    "        if not results_df.empty:\n",
    "            all_results.append(results_df)\n",
    "    \n",
    "    # Combine all results\n",
    "    combined_results = pd.concat(all_results) if all_results else pd.DataFrame()\n",
    "    \n",
    "    if combined_results.empty:\n",
    "        print(\"No valid results found.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Analyzing {len(combined_results)} total items...\")\n",
    "    \n",
    "    # Generate comparison plot for HSQC \n",
    "    fig = plot_hsqc_by_position(combined_results, \"hsqc_score_by_position.png\")\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\nSUMMARY STATISTICS:\")\n",
    "    \n",
    "    # Calculate accuracy by position\n",
    "    for position in range(1, 6):\n",
    "        pos_data = combined_results[combined_results[\"position\"] == position]\n",
    "        if not pos_data.empty:\n",
    "            correct = pos_data[\"is_true\"].sum()\n",
    "            total = len(pos_data)\n",
    "            print(f\"Position {position}: {correct}/{total} correct ({correct/total*100:.1f}%)\")\n",
    "    \n",
    "    return combined_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509dbd43-c339-4e33-80a0-229565a28525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931acb3c-6410-4e93-8ea6-ab3fab09d288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff61334-c75f-4c8b-aca1-36c402c38f80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16161fee-6096-476d-9c87-08b7ab5c4acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_path) as f:\n",
    "    data = json.load(f)\n",
    "data[\"analysis_results\"][\"final_analysis\"][\"llm_responses\"][\"gemini\"][\"parsed_results\"] = raw_text__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a426d432-8c91-4ff9-adeb-d78193542ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f34dab1-2d8b-4b64-9c02-1e28ca341df9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58389398-bbcb-4180-a82e-260a7f485513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8434676d-34a6-4b0b-8600-eb5b1bbb0a8f",
   "metadata": {},
   "source": [
    "### Basline vs LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa4db32-6b06-42c0-b69f-b0eff2bd1785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import to_rgba\n",
    "\n",
    "# Set the style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"deep\")\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Define experimental conditions\n",
    "experiment_conditions = [\n",
    "    \"Exp-1: Simulated / Broad MW / Correct\",\n",
    "    \"Exp-2: Simulated / Narrow MW / Correct\",\n",
    "    \"Exp-3: Simulated / Broad MW / ROM\",\n",
    "    \"Exp-4: Simulated / Narrow MW / ROM\",\n",
    "    \"Exp-5: Experimental / Broad MW / Correct\",\n",
    "    \"Exp-6: Experimental / Narrow MW / Correct\", \n",
    "    \"Exp-7: Experimental / Broad MW / ROM\",\n",
    "    \"Exp-8: Simulated+Noise / Broad MW / Correct\"\n",
    "]\n",
    "\n",
    "# Create shorter labels for the plot\n",
    "exp_labels = [\n",
    "    \"Sim/Broad/Correct\",\n",
    "    \"Sim/Narrow/Correct\",\n",
    "    \"Sim/Broad/ROM\",\n",
    "    \"Sim/Narrow/ROM\",\n",
    "    \"Exp/Broad/Correct\",\n",
    "    \"Exp/Narrow/Correct\", \n",
    "    \"Exp/Broad/ROM\",\n",
    "    \"Sim+Noise/Broad/Correct\"\n",
    "]\n",
    "\n",
    "# Define models\n",
    "models = [\n",
    "    {\"name\": \"HSQC Matching\", \"color\": \"#999999\", \"is_baseline\": True},\n",
    "    {\"name\": \"Claude 3.5 Sonnet\", \"color\": \"#6366F1\", \"is_baseline\": False},\n",
    "    {\"name\": \"Claude 3.7 Sonnet-Thinking\", \"color\": \"#3B82F6\", \"is_baseline\": False},\n",
    "    {\"name\": \"DeepSeek-R1\", \"color\": \"#10B981\", \"is_baseline\": False},\n",
    "    {\"name\": \"Gemini-Thinking\", \"color\": \"#F59E0B\", \"is_baseline\": False},\n",
    "    {\"name\": \"o3-mini\", \"color\": \"#EC4899\", \"is_baseline\": False},\n",
    "    {\"name\": \"Kimi 1.5\", \"color\": \"#8B5CF6\", \"is_baseline\": False}\n",
    "]\n",
    "\n",
    "# Create dummy data based on the description\n",
    "# Baseline accuracy for each experiment\n",
    "baseline_accuracy = np.array([0.85, 0.88, 0.62, 0.70, 0.60, 0.68, 0.52, 0.50])\n",
    "\n",
    "# Create random data with the described patterns for LLM models\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Function to generate accuracies for a specific model following the described patterns\n",
    "def generate_model_accuracies(baseline, model_index):\n",
    "    # Starting point for each model (slight variations)\n",
    "    base_improvement = np.array([\n",
    "        0.03,  # Sim/Broad/Correct - small improvement\n",
    "        0.02,  # Sim/Narrow/Correct - small improvement\n",
    "        0.10,  # Sim/Broad/ROM - moderate improvement\n",
    "        0.08,  # Sim/Narrow/ROM - moderate improvement\n",
    "        0.15,  # Exp/Broad/Correct - larger improvement\n",
    "        0.12,  # Exp/Narrow/Correct - larger improvement\n",
    "        0.20,  # Exp/Broad/ROM - largest improvement\n",
    "        0.29   # Sim+Noise/Broad/Correct - dramatic improvement\n",
    "    ])\n",
    "    \n",
    "    # Add some model-specific variation (+/- up to 5%)\n",
    "    model_variation = (np.random.random(len(baseline)) - 0.5) * 0.10\n",
    "    \n",
    "    # More variation for reasoning models (improve more on challenging cases)\n",
    "    if model_index >= 2:  # Reasoning models\n",
    "        # Enhance improvement for challenging cases (noise and experimental)\n",
    "        base_improvement[4:] += 0.03 * (model_index - 1)  # Progressive boost\n",
    "    \n",
    "    # Calculate accuracies, ensuring they don't exceed 1.0\n",
    "    accuracies = np.minimum(baseline + base_improvement + model_variation, 0.95)\n",
    "    \n",
    "    return accuracies\n",
    "\n",
    "# Generate data for all models\n",
    "all_accuracies = []\n",
    "for i, model in enumerate(models):\n",
    "    if model[\"is_baseline\"]:\n",
    "        accuracies = baseline_accuracy\n",
    "    else:\n",
    "        accuracies = generate_model_accuracies(baseline_accuracy, i)\n",
    "    \n",
    "    # Create records for each experiment\n",
    "    for j, exp in enumerate(experiment_conditions):\n",
    "        all_accuracies.append({\n",
    "            \"experiment\": exp,\n",
    "            \"experiment_short\": exp_labels[j],\n",
    "            \"model\": model[\"name\"],\n",
    "            \"accuracy\": accuracies[j],\n",
    "            \"color\": model[\"color\"],\n",
    "            \"is_baseline\": model[\"is_baseline\"]\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(all_accuracies)\n",
    "\n",
    "# Create a figure with a grid of subplots - one per experiment\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10), sharex=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot each experiment in its own subplot\n",
    "for i, exp in enumerate(experiment_conditions):\n",
    "    ax = axes[i]\n",
    "    exp_data = df[df['experiment'] == exp]\n",
    "    \n",
    "    # Sort by accuracy within each group to see ranking\n",
    "    exp_data = exp_data.sort_values('accuracy', ascending=False)\n",
    "    \n",
    "    # Extract baseline data\n",
    "    baseline_data = exp_data[exp_data['is_baseline']]\n",
    "    baseline_value = baseline_data['accuracy'].values[0]\n",
    "    \n",
    "    # Extract non-baseline data\n",
    "    model_data = exp_data[~exp_data['is_baseline']]\n",
    "    \n",
    "    # Plot baseline as a horizontal line\n",
    "    ax.axhline(y=baseline_value, color='black', linestyle='--', \n",
    "              alpha=0.7, label='_nolegend_')\n",
    "    \n",
    "    # Annotate baseline\n",
    "    ax.text(0.02, baseline_value + 0.01, f\"Baseline: {baseline_value:.2f}\", \n",
    "            transform=ax.get_yaxis_transform(), ha='left', va='bottom', \n",
    "            fontsize=9, fontstyle='italic')\n",
    "    \n",
    "    # Plot model bars\n",
    "    bars = ax.bar(range(len(model_data)), model_data['accuracy'], \n",
    "                 color=model_data['color'].tolist())\n",
    "    \n",
    "    # Add improvement annotations\n",
    "    for j, (_, row) in enumerate(model_data.iterrows()):\n",
    "        improvement = row['accuracy'] - baseline_value\n",
    "        if improvement > 0:\n",
    "            ax.text(j, row['accuracy'] + 0.01, f\"+{improvement:.2f}\", \n",
    "                    ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    # Customize subplot\n",
    "    ax.set_title(exp_labels[i], fontsize=11, fontweight='bold')\n",
    "    ax.set_ylim(0.45, 1.0)  # Set y-axis limit\n",
    "    ax.set_xticks(range(len(model_data)))\n",
    "    ax.set_xticklabels([name.split()[0] for name in model_data['model']], \n",
    "                      rotation=45, ha='right', fontsize=9)\n",
    "    \n",
    "    # Highlight the best performing model\n",
    "    best_idx = model_data['accuracy'].idxmax()\n",
    "    best_model = model_data.loc[best_idx]\n",
    "    bars[model_data.index.get_loc(best_idx)].set_edgecolor('black')\n",
    "    bars[model_data.index.get_loc(best_idx)].set_linewidth(2)\n",
    "    \n",
    "    # Add a grid for readability\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "    \n",
    "    # Group experimental conditions visually\n",
    "    if i < 4:  # Simulated data\n",
    "        ax.patch.set_facecolor(to_rgba('#f8f9fa', 0.2))\n",
    "    else:  # Experimental data or noise\n",
    "        ax.patch.set_facecolor(to_rgba('#e9ecef', 0.2))\n",
    "\n",
    "# Add a common y-label\n",
    "fig.text(0.01, 0.5, 'Top-1 Accuracy', va='center', rotation='vertical', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add a super title\n",
    "plt.suptitle('Comparison of HSQC Matching vs. LLM-Enhanced Structure Elucidation', \n",
    "             fontsize=16, fontweight='bold', y=0.98)\n",
    "\n",
    "# Create a common legend for all subplots\n",
    "legend_elements = []\n",
    "for model in models:\n",
    "    if not model[\"is_baseline\"]:  # Skip baseline in the legend (shown as line)\n",
    "        legend_elements.append(plt.Rectangle((0,0), 1, 1, color=model[\"color\"], \n",
    "                                            label=model[\"name\"]))\n",
    "\n",
    "fig.legend(handles=legend_elements, loc='upper center', \n",
    "          bbox_to_anchor=(0.5, 0.04), ncol=6, fontsize=11)\n",
    "\n",
    "# Add explanatory text\n",
    "fig.text(0.5, 0.01, \n",
    "         \"Figure 5: Comparison of baseline HSQC matching vs. LLM-enhanced accuracy across experimental conditions. \" + \n",
    "         \"Each subplot represents a different experimental condition, with the baseline HSQC matching accuracy shown as a dashed line. \" +\n",
    "         \"Bars indicate Top-1 accuracy for different LLM models, with improvements over baseline annotated above each bar. \" +\n",
    "         \"Note the larger improvements in challenging conditions (experimental data, noise, and ROM starting structures).\",\n",
    "         ha='center', fontsize=10, style='italic', wrap=True)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(rect=[0.02, 0.08, 0.98, 0.95])\n",
    "\n",
    "# Save figure\n",
    "plt.savefig('performance_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Now create a summary figure for baseline only vs. best LLM across all experiments\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Get baseline data\n",
    "baseline_df = df[df['is_baseline']].copy()\n",
    "\n",
    "# For each experiment, get the best performing LLM model\n",
    "best_llm_rows = []\n",
    "for exp in experiment_conditions:\n",
    "    exp_data = df[(df['experiment'] == exp) & (~df['is_baseline'])]\n",
    "    best_row = exp_data.loc[exp_data['accuracy'].idxmax()]\n",
    "    best_llm_rows.append(best_row)\n",
    "\n",
    "# Create dataframe with best LLM results\n",
    "best_llm_df = pd.DataFrame(best_llm_rows)\n",
    "\n",
    "# Plot as grouped bar chart\n",
    "x = np.arange(len(experiment_conditions))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "baseline_bars = ax.bar(x - width/2, baseline_df['accuracy'], width, \n",
    "                     color='#999999', label='HSQC Matching Baseline')\n",
    "llm_bars = ax.bar(x + width/2, best_llm_df['accuracy'], width, \n",
    "                color='#3B82F6', label='Best LLM-Enhanced')\n",
    "\n",
    "# Add improvement annotations\n",
    "for i, (base, best) in enumerate(zip(baseline_df['accuracy'], best_llm_df['accuracy'])):\n",
    "    improvement = best - base\n",
    "    if improvement > 0.05:  # Only annotate significant improvements\n",
    "        ax.annotate(f'+{improvement:.2f}',\n",
    "                   xy=(i + width/2, best + 0.01),\n",
    "                   ha='center', va='bottom',\n",
    "                   fontweight='bold', color='#1e40af')\n",
    "\n",
    "# Customize the chart\n",
    "ax.set_ylabel('Top-1 Accuracy', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Baseline vs. Best LLM-Enhanced Performance Across Experimental Conditions', \n",
    "            fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(exp_labels, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "\n",
    "# Add gridlines for readability\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "ax.set_ylim(0.4, 1.0)\n",
    "\n",
    "# Add a divider to visually separate simulated from experimental conditions\n",
    "ax.axvline(x=3.5, color='black', linestyle='--', alpha=0.5)\n",
    "ax.text(1.5, 0.42, 'Simulated Data', ha='center', fontsize=10, fontweight='bold')\n",
    "ax.text(5.5, 0.42, 'Experimental/Noise Data', ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Add figure caption\n",
    "plt.figtext(0.5, 0.01, \n",
    "           \"Figure 4: Comparison of baseline HSQC matching accuracy vs. best LLM-enhanced performance across all experimental conditions. \" + \n",
    "           \"Note the substantial improvements in challenging scenarios (right side) with experimental data, noise, or incorrect starting structures.\",\n",
    "           ha='center', fontsize=10, style='italic', wrap=True)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.05, 1, 0.98])\n",
    "plt.savefig('baseline_vs_best_llm.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af28f758-6c9c-4bd9-a962-2205d7c936b7",
   "metadata": {},
   "source": [
    "## Plot Molecules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86859dd-6cea-41bf-ba6e-4c45846f8c6a",
   "metadata": {},
   "source": [
    "### Richard Molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28773b89-0197-49eb-a125-a1da2c0ca04a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import Descriptors\n",
    "import math\n",
    "\n",
    "def plot_molecules_from_csv(csv_path, molecules_per_row=5):\n",
    "    \"\"\"\n",
    "    Plot all molecules from a CSV file with their sample ID and molecular weight.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    csv_path : str\n",
    "        Path to the CSV file\n",
    "    molecules_per_row : int, optional\n",
    "        Number of molecules to plot in each row (default is 5)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    matplotlib figure with molecule grid\n",
    "    \"\"\"\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Extract SMILES and Sample ID columns (adjust column names as needed)\n",
    "    smiles_column = [col for col in df.columns if 'SMILES' in col.upper()][0]\n",
    "    sample_id_column = [col for col in df.columns if 'SAMPLE' in col.upper() and 'ID' in col.upper()][0]\n",
    "    \n",
    "    # Calculate number of rows needed\n",
    "    total_molecules = len(df)\n",
    "    num_rows = math.ceil(total_molecules / molecules_per_row)\n",
    "    \n",
    "    # Create a figure with appropriate size\n",
    "    fig, axes = plt.subplots(num_rows, molecules_per_row, \n",
    "                              figsize=(4*molecules_per_row, 4*num_rows))\n",
    "    \n",
    "    # Flatten axes for easier indexing if multiple rows\n",
    "    if num_rows > 1:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    # Plot each molecule\n",
    "    for i, (_, row) in enumerate(df.iterrows()):\n",
    "        # Get SMILES and Sample ID\n",
    "        smiles = row[smiles_column]\n",
    "        sample_id = row[sample_id_column]\n",
    "        \n",
    "        # Generate molecule\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        \n",
    "        # Calculate molecular weight\n",
    "        mol_weight = round(Descriptors.ExactMolWt(mol), 2)\n",
    "        \n",
    "        # Generate molecule image\n",
    "        img = Draw.MolToImage(mol, size=(300, 300))\n",
    "        \n",
    "        # Plot the molecule\n",
    "        ax = axes[i] if len(axes) > 1 else axes\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Add sample ID and molecular weight as text with larger font\n",
    "        ax.set_title(f'Sample ID: {sample_id}\\nMW: {mol_weight} g/mol', \n",
    "                     fontsize=14, fontweight='bold', wrap=True)\n",
    "    \n",
    "    # Hide any unused subplots\n",
    "    for j in range(i+1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "    \n",
    "    # Adjust layout and return figure\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Example usage\n",
    "fig = plot_molecules_from_csv('/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv')\n",
    "#plt.savefig('/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/Figures/molecule_visualization.png', dpi=300, bbox_inches='tight')\n",
    "#plt.close()\n",
    "\n",
    "print(\"Molecule visualization has been saved as 'molecule_visualization.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2699d7b9-6cf3-44bf-97bb-19ed1d25ea90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "fig = plot_molecules_from_csv('/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/real_data/combined_real_nmr_data_no_stereo_aug.csv')\n",
    "plt.savefig('/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/Figures/molecule_visualization_WG.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"Molecule visualization has been saved as 'molecule_visualization.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7d8f9d-ffa5-49a9-a2a6-2431cdb2c2db",
   "metadata": {},
   "source": [
    "### Lukas Molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d79ac3c-516a-4bbb-92ea-7cb9a3e1efc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "fig = plot_molecules_from_csv('/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/53_Lukas_real_data/cleaned_data_aug_CLEAN.csv')\n",
    "plt.savefig('/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/Figures/molecule_visualization_aug_Lukas_WG.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"Molecule visualization has been saved as 'molecule_visualization_aug_Lukas_WG.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b0561c-96ed-48c2-b582-f5a1c0376ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "fig = plot_molecules_from_csv('/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/53_Lukas_real_data/cleaned_data_CLEAN.csv')\n",
    "plt.savefig('/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/Figures/molecule_visualization_Lukas_WG.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"Molecule visualization has been saved as 'molecule_visualization.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a6f86a-e394-42cc-865b-e6a31ddba137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5c50875-e40f-482e-bbe3-7bee1810f6c5",
   "metadata": {},
   "source": [
    "## Plot successes for each method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc875fa-b2fe-4106-bab4-ae3143696fa6",
   "metadata": {},
   "source": [
    "### V1 Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae538c2-e7c2-4abd-8af6-9439d88ca65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def load_reference_data(csv_path):\n",
    "    \"\"\"Load reference SMILES from CSV file.\"\"\"\n",
    "    ref_df = pd.read_csv(csv_path)\n",
    "    # Convert to dictionary for faster lookups\n",
    "    return ref_df.set_index('sample-id')['SMILES'].to_dict()\n",
    "\n",
    "def get_base_sample_id(sample_id):\n",
    "    \"\"\"Extract base sample ID (part before underscore).\"\"\"\n",
    "    return sample_id.split('_')[0] if sample_id else ''\n",
    "\n",
    "def analyze_approaches_by_json(json_data, true_smiles):\n",
    "    \"\"\"\n",
    "    Analyze a single JSON file and return where the correct molecule was found.\n",
    "    Returns a dictionary indicating if the true molecule was found in each approach.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        candidate_analysis = json_data[\"molecule_data\"]['candidate_analysis']\n",
    "    except KeyError:\n",
    "        return None\n",
    "    \n",
    "    results = {\n",
    "        'forward_synthesis': False,\n",
    "        'mol2mol': False,\n",
    "        'mmst': False,\n",
    "        'any': False  # Was the molecule found in any approach?\n",
    "    }\n",
    "    \n",
    "    for approach in ['forward_synthesis', 'mol2mol', 'mmst']:\n",
    "        if approach in candidate_analysis:\n",
    "            molecules = candidate_analysis[approach].get('molecules', [])\n",
    "            for mol in molecules:\n",
    "                try:\n",
    "                    if mol['smiles'] == true_smiles:\n",
    "                        results[approach] = True\n",
    "                        results['any'] = True\n",
    "                        break\n",
    "                except KeyError:\n",
    "                    continue\n",
    "    \n",
    "    return results\n",
    "\n",
    "def analyze_directory_by_approach(json_dir, reference_csv):\n",
    "    \"\"\"\n",
    "    Analyze all JSON files and return counts of where correct molecules were found.\n",
    "    \"\"\"\n",
    "    # Load reference data\n",
    "    reference_data = load_reference_data(reference_csv)\n",
    "    \n",
    "    # Get all JSON files\n",
    "    json_files = glob.glob(os.path.join(json_dir, \"*.json\"))\n",
    "    print(f\"Found {len(json_files)} JSON files to analyze\")\n",
    "    \n",
    "    # Initialize counters\n",
    "    approach_counts = {\n",
    "        'forward_synthesis': 0,\n",
    "        'mol2mol': 0,\n",
    "        'mmst': 0,\n",
    "        'any': 0,\n",
    "        'total': 0\n",
    "    }\n",
    "    \n",
    "    # For storing data about individual molecules\n",
    "    molecule_data = []\n",
    "    \n",
    "    for file_path in json_files:\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                json_data = json.load(f)\n",
    "            \n",
    "            molecule_data_json = json_data.get('molecule_data', {})\n",
    "            sample_id = molecule_data_json.get('sample_id')\n",
    "            \n",
    "            if not sample_id:\n",
    "                continue\n",
    "                \n",
    "            # Get base sample ID for reference matching\n",
    "            base_sample_id = get_base_sample_id(sample_id)\n",
    "            \n",
    "            # Get correct SMILES\n",
    "            true_smiles = reference_data.get(base_sample_id)\n",
    "            if true_smiles is None:\n",
    "                print(f\"No reference SMILES found for {base_sample_id}\")\n",
    "                continue\n",
    "            \n",
    "            # Analyze where the correct molecule was found\n",
    "            results = analyze_approaches_by_json(json_data, true_smiles)\n",
    "            if results is None:\n",
    "                continue\n",
    "            \n",
    "            # Update counts\n",
    "            approach_counts['total'] += 1\n",
    "            for approach, found in results.items():\n",
    "                if found:\n",
    "                    approach_counts[approach] += 1\n",
    "            \n",
    "            # Save individual molecule data\n",
    "            molecule_data.append({\n",
    "                'sample_id': sample_id,\n",
    "                'true_smiles': true_smiles,\n",
    "                'found_in_forward_synthesis': results['forward_synthesis'],\n",
    "                'found_in_mol2mol': results['mol2mol'],\n",
    "                'found_in_mmst': results['mmst'],\n",
    "                'found_anywhere': results['any']\n",
    "            })\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return approach_counts, molecule_data\n",
    "\n",
    "def create_enhanced_comparison_plot(experiments_data, output_dir):\n",
    "    \"\"\"\n",
    "    Create an enhanced single plot comparing approach effectiveness across experiments\n",
    "    with the specified color scheme.\n",
    "    \n",
    "    Args:\n",
    "        experiments_data: List of dictionaries with experiment name and approach counts\n",
    "        output_dir: Directory to save the output\n",
    "    \"\"\"\n",
    "    # Create figure with white background\n",
    "    fig, ax = plt.subplots(figsize=(12, 8), facecolor='white')\n",
    "    ax.set_facecolor('white')\n",
    "    \n",
    "    # Define approaches and their display names\n",
    "    approaches = ['forward_synthesis', 'mol2mol', 'mmst']\n",
    "    friendly_names = {\n",
    "        'forward_synthesis': 'Retrosynthesis-Forward',\n",
    "        'mol2mol': 'Mol2Mol Analogues',\n",
    "        'mmst': 'MMST-Driven Generation'\n",
    "    }\n",
    "    \n",
    "    # Set the width of a bar and gap between experiment groups\n",
    "    bar_width = 0.275  # Slightly wider bars\n",
    "    \n",
    "    # Calculate positions for grouped bars\n",
    "    positions = {}\n",
    "    for i, approach in enumerate(approaches):\n",
    "        positions[approach] = np.arange(len(experiments_data)) + i * bar_width\n",
    "    \n",
    "    # Define colors for each approach using the provided hex codes\n",
    "    colors = {\n",
    "        'forward_synthesis': '#529356',  # Green\n",
    "        'mol2mol': '#FFB047',           # Orange\n",
    "        'mmst': '#9F45B7'               # Purple\n",
    "    }\n",
    "    \n",
    "    # Calculate the highest count for y-axis scaling\n",
    "    max_count = 0\n",
    "    for exp in experiments_data:\n",
    "        for approach in approaches:\n",
    "            if exp['counts'][approach] > max_count:\n",
    "                max_count = exp['counts'][approach]\n",
    "    \n",
    "    # Create the bars\n",
    "    bars = {}\n",
    "    for approach in approaches:\n",
    "        counts = [exp['counts'][approach] for exp in experiments_data]\n",
    "        percentages = [exp['counts'][approach] / exp['counts']['total'] * 100 if exp['counts']['total'] > 0 else 0 for exp in experiments_data]\n",
    "        \n",
    "        bars[approach] = ax.bar(\n",
    "            positions[approach],\n",
    "            counts,\n",
    "            width=bar_width,\n",
    "            color=colors[approach],\n",
    "            edgecolor='black',\n",
    "            alpha=0.9,\n",
    "            label=friendly_names[approach]\n",
    "        )\n",
    "        \n",
    "        # Add counts and percentages inside or above bars\n",
    "        for i, (bar, count, percentage) in enumerate(zip(bars[approach], counts, percentages)):\n",
    "            height = bar.get_height()\n",
    "            \n",
    "            # Always show count and percentage, even for zero values\n",
    "            if height <= 0:\n",
    "                # For zero values, place text just above the x-axis\n",
    "                ax.text(\n",
    "                    bar.get_x() + bar.get_width()/2, \n",
    "                    0.5,  # Small offset from x-axis\n",
    "                    f'0\\n(0.0%)',\n",
    "                    ha='center', \n",
    "                    va='bottom',\n",
    "                    fontsize=14,\n",
    "                    color='black'\n",
    "                )\n",
    "            else:\n",
    "                # For shorter bars, place text above\n",
    "                if height < max_count * 0.15:  # If bar is less than 15% of max height\n",
    "                    y_pos = height + max_count * 0.02\n",
    "                    color = 'black'\n",
    "                    va = 'bottom'\n",
    "                else:  # For taller bars, place text inside\n",
    "                    y_pos = height/2\n",
    "                    color = 'white'\n",
    "                    va = 'center'\n",
    "                \n",
    "                ax.text(\n",
    "                    bar.get_x() + bar.get_width()/2, \n",
    "                    y_pos,\n",
    "                    f'{count}\\n({percentage:.1f}%)',\n",
    "                    ha='center', \n",
    "                    va=va,\n",
    "                    fontsize=14,\n",
    "                    color=color\n",
    "                )\n",
    "    \n",
    "    # Add title and labels\n",
    "    ax.set_title('Comparison of Structure Generation Approaches', fontsize=20, fontweight='bold')\n",
    "    ax.set_ylabel('Number of Molecules', fontsize=16)\n",
    "    \n",
    "    # Increase the size of tick labels\n",
    "    ax.tick_params(axis='both', labelsize=14)\n",
    "    \n",
    "    # Set x-axis ticks at the center of each experiment group\n",
    "    middle_positions = [(positions['forward_synthesis'][i] + positions['mmst'][i]) / 2 for i in range(len(experiments_data))]\n",
    "    ax.set_xticks(middle_positions)\n",
    "    \n",
    "    # Use single-line labels without rotation\n",
    "    flat_labels = [exp['label'].replace('\\n', ' ') for exp in experiments_data]\n",
    "    ax.set_xticklabels(flat_labels, fontsize=14)\n",
    "    \n",
    "    # Add grid with light gray color\n",
    "    ax.grid(True, alpha=0.3, color='gray', linestyle='--', axis='y')\n",
    "    \n",
    "    # Add legend with enhanced styling\n",
    "    legend = ax.legend(fontsize=14, loc='upper center', bbox_to_anchor=(0.5, -0.12),\n",
    "                      frameon=True, fancybox=True, shadow=True, ncol=3)\n",
    "    \n",
    "    # Add text showing total molecules analyzed for each experiment\n",
    "    for i, exp in enumerate(experiments_data):\n",
    "        ax.text(\n",
    "            middle_positions[i],\n",
    "            -max_count * 0.05,  # Position below the x-axis\n",
    "            f'Total: {exp[\"counts\"][\"total\"]}',\n",
    "            ha='center',\n",
    "            va='top',\n",
    "            fontsize=14,\n",
    "            fontweight='bold'\n",
    "        )\n",
    "    \n",
    "    # Set y-axis limit with a little headroom\n",
    "    ax.set_ylim(0, max_count * 1.2)\n",
    "    \n",
    "    # Remove top and right spines for cleaner look\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Adjust figure size to accommodate legend\n",
    "    fig.subplots_adjust(bottom=0.18)\n",
    "    \n",
    "    # Save the plot with high resolution\n",
    "    output_path = os.path.join(output_dir, \"enhanced_approach_comparison.png\")\n",
    "    fig.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved enhanced comparison figure to: {output_path}\")\n",
    "    \n",
    "    # Also save as SVG for vector graphics\n",
    "    svg_output_path = os.path.join(output_dir, \"enhanced_approach_comparison.svg\")\n",
    "    fig.savefig(svg_output_path, format='svg', bbox_inches='tight')\n",
    "    print(f\"Saved enhanced comparison figure as SVG to: {svg_output_path}\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def plot_approach_comparison(approach_counts, experiment_label=\"\"):\n",
    "    \"\"\"\n",
    "    Create a bar chart showing the number of correct molecules found by each approach.\n",
    "    \"\"\"\n",
    "    # Create figure with white background\n",
    "    fig, ax = plt.subplots(figsize=(10, 6), facecolor='white')\n",
    "    ax.set_facecolor('white')\n",
    "    \n",
    "    # Data for plotting\n",
    "    approaches = ['forward_synthesis', 'mol2mol', 'mmst']\n",
    "    friendly_names = {\n",
    "        'forward_synthesis': 'Retrosynthesis',\n",
    "        'mol2mol': 'Mol2Mol',\n",
    "        'mmst': 'MMST'\n",
    "    }\n",
    "    \n",
    "    # Calculate percentages\n",
    "    total = approach_counts['total']\n",
    "    percentages = [approach_counts[a] / total * 100 if total > 0 else 0 for a in approaches]\n",
    "    counts = [approach_counts[a] for a in approaches]\n",
    "    \n",
    "    # Define colors for each approach\n",
    "    colors = {'forward_synthesis': '#6366F1', 'mol2mol': '#3B82F6', 'mmst': '#10B981'}\n",
    "    \n",
    "    # Create the bars\n",
    "    bars = ax.bar(\n",
    "        [friendly_names[a] for a in approaches],\n",
    "        counts,\n",
    "        color=[colors[a] for a in approaches],\n",
    "        edgecolor='black',\n",
    "        alpha=0.7\n",
    "    )\n",
    "    \n",
    "    # Add title and labels\n",
    "    title = f'Correct Molecules Found by Approach\\n{experiment_label}'\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.set_xlabel('Approach', fontsize=14)\n",
    "    ax.set_ylabel('Number of Molecules', fontsize=14)\n",
    "    \n",
    "    # Customize y-axis to extend slightly above the maximum value\n",
    "    max_count = max(counts)\n",
    "    ax.set_ylim(0, max_count * 1.1)\n",
    "    \n",
    "    # Add grid with light gray color\n",
    "    ax.grid(True, alpha=0.3, color='gray', linestyle='--', axis='y')\n",
    "    \n",
    "    # Add counts and percentages above bars\n",
    "    for bar, count, percentage in zip(bars, counts, percentages):\n",
    "        height = bar.get_height()\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width()/2, \n",
    "            height + 0.1,\n",
    "            f'{count} ({percentage:.1f}%)',\n",
    "            ha='center', \n",
    "            va='bottom',\n",
    "            fontsize=12\n",
    "        )\n",
    "    \n",
    "    # Increase tick label size\n",
    "    ax.tick_params(axis='both', labelsize=12)\n",
    "    \n",
    "    # Add text showing total molecules analyzed\n",
    "    ax.text(0.02, 0.98, f'Total molecules: {total}',\n",
    "            transform=ax.transAxes,\n",
    "            verticalalignment='top',\n",
    "            horizontalalignment='left',\n",
    "            fontsize=12,\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig, pd.DataFrame({\n",
    "        'Approach': [friendly_names[a] for a in approaches],\n",
    "        'Count': counts,\n",
    "        'Percentage': percentages\n",
    "    })\n",
    "\n",
    "def main():\n",
    "    # Define the experiments\n",
    "    experiments = [\n",
    "        {\n",
    "            \"label\": \"Simulated Data\",\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_1_sim_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"Simulated Data with Wrong Guess\",\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_2_sim_aug_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Define output directory for figures and data\n",
    "    output_dir = \"./output\"\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Store results for each experiment\n",
    "    experiments_data = []\n",
    "    \n",
    "    # Process each experiment\n",
    "    for experiment in experiments:\n",
    "        print(f\"\\nAnalyzing {experiment['label']}...\")\n",
    "        \n",
    "        # Get approach counts and molecule data\n",
    "        approach_counts, molecule_data = analyze_directory_by_approach(\n",
    "            experiment[\"json_directory\"], \n",
    "            experiment[\"reference_csv\"]\n",
    "        )\n",
    "        \n",
    "        # Create and show individual plot\n",
    "        fig, summary_df = plot_approach_comparison(approach_counts, experiment['label'])\n",
    "        \n",
    "        # Save the plot\n",
    "        output_path = os.path.join(output_dir, f\"approach_comparison_{experiment['label'].replace(' ', '_').replace('\\\\n', '_')}.png\")\n",
    "        fig.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Saved figure to: {output_path}\")\n",
    "        \n",
    "        # Save the summary data\n",
    "        summary_path = os.path.join(output_dir, f\"approach_summary_{experiment['label'].replace(' ', '_').replace('\\\\n', '_')}.csv\")\n",
    "        summary_df.to_csv(summary_path, index=False)\n",
    "        print(f\"Saved summary to: {summary_path}\")\n",
    "        \n",
    "        # Save the molecule-level data\n",
    "        if molecule_data:\n",
    "            molecule_df = pd.DataFrame(molecule_data)\n",
    "            molecule_path = os.path.join(output_dir, f\"molecule_data_{experiment['label'].replace(' ', '_').replace('\\\\n', '_')}.csv\")\n",
    "            molecule_df.to_csv(molecule_path, index=False)\n",
    "            print(f\"Saved molecule data to: {molecule_path}\")\n",
    "        \n",
    "        # Store data for comparison plot\n",
    "        experiments_data.append({\n",
    "            'label': experiment['label'],\n",
    "            'counts': approach_counts\n",
    "        })\n",
    "        \n",
    "        # Print overall counts\n",
    "        print(\"\\nApproach counts:\")\n",
    "        for approach, count in approach_counts.items():\n",
    "            if approach not in ['total', 'any']:\n",
    "                percentage = count / approach_counts['total'] * 100 if approach_counts['total'] > 0 else 0\n",
    "                print(f\"  {approach}: {count} ({percentage:.1f}%)\")\n",
    "        print(f\"  Total molecules: {approach_counts['total']}\")\n",
    "    \n",
    "    # Create enhanced comparison plot across experiments with better styling and colors\n",
    "    create_enhanced_comparison_plot(experiments_data, output_dir)\n",
    "    \n",
    "    # Create a markdown file with the figure description\n",
    "    figure_description = \"\"\"\n",
    "# Figure X: Comparison of Structure Generation Approaches\n",
    "\n",
    "Comparison of the three complementary structure generation approaches (Retrosynthesis-Forward in green, Mol2Mol Analogues in orange, and MMST-Driven Generation in purple) across two experimental conditions. Left: Performance with correct initial structure. Right: Performance with regioisomeric initial structure (wrong starting guess). Numbers indicate the count of correct molecules found by each approach, with percentages in parentheses. Total molecules in both datasets: 34.\n",
    "\n",
    "## Key Findings\n",
    "\n",
    "**With Correct Initial Structure:**\n",
    "The Retrosynthesis-Forward approach demonstrates exceptional performance when provided with the correct starting structure. This is expected behavior as this method effectively explores the local chemical space around the target molecule through plausible synthetic transformations.\n",
    "\n",
    "**With Incorrect Initial Structure (Regioisomeric Guess):**\n",
    "The performance pattern changes dramatically when an incorrect regioisomeric structure serves as the initial guess. The Retrosynthesis-Forward approach drops significantly in effectiveness, as it cannot easily reconstruct the correct connectivity patterns from the wrong starting point.\n",
    "\n",
    "In contrast, the Mol2Mol approach demonstrates remarkable resilience to incorrect starting structures, maintaining high performance even with regioisomeric initial guesses. This highlights Mol2Mol's strength in structural modificationit efficiently explores diverse molecular variations while preserving core scaffold features, enabling discovery of the correct structure despite the initial error.\n",
    "\n",
    "The MMST-Driven Generation approach shows consistent performance across both scenarios. Its data-driven nature, enhanced by the improvement cycle with on-the-fly fine-tuning, allows it to generate candidates based primarily on spectral patterns rather than relying heavily on the initial structure.\n",
    "\"\"\"\n",
    "    \n",
    "    # Save the figure description\n",
    "    description_path = os.path.join(output_dir, \"figure_description.md\")\n",
    "    with open(description_path, 'w') as f:\n",
    "        f.write(figure_description)\n",
    "    print(f\"Saved figure description to: {description_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edabaf7-6528-43eb-89da-bc841508fd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def load_reference_data(csv_path):\n",
    "    \"\"\"Load reference SMILES from CSV file.\"\"\"\n",
    "    ref_df = pd.read_csv(csv_path)\n",
    "    # Convert to dictionary for faster lookups\n",
    "    return ref_df.set_index('sample-id')['SMILES'].to_dict()\n",
    "\n",
    "def get_base_sample_id(sample_id):\n",
    "    \"\"\"Extract base sample ID (part before underscore).\"\"\"\n",
    "    return sample_id.split('_')[0] if sample_id else ''\n",
    "\n",
    "def analyze_approaches_by_json(json_data, true_smiles):\n",
    "    \"\"\"\n",
    "    Analyze a single JSON file and return where the correct molecule was found.\n",
    "    Returns a dictionary indicating if the true molecule was found in each approach.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        candidate_analysis = json_data[\"molecule_data\"]['candidate_analysis']\n",
    "    except KeyError:\n",
    "        return None\n",
    "    \n",
    "    results = {\n",
    "        'forward_synthesis': False,\n",
    "        'mol2mol': False,\n",
    "        'mmst': False,\n",
    "        'any': False  # Was the molecule found in any approach?\n",
    "    }\n",
    "    \n",
    "    for approach in ['forward_synthesis', 'mol2mol', 'mmst']:\n",
    "        if approach in candidate_analysis:\n",
    "            molecules = candidate_analysis[approach].get('molecules', [])\n",
    "            for mol in molecules:\n",
    "                try:\n",
    "                    if mol['smiles'] == true_smiles:\n",
    "                        results[approach] = True\n",
    "                        results['any'] = True\n",
    "                        break\n",
    "                except KeyError:\n",
    "                    continue\n",
    "    \n",
    "    return results\n",
    "\n",
    "def analyze_directory_by_approach(json_dir, reference_csv):\n",
    "    \"\"\"\n",
    "    Analyze all JSON files and return counts of where correct molecules were found.\n",
    "    \"\"\"\n",
    "    # Load reference data\n",
    "    reference_data = load_reference_data(reference_csv)\n",
    "    \n",
    "    # Get all JSON files\n",
    "    json_files = glob.glob(os.path.join(json_dir, \"*.json\"))\n",
    "    print(f\"Found {len(json_files)} JSON files to analyze\")\n",
    "    \n",
    "    # Initialize counters\n",
    "    approach_counts = {\n",
    "        'forward_synthesis': 0,\n",
    "        'mol2mol': 0,\n",
    "        'mmst': 0,\n",
    "        'any': 0,\n",
    "        'total': 0\n",
    "    }\n",
    "    \n",
    "    # For storing data about individual molecules\n",
    "    molecule_data = []\n",
    "    \n",
    "    for file_path in json_files:\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                json_data = json.load(f)\n",
    "            \n",
    "            molecule_data_json = json_data.get('molecule_data', {})\n",
    "            sample_id = molecule_data_json.get('sample_id')\n",
    "            \n",
    "            if not sample_id:\n",
    "                continue\n",
    "                \n",
    "            # Get base sample ID for reference matching\n",
    "            base_sample_id = get_base_sample_id(sample_id)\n",
    "            \n",
    "            # Get correct SMILES\n",
    "            true_smiles = reference_data.get(base_sample_id)\n",
    "            if true_smiles is None:\n",
    "                print(f\"No reference SMILES found for {base_sample_id}\")\n",
    "                continue\n",
    "            \n",
    "            # Analyze where the correct molecule was found\n",
    "            results = analyze_approaches_by_json(json_data, true_smiles)\n",
    "            if results is None:\n",
    "                continue\n",
    "            \n",
    "            # Update counts\n",
    "            approach_counts['total'] += 1\n",
    "            for approach, found in results.items():\n",
    "                if found:\n",
    "                    approach_counts[approach] += 1\n",
    "            \n",
    "            # Save individual molecule data\n",
    "            molecule_data.append({\n",
    "                'sample_id': sample_id,\n",
    "                'true_smiles': true_smiles,\n",
    "                'found_in_forward_synthesis': results['forward_synthesis'],\n",
    "                'found_in_mol2mol': results['mol2mol'],\n",
    "                'found_in_mmst': results['mmst'],\n",
    "                'found_anywhere': results['any']\n",
    "            })\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return approach_counts, molecule_data\n",
    "\n",
    "def create_enhanced_comparison_plot(experiments_data, output_dir):\n",
    "    \"\"\"\n",
    "    Create an enhanced single plot comparing approach effectiveness across experiments\n",
    "    with the specified color scheme.\n",
    "    \n",
    "    Args:\n",
    "        experiments_data: List of dictionaries with experiment name and approach counts\n",
    "        output_dir: Directory to save the output\n",
    "    \"\"\"\n",
    "    # Create figure with white background - narrower width\n",
    "    fig, ax = plt.subplots(figsize=(8, 8), facecolor='white')\n",
    "    ax.set_facecolor('white')\n",
    "    \n",
    "    # Define approaches and their display names\n",
    "    approaches = ['forward_synthesis', 'mol2mol', 'mmst']\n",
    "    friendly_names = {\n",
    "        'forward_synthesis': 'Retrosynthesis-Forward',\n",
    "        'mol2mol': 'Mol2Mol Analogues',\n",
    "        'mmst': 'MMST-Driven Generation'\n",
    "    }\n",
    "    \n",
    "    # Set the width of a bar \n",
    "    bar_width = 0.25  # Slightly narrower bars for the smaller plot\n",
    "    \n",
    "    # Calculate positions for grouped bars\n",
    "    positions = {}\n",
    "    for i, approach in enumerate(approaches):\n",
    "        positions[approach] = np.arange(len(experiments_data)) + i * bar_width\n",
    "    \n",
    "    # Define colors for each approach using the provided hex codes\n",
    "    colors = {\n",
    "        'forward_synthesis': '#529356',  # Green\n",
    "        'mol2mol': '#FFB047',           # Orange\n",
    "        'mmst': '#9F45B7'               # Purple\n",
    "    }\n",
    "    \n",
    "    # Calculate the highest count for y-axis scaling\n",
    "    max_count = 0\n",
    "    for exp in experiments_data:\n",
    "        for approach in approaches:\n",
    "            if exp['counts'][approach] > max_count:\n",
    "                max_count = exp['counts'][approach]\n",
    "    \n",
    "    # Create the bars\n",
    "    bars = {}\n",
    "    for approach in approaches:\n",
    "        counts = [exp['counts'][approach] for exp in experiments_data]\n",
    "        percentages = [exp['counts'][approach] / exp['counts']['total'] * 100 if exp['counts']['total'] > 0 else 0 for exp in experiments_data]\n",
    "        \n",
    "        bars[approach] = ax.bar(\n",
    "            positions[approach],\n",
    "            counts,\n",
    "            width=bar_width,\n",
    "            color=colors[approach],\n",
    "            edgecolor='black',\n",
    "            alpha=0.9,\n",
    "            label=friendly_names[approach]\n",
    "        )\n",
    "        \n",
    "        # Add counts and percentages inside or above bars\n",
    "        for i, (bar, count, percentage) in enumerate(zip(bars[approach], counts, percentages)):\n",
    "            height = bar.get_height()\n",
    "            \n",
    "            # Always show count and percentage, even for zero values\n",
    "            if height <= 0:\n",
    "                # For zero values, place text just above the x-axis\n",
    "                ax.text(\n",
    "                    bar.get_x() + bar.get_width()/2, \n",
    "                    0.5,  # Small offset from x-axis\n",
    "                    f'0\\n(0.0%)',\n",
    "                    ha='center', \n",
    "                    va='bottom',\n",
    "                    fontsize=12,  # Reduced font size\n",
    "                    color='black'\n",
    "                )\n",
    "            else:\n",
    "                # For shorter bars, place text above\n",
    "                if height < max_count * 0.15:  # If bar is less than 15% of max height\n",
    "                    y_pos = height + max_count * 0.02\n",
    "                    color = 'black'\n",
    "                    va = 'bottom'\n",
    "                else:  # For taller bars, place text inside\n",
    "                    y_pos = height/2\n",
    "                    color = 'white'\n",
    "                    va = 'center'\n",
    "                \n",
    "                ax.text(\n",
    "                    bar.get_x() + bar.get_width()/2, \n",
    "                    y_pos,\n",
    "                    f'{count}\\n({percentage:.1f}%)',\n",
    "                    ha='center', \n",
    "                    va=va,\n",
    "                    fontsize=12,  # Reduced font size\n",
    "                    color=color\n",
    "                )\n",
    "    \n",
    "    # Add title and labels - reduced font size\n",
    "    ax.set_title('Comparison of Structure Generation Approaches', fontsize=16, fontweight='bold')\n",
    "    ax.set_ylabel('Number of Molecules', fontsize=14)\n",
    "    \n",
    "    # Increase the size of tick labels\n",
    "    ax.tick_params(axis='both', labelsize=12)\n",
    "    \n",
    "    # Set x-axis ticks at the center of each experiment group\n",
    "    middle_positions = [(positions['forward_synthesis'][i] + positions['mmst'][i]) / 2 for i in range(len(experiments_data))]\n",
    "    ax.set_xticks(middle_positions)\n",
    "    \n",
    "    # Use single-line labels without rotation\n",
    "    flat_labels = [exp['label'].replace('\\n', ' ') for exp in experiments_data]\n",
    "    ax.set_xticklabels(flat_labels, fontsize=12)\n",
    "    \n",
    "    # Add grid with light gray color\n",
    "    ax.grid(True, alpha=0.3, color='gray', linestyle='--', axis='y')\n",
    "    \n",
    "    # Add legend with enhanced styling - reduced size and moved position\n",
    "    legend = ax.legend(fontsize=12, loc='upper center', bbox_to_anchor=(0.5, -0.14),\n",
    "                      frameon=True, fancybox=True, shadow=True, ncol=3)\n",
    "    \n",
    "    # Add text showing total molecules analyzed for each experiment\n",
    "    for i, exp in enumerate(experiments_data):\n",
    "        ax.text(\n",
    "            middle_positions[i],\n",
    "            -max_count * 0.05,  # Position below the x-axis\n",
    "            f'Total: {exp[\"counts\"][\"total\"]}',\n",
    "            ha='center',\n",
    "            va='top',\n",
    "            fontsize=12,\n",
    "            fontweight='bold'\n",
    "        )\n",
    "    \n",
    "    # Set y-axis limit with a little headroom\n",
    "    ax.set_ylim(0, max_count * 1.2)\n",
    "    \n",
    "    # Remove top and right spines for cleaner look\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Adjust figure size to accommodate legend\n",
    "    fig.subplots_adjust(bottom=0.2)\n",
    "    \n",
    "    # Save the plot with high resolution - use a different filename to avoid overwriting\n",
    "    output_path = os.path.join(output_dir, \"narrow_approach_comparison.png\")\n",
    "    fig.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved narrow comparison figure to: {output_path}\")\n",
    "    \n",
    "    # Also save as SVG for vector graphics\n",
    "    svg_output_path = os.path.join(output_dir, \"narrow_approach_comparison.svg\")\n",
    "    fig.savefig(svg_output_path, format='svg', bbox_inches='tight')\n",
    "    print(f\"Saved narrow comparison figure as SVG to: {svg_output_path}\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def plot_approach_comparison(approach_counts, experiment_label=\"\"):\n",
    "    \"\"\"\n",
    "    Create a bar chart showing the number of correct molecules found by each approach.\n",
    "    \"\"\"\n",
    "    # Create figure with white background\n",
    "    fig, ax = plt.subplots(figsize=(10, 6), facecolor='white')\n",
    "    ax.set_facecolor('white')\n",
    "    \n",
    "    # Data for plotting\n",
    "    approaches = ['forward_synthesis', 'mol2mol', 'mmst']\n",
    "    friendly_names = {\n",
    "        'forward_synthesis': 'Retrosynthesis',\n",
    "        'mol2mol': 'Mol2Mol',\n",
    "        'mmst': 'MMST'\n",
    "    }\n",
    "    \n",
    "    # Calculate percentages\n",
    "    total = approach_counts['total']\n",
    "    percentages = [approach_counts[a] / total * 100 if total > 0 else 0 for a in approaches]\n",
    "    counts = [approach_counts[a] for a in approaches]\n",
    "    \n",
    "    # Define colors for each approach\n",
    "    colors = {'forward_synthesis': '#6366F1', 'mol2mol': '#3B82F6', 'mmst': '#10B981'}\n",
    "    \n",
    "    # Create the bars\n",
    "    bars = ax.bar(\n",
    "        [friendly_names[a] for a in approaches],\n",
    "        counts,\n",
    "        color=[colors[a] for a in approaches],\n",
    "        edgecolor='black',\n",
    "        alpha=0.7\n",
    "    )\n",
    "    \n",
    "    # Add title and labels\n",
    "    title = f'Correct Molecules Found by Approach\\n{experiment_label}'\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.set_xlabel('Approach', fontsize=14)\n",
    "    ax.set_ylabel('Number of Molecules', fontsize=14)\n",
    "    \n",
    "    # Customize y-axis to extend slightly above the maximum value\n",
    "    max_count = max(counts)\n",
    "    ax.set_ylim(0, max_count * 1.1)\n",
    "    \n",
    "    # Add grid with light gray color\n",
    "    ax.grid(True, alpha=0.3, color='gray', linestyle='--', axis='y')\n",
    "    \n",
    "    # Add counts and percentages above bars\n",
    "    for bar, count, percentage in zip(bars, counts, percentages):\n",
    "        height = bar.get_height()\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width()/2, \n",
    "            height + 0.1,\n",
    "            f'{count} ({percentage:.1f}%)',\n",
    "            ha='center', \n",
    "            va='bottom',\n",
    "            fontsize=12\n",
    "        )\n",
    "    \n",
    "    # Increase tick label size\n",
    "    ax.tick_params(axis='both', labelsize=12)\n",
    "    \n",
    "    # Add text showing total molecules analyzed\n",
    "    ax.text(0.02, 0.98, f'Total molecules: {total}',\n",
    "            transform=ax.transAxes,\n",
    "            verticalalignment='top',\n",
    "            horizontalalignment='left',\n",
    "            fontsize=12,\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig, pd.DataFrame({\n",
    "        'Approach': [friendly_names[a] for a in approaches],\n",
    "        'Count': counts,\n",
    "        'Percentage': percentages\n",
    "    })\n",
    "\n",
    "def main():\n",
    "    # Define the experiments\n",
    "    experiments = [\n",
    "        {\n",
    "            \"label\": \"Simulated Data\",\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_1_sim_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"Simulated Data with Wrong Guess\",\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_2_sim_aug_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Define output directory for figures and data\n",
    "    output_dir = \"./output\"\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Store results for each experiment\n",
    "    experiments_data = []\n",
    "    \n",
    "    # Process each experiment\n",
    "    for experiment in experiments:\n",
    "        print(f\"\\nAnalyzing {experiment['label']}...\")\n",
    "        \n",
    "        # Get approach counts and molecule data\n",
    "        approach_counts, molecule_data = analyze_directory_by_approach(\n",
    "            experiment[\"json_directory\"], \n",
    "            experiment[\"reference_csv\"]\n",
    "        )\n",
    "        \n",
    "        # Create and show individual plot\n",
    "        fig, summary_df = plot_approach_comparison(approach_counts, experiment['label'])\n",
    "        \n",
    "        # Save the plot\n",
    "        output_path = os.path.join(output_dir, f\"approach_comparison_{experiment['label'].replace(' ', '_').replace('\\\\n', '_')}.png\")\n",
    "        fig.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Saved figure to: {output_path}\")\n",
    "        \n",
    "        # Save the summary data\n",
    "        summary_path = os.path.join(output_dir, f\"approach_summary_{experiment['label'].replace(' ', '_').replace('\\\\n', '_')}.csv\")\n",
    "        summary_df.to_csv(summary_path, index=False)\n",
    "        print(f\"Saved summary to: {summary_path}\")\n",
    "        \n",
    "        # Save the molecule-level data\n",
    "        if molecule_data:\n",
    "            molecule_df = pd.DataFrame(molecule_data)\n",
    "            molecule_path = os.path.join(output_dir, f\"molecule_data_{experiment['label'].replace(' ', '_').replace('\\\\n', '_')}.csv\")\n",
    "            molecule_df.to_csv(molecule_path, index=False)\n",
    "            print(f\"Saved molecule data to: {molecule_path}\")\n",
    "        \n",
    "        # Store data for comparison plot\n",
    "        experiments_data.append({\n",
    "            'label': experiment['label'],\n",
    "            'counts': approach_counts\n",
    "        })\n",
    "        \n",
    "        # Print overall counts\n",
    "        print(\"\\nApproach counts:\")\n",
    "        for approach, count in approach_counts.items():\n",
    "            if approach not in ['total', 'any']:\n",
    "                percentage = count / approach_counts['total'] * 100 if approach_counts['total'] > 0 else 0\n",
    "                print(f\"  {approach}: {count} ({percentage:.1f}%)\")\n",
    "        print(f\"  Total molecules: {approach_counts['total']}\")\n",
    "    \n",
    "    # Create enhanced comparison plot across experiments with better styling and colors\n",
    "    create_enhanced_comparison_plot(experiments_data, output_dir)\n",
    "    \n",
    "    # Create a markdown file with the figure description\n",
    "    figure_description = \"\"\"\n",
    "# Figure X: Comparison of Structure Generation Approaches\n",
    "\n",
    "Comparison of the three complementary structure generation approaches (Retrosynthesis-Forward in green, Mol2Mol Analogues in orange, and MMST-Driven Generation in purple) across two experimental conditions. Left: Performance with correct initial structure. Right: Performance with regioisomeric initial structure (wrong starting guess). Numbers indicate the count of correct molecules found by each approach, with percentages in parentheses. Total molecules in both datasets: 34.\n",
    "\n",
    "## Key Findings\n",
    "\n",
    "**With Correct Initial Structure:**\n",
    "The Retrosynthesis-Forward approach demonstrates exceptional performance when provided with the correct starting structure. This is expected behavior as this method effectively explores the local chemical space around the target molecule through plausible synthetic transformations.\n",
    "\n",
    "**With Incorrect Initial Structure (Regioisomeric Guess):**\n",
    "The performance pattern changes dramatically when an incorrect regioisomeric structure serves as the initial guess. The Retrosynthesis-Forward approach drops significantly in effectiveness, as it cannot easily reconstruct the correct connectivity patterns from the wrong starting point.\n",
    "\n",
    "In contrast, the Mol2Mol approach demonstrates remarkable resilience to incorrect starting structures, maintaining high performance even with regioisomeric initial guesses. This highlights Mol2Mol's strength in structural modificationit efficiently explores diverse molecular variations while preserving core scaffold features, enabling discovery of the correct structure despite the initial error.\n",
    "\n",
    "The MMST-Driven Generation approach shows consistent performance across both scenarios. Its data-driven nature, enhanced by the improvement cycle with on-the-fly fine-tuning, allows it to generate candidates based primarily on spectral patterns rather than relying heavily on the initial structure.\n",
    "\"\"\"\n",
    "    \n",
    "    # Save the figure description\n",
    "    description_path = os.path.join(output_dir, \"figure_description.md\")\n",
    "    with open(description_path, 'w') as f:\n",
    "        f.write(figure_description)\n",
    "    print(f\"Saved figure description to: {description_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e48ee19-c136-41d8-b86c-7998604b5dc8",
   "metadata": {},
   "source": [
    "### V2 ALL (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959e1a92-e342-45a7-95d5-502e49d5d88b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def load_reference_data(csv_path):\n",
    "    \"\"\"Load reference SMILES from CSV file.\"\"\"\n",
    "    ref_df = pd.read_csv(csv_path)\n",
    "    # Convert to dictionary for faster lookups\n",
    "    return ref_df.set_index('sample-id')['SMILES'].to_dict()\n",
    "\n",
    "def get_base_sample_id(sample_id):\n",
    "    \"\"\"Extract base sample ID (part before underscore).\"\"\"\n",
    "    return sample_id.split('_')[0] if sample_id else ''\n",
    "\n",
    "def analyze_approaches_by_json(json_data, true_smiles):\n",
    "    \"\"\"\n",
    "    Analyze a single JSON file and return where the correct molecule was found.\n",
    "    Returns a dictionary indicating if the true molecule was found in each approach.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        candidate_analysis = json_data[\"molecule_data\"]['candidate_analysis']\n",
    "    except KeyError:\n",
    "        return None\n",
    "    \n",
    "    results = {\n",
    "        'forward_synthesis': False,\n",
    "        'mol2mol': False,\n",
    "        'mmst': False,\n",
    "        'any': False  # Was the molecule found in any approach?\n",
    "    }\n",
    "    \n",
    "    for approach in ['forward_synthesis', 'mol2mol', 'mmst']:\n",
    "        if approach in candidate_analysis:\n",
    "            molecules = candidate_analysis[approach].get('molecules', [])\n",
    "            for mol in molecules:\n",
    "                try:\n",
    "                    if mol['smiles'] == true_smiles:\n",
    "                        results[approach] = True\n",
    "                        results['any'] = True\n",
    "                        break\n",
    "                except KeyError:\n",
    "                    continue\n",
    "    \n",
    "    return results\n",
    "\n",
    "def analyze_directory_by_approach(json_dir, reference_csv):\n",
    "    \"\"\"\n",
    "    Analyze all JSON files and return counts of where correct molecules were found.\n",
    "    \"\"\"\n",
    "    # Load reference data\n",
    "    reference_data = load_reference_data(reference_csv)\n",
    "    \n",
    "    # Get all JSON files\n",
    "    json_files = glob.glob(os.path.join(json_dir, \"*.json\"))\n",
    "    print(f\"Found {len(json_files)} JSON files to analyze\")\n",
    "    \n",
    "    # Initialize counters\n",
    "    approach_counts = {\n",
    "        'forward_synthesis': 0,\n",
    "        'mol2mol': 0,\n",
    "        'mmst': 0,\n",
    "        'any': 0,\n",
    "        'total': 0\n",
    "    }\n",
    "    \n",
    "    # For storing data about individual molecules\n",
    "    molecule_data = []\n",
    "    \n",
    "    # For stacked bar chart analysis\n",
    "    retro_molecules = []\n",
    "    mol2mol_molecules = []\n",
    "    mmst_molecules = []\n",
    "    \n",
    "    for file_path in json_files:\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                json_data = json.load(f)\n",
    "            \n",
    "            molecule_data_json = json_data.get('molecule_data', {})\n",
    "            sample_id = molecule_data_json.get('sample_id')\n",
    "            \n",
    "            if not sample_id:\n",
    "                continue\n",
    "                \n",
    "            # Get base sample ID for reference matching\n",
    "            base_sample_id = get_base_sample_id(sample_id)\n",
    "            \n",
    "            # Get correct SMILES\n",
    "            true_smiles = reference_data.get(base_sample_id)\n",
    "            if true_smiles is None:\n",
    "                print(f\"No reference SMILES found for {base_sample_id}\")\n",
    "                continue\n",
    "            \n",
    "            # Analyze where the correct molecule was found\n",
    "            results = analyze_approaches_by_json(json_data, true_smiles)\n",
    "            if results is None:\n",
    "                continue\n",
    "            \n",
    "            # Update counts\n",
    "            approach_counts['total'] += 1\n",
    "            for approach, found in results.items():\n",
    "                if found:\n",
    "                    approach_counts[approach] += 1\n",
    "                    \n",
    "                    # Track individual molecules for stacked bar chart\n",
    "                    if approach == 'forward_synthesis' and found:\n",
    "                        retro_molecules.append(sample_id)\n",
    "                    elif approach == 'mol2mol' and found:\n",
    "                        mol2mol_molecules.append(sample_id)\n",
    "                    elif approach == 'mmst' and found:\n",
    "                        mmst_molecules.append(sample_id)\n",
    "            \n",
    "            # Save individual molecule data\n",
    "            molecule_data.append({\n",
    "                'sample_id': sample_id,\n",
    "                'true_smiles': true_smiles,\n",
    "                'found_in_forward_synthesis': results['forward_synthesis'],\n",
    "                'found_in_mol2mol': results['mol2mol'],\n",
    "                'found_in_mmst': results['mmst'],\n",
    "                'found_anywhere': results['any']\n",
    "            })\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Add molecule sets to the results\n",
    "    return approach_counts, molecule_data, retro_molecules, mol2mol_molecules, mmst_molecules\n",
    "\n",
    "def plot_approach_comparison(approach_counts, experiment_label=\"\"):\n",
    "    \"\"\"\n",
    "    Create a bar chart showing the number of correct molecules found by each approach.\n",
    "    \"\"\"\n",
    "    # Create figure with white background\n",
    "    fig, ax = plt.subplots(figsize=(10, 6), facecolor='white')\n",
    "    ax.set_facecolor('white')\n",
    "    \n",
    "    # Data for plotting\n",
    "    approaches = ['forward_synthesis', 'mol2mol', 'mmst']\n",
    "    friendly_names = {\n",
    "        'forward_synthesis': 'Retrosynthesis',\n",
    "        'mol2mol': 'Mol2Mol',\n",
    "        'mmst': 'MMST'\n",
    "    }\n",
    "    \n",
    "    # Calculate percentages\n",
    "    total = approach_counts['total']\n",
    "    percentages = [approach_counts[a] / total * 100 if total > 0 else 0 for a in approaches]\n",
    "    counts = [approach_counts[a] for a in approaches]\n",
    "    \n",
    "    # Define colors for each approach\n",
    "    colors = {'forward_synthesis': '#6366F1', 'mol2mol': '#3B82F6', 'mmst': '#10B981'}\n",
    "    \n",
    "    # Create the bars\n",
    "    bars = ax.bar(\n",
    "        [friendly_names[a] for a in approaches],\n",
    "        counts,\n",
    "        color=[colors[a] for a in approaches],\n",
    "        edgecolor='black',\n",
    "        alpha=0.7\n",
    "    )\n",
    "    \n",
    "    # Add title and labels\n",
    "    title = f'Correct Molecules Found by Approach\\n{experiment_label}'\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.set_xlabel('Approach', fontsize=14)\n",
    "    ax.set_ylabel('Number of Molecules', fontsize=14)\n",
    "    \n",
    "    # Customize y-axis to extend slightly above the maximum value\n",
    "    max_count = max(counts)\n",
    "    ax.set_ylim(0, max_count * 1.1)\n",
    "    \n",
    "    # Add grid with light gray color\n",
    "    ax.grid(True, alpha=0.3, color='gray', linestyle='--', axis='y')\n",
    "    \n",
    "    # Add counts and percentages above bars\n",
    "    for bar, count, percentage in zip(bars, counts, percentages):\n",
    "        height = bar.get_height()\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width()/2, \n",
    "            height + 0.1,\n",
    "            f'{count} ({percentage:.1f}%)',\n",
    "            ha='center', \n",
    "            va='bottom',\n",
    "            fontsize=12\n",
    "        )\n",
    "    \n",
    "    # Increase tick label size\n",
    "    ax.tick_params(axis='both', labelsize=12)\n",
    "    \n",
    "    # Add text showing total molecules analyzed\n",
    "    ax.text(0.02, 0.98, f'Total molecules: {total}',\n",
    "            transform=ax.transAxes,\n",
    "            verticalalignment='top',\n",
    "            horizontalalignment='left',\n",
    "            fontsize=12,\n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig, pd.DataFrame({\n",
    "        'Approach': [friendly_names[a] for a in approaches],\n",
    "        'Count': counts,\n",
    "        'Percentage': percentages\n",
    "    })\n",
    "\n",
    "def compare_approaches_plot(experiments_data, output_dir):\n",
    "    \"\"\"\n",
    "    Create a single plot comparing approach effectiveness across experiments.\n",
    "    \n",
    "    Args:\n",
    "        experiments_data: List of dictionaries with experiment name and approach counts\n",
    "        output_dir: Directory to save the output\n",
    "    \"\"\"\n",
    "    # Create figure with white background\n",
    "    fig, ax = plt.subplots(figsize=(14, 8), facecolor='white')\n",
    "    ax.set_facecolor('white')\n",
    "    \n",
    "    # Define approaches and their display names\n",
    "    approaches = ['forward_synthesis', 'mol2mol', 'mmst']\n",
    "    friendly_names = {\n",
    "        'forward_synthesis': 'Retrosynthesis',\n",
    "        'mol2mol': 'Mol2Mol',\n",
    "        'mmst': 'MMST'\n",
    "    }\n",
    "    \n",
    "    # Set the width of a bar and gap between experiment groups\n",
    "    bar_width = 0.25\n",
    "    experiment_gap = 0.1\n",
    "    \n",
    "    # Calculate positions for grouped bars\n",
    "    positions = {}\n",
    "    for i, approach in enumerate(approaches):\n",
    "        positions[approach] = np.arange(len(experiments_data)) + i * bar_width\n",
    "    \n",
    "    # Define colors for each approach (consistent with previous)\n",
    "    colors = {'forward_synthesis': '#6366F1', 'mol2mol': '#3B82F6', 'mmst': '#10B981'}\n",
    "    \n",
    "    # Calculate the highest count for y-axis scaling\n",
    "    max_count = 0\n",
    "    for exp in experiments_data:\n",
    "        for approach in approaches:\n",
    "            if exp['counts'][approach] > max_count:\n",
    "                max_count = exp['counts'][approach]\n",
    "    \n",
    "    # Create the bars\n",
    "    bars = {}\n",
    "    for approach in approaches:\n",
    "        counts = [exp['counts'][approach] for exp in experiments_data]\n",
    "        percentages = [exp['counts'][approach] / exp['counts']['total'] * 100 if exp['counts']['total'] > 0 else 0 for exp in experiments_data]\n",
    "        \n",
    "        bars[approach] = ax.bar(\n",
    "            positions[approach],\n",
    "            counts,\n",
    "            width=bar_width,\n",
    "            color=colors[approach],\n",
    "            edgecolor='black',\n",
    "            alpha=0.8,\n",
    "            label=friendly_names[approach]\n",
    "        )\n",
    "        \n",
    "        # Add counts and percentages inside or above bars\n",
    "        for i, (bar, count, percentage) in enumerate(zip(bars[approach], counts, percentages)):\n",
    "            height = bar.get_height()\n",
    "            if height > 0:\n",
    "                # For shorter bars, place text above\n",
    "                if height < max_count * 0.15:  # If bar is less than 15% of max height\n",
    "                    y_pos = height + max_count * 0.02\n",
    "                    color = 'black'\n",
    "                    va = 'bottom'\n",
    "                else:  # For taller bars, place text inside\n",
    "                    y_pos = height/2\n",
    "                    color = 'white'\n",
    "                    va = 'center'\n",
    "                \n",
    "                ax.text(\n",
    "                    bar.get_x() + bar.get_width()/2, \n",
    "                    y_pos,\n",
    "                    f'{count}\\n({percentage:.1f}%)',\n",
    "                    ha='center', \n",
    "                    va=va,\n",
    "                    fontsize=10,\n",
    "                    color=color,\n",
    "                    fontweight='bold'\n",
    "                )\n",
    "    \n",
    "    # Add title and labels\n",
    "    ax.set_title('Comparison of Approach Effectiveness Across Experiments', fontsize=16)\n",
    "    ax.set_ylabel('Number of Molecules', fontsize=14)\n",
    "    \n",
    "    # Set x-axis ticks at the center of each experiment group\n",
    "    middle_positions = [(positions['forward_synthesis'][i] + positions['mmst'][i]) / 2 for i in range(len(experiments_data))]\n",
    "    ax.set_xticks(middle_positions)\n",
    "    ax.set_xticklabels([exp['label'] for exp in experiments_data], fontsize=12)\n",
    "    \n",
    "    # Add grid with light gray color\n",
    "    ax.grid(True, alpha=0.3, color='gray', linestyle='--', axis='y')\n",
    "    \n",
    "    # Add legend\n",
    "    ax.legend(fontsize=12)\n",
    "    \n",
    "    # Add text showing total molecules analyzed for each experiment\n",
    "    for i, exp in enumerate(experiments_data):\n",
    "        ax.text(\n",
    "            middle_positions[i],\n",
    "            -max_count * 0.05,  # Position below the x-axis\n",
    "            f'Total: {exp[\"counts\"][\"total\"]}',\n",
    "            ha='center',\n",
    "            va='top',\n",
    "            fontsize=10\n",
    "        )\n",
    "    \n",
    "    # Set y-axis limit with a little headroom\n",
    "    ax.set_ylim(0, max_count * 1.15)\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    output_path = os.path.join(output_dir, \"approach_comparison_across_experiments.png\")\n",
    "    fig.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved comparison figure to: {output_path}\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_stacked_comparison(experiments_data, output_dir):\n",
    "    \"\"\"Create a stacked bar chart showing the distribution of molecules across approaches.\"\"\"\n",
    "    \n",
    "    # Create figure with white background\n",
    "    fig, ax = plt.subplots(figsize=(14, 8), facecolor='white')\n",
    "    ax.set_facecolor('white')\n",
    "    \n",
    "    # Data for the x-axis (experiment labels)\n",
    "    labels = [exp['label'] for exp in experiments_data]\n",
    "    \n",
    "    # Set up colors\n",
    "    colors = {\n",
    "        'All Three': '#4B0082',  # Deep purple for molecules found by all approaches\n",
    "        'Retro+Mol2Mol': '#6A5ACD',  # Slate blue for retro + mol2mol only\n",
    "        'Retro+MMST': '#9370DB',  # Medium purple for retro + mmst only\n",
    "        'Mol2Mol+MMST': '#8A2BE2',  # Blue violet for mol2mol + mmst only\n",
    "        'Retrosynthesis Only': '#6366F1',  # Same as in previous plots\n",
    "        'Mol2Mol Only': '#3B82F6',  # Same as in previous plots\n",
    "        'MMST Only': '#10B981',  # Same as in previous plots\n",
    "        'Not Found': '#D3D3D3'  # Light gray for molecules not found by any method\n",
    "    }\n",
    "    \n",
    "    # Calculate counts for each experiment\n",
    "    data = []\n",
    "    \n",
    "    for exp in experiments_data:\n",
    "        counts = exp['counts']\n",
    "        total = counts['total']\n",
    "        \n",
    "        # Skip if no data\n",
    "        if total == 0:\n",
    "            data.append({k: 0 for k in colors.keys()})\n",
    "            continue\n",
    "        \n",
    "        # Convert molecules data to a list of sets for each approach\n",
    "        retro_set = set(exp.get('retro_molecules', []))\n",
    "        mol2mol_set = set(exp.get('mol2mol_molecules', []))\n",
    "        mmst_set = set(exp.get('mmst_molecules', []))\n",
    "        \n",
    "        # Calculate molecules in each segment\n",
    "        all_three = len(retro_set & mol2mol_set & mmst_set)\n",
    "        retro_mol2mol = len((retro_set & mol2mol_set) - mmst_set)\n",
    "        retro_mmst = len((retro_set & mmst_set) - mol2mol_set)\n",
    "        mol2mol_mmst = len((mol2mol_set & mmst_set) - retro_set)\n",
    "        retro_only = len(retro_set - mol2mol_set - mmst_set)\n",
    "        mol2mol_only = len(mol2mol_set - retro_set - mmst_set)\n",
    "        mmst_only = len(mmst_set - retro_set - mol2mol_set)\n",
    "        \n",
    "        # Calculate not found\n",
    "        found = len(retro_set | mol2mol_set | mmst_set)\n",
    "        not_found = total - found\n",
    "        \n",
    "        # Store data\n",
    "        data.append({\n",
    "            'All Three': all_three,\n",
    "            'Retro+Mol2Mol': retro_mol2mol,\n",
    "            'Retro+MMST': retro_mmst,\n",
    "            'Mol2Mol+MMST': mol2mol_mmst,\n",
    "            'Retrosynthesis Only': retro_only,\n",
    "            'Mol2Mol Only': mol2mol_only,\n",
    "            'MMST Only': mmst_only,\n",
    "            'Not Found': not_found\n",
    "        })\n",
    "    \n",
    "    # Get the order of segments (bottom to top)\n",
    "    segments = ['Not Found', 'MMST Only', 'Mol2Mol Only', 'Retrosynthesis Only', \n",
    "                'Mol2Mol+MMST', 'Retro+MMST', 'Retro+Mol2Mol', 'All Three']\n",
    "    \n",
    "    # Calculate positions for the bars\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.6\n",
    "    \n",
    "    # Create the stacked bars\n",
    "    bottom = np.zeros(len(labels))\n",
    "    \n",
    "    for segment in segments:\n",
    "        values = [d[segment] for d in data]\n",
    "        percentages = [values[i] / experiments_data[i]['counts']['total'] * 100 \n",
    "                      if experiments_data[i]['counts']['total'] > 0 else 0 \n",
    "                      for i in range(len(values))]\n",
    "        \n",
    "        rects = ax.bar(x, values, width, label=segment, bottom=bottom, \n",
    "                      color=colors[segment], edgecolor='black')\n",
    "        \n",
    "        # Add labels inside the bars for non-zero segments\n",
    "        for i, rect in enumerate(rects):\n",
    "            height = rect.get_height()\n",
    "            if height > 0:\n",
    "                # Calculate the position for the text\n",
    "                value = values[i]\n",
    "                percentage = percentages[i]\n",
    "                y_pos = bottom[i] + height/2\n",
    "                \n",
    "                # Use black text for light colors, white for dark colors\n",
    "                if segment == 'Not Found':\n",
    "                    text_color = 'black'\n",
    "                else:\n",
    "                    text_color = 'white'\n",
    "                \n",
    "                ax.text(rect.get_x() + rect.get_width()/2, y_pos,\n",
    "                       f'{value}\\n({percentage:.1f}%)',\n",
    "                       ha='center', va='center', color=text_color, fontweight='bold')\n",
    "        \n",
    "        bottom += values\n",
    "    \n",
    "    # Configure the plot\n",
    "    ax.set_title('Distribution of Molecules Across Approaches', fontsize=16)\n",
    "    ax.set_ylabel('Number of Molecules', fontsize=14)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels, fontsize=12)\n",
    "    \n",
    "    # Add a legend at the bottom of the plot\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), \n",
    "             fancybox=True, shadow=True, ncol=4, fontsize=12)\n",
    "    \n",
    "    # Add grid lines\n",
    "    ax.grid(True, alpha=0.3, color='gray', linestyle='--', axis='y')\n",
    "    \n",
    "    # Adjust layout to make room for the legend\n",
    "    fig.tight_layout(rect=[0, 0.1, 1, 0.95])\n",
    "    \n",
    "    # Save the plot\n",
    "    output_path = os.path.join(output_dir, \"approach_stacked_comparison.png\")\n",
    "    fig.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved stacked comparison figure to: {output_path}\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def generate_summary_tables(experiments_data, output_dir):\n",
    "    \"\"\"Generate summary tables comparing approaches across experiments.\"\"\"\n",
    "    \n",
    "    # Prepare data for the comparison table\n",
    "    comparison_data = []\n",
    "    \n",
    "    for exp in experiments_data:\n",
    "        total = exp['counts']['total']\n",
    "        if total == 0:\n",
    "            continue\n",
    "            \n",
    "        for approach in ['forward_synthesis', 'mol2mol', 'mmst']:\n",
    "            count = exp['counts'][approach]\n",
    "            percentage = count / total * 100 if total > 0 else 0\n",
    "            \n",
    "            comparison_data.append({\n",
    "                'Experiment': exp['label'].replace('\\n', ' '),\n",
    "                'Approach': approach,\n",
    "                'Count': count,\n",
    "                'Percentage': percentage,\n",
    "                'Total': total\n",
    "            })\n",
    "    \n",
    "    # Create the comparison DataFrame\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    # Save the comparison table\n",
    "    comparison_path = os.path.join(output_dir, \"approach_comparison_summary.csv\")\n",
    "    comparison_df.to_csv(comparison_path, index=False)\n",
    "    print(f\"Saved comparison summary to: {comparison_path}\")\n",
    "    \n",
    "    # Create a pivot table for easier comparison\n",
    "    pivot_df = comparison_df.pivot_table(\n",
    "        index='Experiment', \n",
    "        columns='Approach', \n",
    "        values=['Count', 'Percentage'], \n",
    "        aggfunc='sum'\n",
    "    )\n",
    "    \n",
    "    # Add a total column to the pivot table\n",
    "    pivot_df[('Total', '')] = comparison_df.groupby('Experiment')['Total'].first()\n",
    "    \n",
    "    # Save the pivot table\n",
    "    pivot_path = os.path.join(output_dir, \"approach_comparison_pivot.csv\")\n",
    "    pivot_df.to_csv(pivot_path)\n",
    "    print(f\"Saved pivot table summary to: {pivot_path}\")\n",
    "    \n",
    "    # Print a summary table\n",
    "    print(\"\\n===== APPROACH EFFECTIVENESS SUMMARY =====\")\n",
    "    print(\"\\nExperiment | Approach | Count | Percentage | Total\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for exp in experiments_data:\n",
    "        total = exp['counts']['total']\n",
    "        if total == 0:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n{exp['label'].replace(chr(10), ' ')}:\")\n",
    "        \n",
    "        for approach in ['forward_synthesis', 'mol2mol', 'mmst']:\n",
    "            count = exp['counts'][approach]\n",
    "            percentage = count / total * 100 if total > 0 else 0\n",
    "            print(f\"  {approach}: {count} ({percentage:.1f}%) of {total}\")\n",
    "    \n",
    "    return comparison_df, pivot_df\n",
    "\n",
    "def main():\n",
    "    # Define the experiments\n",
    "    experiments = [\n",
    "        {\n",
    "            \"label\": \"Simulated Data\",\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_1_sim_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"Simulated Data\\nwith Wrong Guess\",\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_2_sim_aug_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"Simulated Data\\nwith Noise\",\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_3_sim+noise_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"Experimental Data\",\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_4_exp_d1_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        },\n",
    "        {\n",
    "            \"label\": \"Experimental Data\\nwith Wrong Guess\",\n",
    "            \"json_directory\": \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_5_exp_d1_aug_finished_clean\",\n",
    "            \"reference_csv\": \"/projects/cc/se_users/knlr326/1_NMR_project/1_NMR_data_AZ/52_project_3.3_data/sim_data/combined_sim_nmr_data_no_stereo.csv\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Define output directory for figures and data\n",
    "    output_dir = \"./output\"\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Store results for each experiment\n",
    "    experiments_data = []\n",
    "    \n",
    "    # Process each experiment\n",
    "    for experiment in experiments:\n",
    "        print(f\"\\nAnalyzing {experiment['label']}...\")\n",
    "        \n",
    "        # Get approach counts and molecule data\n",
    "        approach_counts, molecule_data, retro_molecules, mol2mol_molecules, mmst_molecules = analyze_directory_by_approach(\n",
    "            experiment[\"json_directory\"], \n",
    "            experiment[\"reference_csv\"]\n",
    "        )\n",
    "        \n",
    "        # Create and show individual plot\n",
    "        fig, summary_df = plot_approach_comparison(approach_counts, experiment['label'])\n",
    "        \n",
    "        # Save the plot\n",
    "        output_path = os.path.join(output_dir, f\"approach_comparison_{experiment['label'].replace(' ', '_').replace('\\\\n', '_')}.png\")\n",
    "        fig.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Saved figure to: {output_path}\")\n",
    "        \n",
    "        # Save the summary data\n",
    "        summary_path = os.path.join(output_dir, f\"approach_summary_{experiment['label'].replace(' ', '_').replace('\\\\n', '_')}.csv\")\n",
    "        summary_df.to_csv(summary_path, index=False)\n",
    "        print(f\"Saved summary to: {summary_path}\")\n",
    "        \n",
    "        # Save the molecule-level data\n",
    "        if molecule_data:\n",
    "            molecule_df = pd.DataFrame(molecule_data)\n",
    "            molecule_path = os.path.join(output_dir, f\"molecule_data_{experiment['label'].replace(' ', '_').replace('\\\\n', '_')}.csv\")\n",
    "            molecule_df.to_csv(molecule_path, index=False)\n",
    "            print(f\"Saved molecule data to: {molecule_path}\")\n",
    "        \n",
    "        # Store data for comparison plot\n",
    "        experiments_data.append({\n",
    "            'label': experiment['label'],\n",
    "            'counts': approach_counts,\n",
    "            'retro_molecules': retro_molecules,\n",
    "            'mol2mol_molecules': mol2mol_molecules,\n",
    "            'mmst_molecules': mmst_molecules\n",
    "        })\n",
    "        \n",
    "        # Print overall counts\n",
    "        print(\"\\nApproach counts:\")\n",
    "        for approach, count in approach_counts.items():\n",
    "            if approach not in ['total', 'any']:\n",
    "                percentage = count / approach_counts['total'] * 100 if approach_counts['total'] > 0 else 0\n",
    "                print(f\"  {approach}: {count} ({percentage:.1f}%)\")\n",
    "        print(f\"  Total molecules: {approach_counts['total']}\")\n",
    "    \n",
    "    # Create comparison plot across experiments\n",
    "    comparison_fig = compare_approaches_plot(experiments_data, output_dir)\n",
    "    \n",
    "    # Generate summary tables\n",
    "    comparison_df, pivot_df = generate_summary_tables(experiments_data, output_dir)\n",
    "    \n",
    "    # Create a stacked bar chart to visualize overlaps\n",
    "    create_stacked_comparison(experiments_data, output_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ade645-9c4e-4457-bc04-34ab6fe52329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3048cbf1-28b2-4473-84c0-caa693c6c179",
   "metadata": {},
   "source": [
    "## Plot molecules for each approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0444aa92-d2a3-4eb7-8cf9-5457b4bbafcd",
   "metadata": {},
   "source": [
    "### AZ10282497"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5255e335-3192-48c7-a619-9bdc1719d57b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw, AllChem\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Path to the specific JSON file for AZ10282497\n",
    "json_filepath = \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_1_sim_finished/AZ10282497_intermediate.json\"\n",
    "\n",
    "# Function to safely get molecules and deduplicate them\n",
    "def get_unique_molecules(smiles_list):\n",
    "    unique_smiles = []\n",
    "    unique_mols = []\n",
    "    \n",
    "    for smi in smiles_list:\n",
    "        try:\n",
    "            mol = Chem.MolFromSmiles(smi)\n",
    "            if mol is None:\n",
    "                continue\n",
    "            # Canonicalize the SMILES\n",
    "            canon_smi = Chem.MolToSmiles(mol, canonical=True)\n",
    "            if canon_smi not in unique_smiles:\n",
    "                unique_smiles.append(canon_smi)\n",
    "                unique_mols.append(mol)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing SMILES {smi}: {e}\")\n",
    "    \n",
    "    return unique_mols, unique_smiles\n",
    "\n",
    "# Load the JSON data for the specific sample\n",
    "try:\n",
    "    with open(json_filepath, \"r\") as f:\n",
    "        sample = json.load(f)\n",
    "    print(f\"Successfully loaded data for AZ10282497\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading JSON file: {e}\")\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(json_filepath):\n",
    "        print(f\"File does not exist: {json_filepath}\")\n",
    "        exit(1)\n",
    "\n",
    "# This file contains data for a single sample\n",
    "target_sample_id = \"AZ10282497\"\n",
    "print(f\"Processing sample: {target_sample_id}\")\n",
    "\n",
    "# Extract the target SMILES\n",
    "target_smiles = sample[\"molecule_data\"][\"smiles\"]\n",
    "target_mol = Chem.MolFromSmiles(target_smiles)\n",
    "print(f\"Target SMILES: {target_smiles}\")\n",
    "\n",
    "# Check for candidate_analysis and forward_synthesis\n",
    "forward_synthesis_molecules = []\n",
    "mol2mol_molecules = []\n",
    "mmst_molecules = []\n",
    "\n",
    "if \"candidate_analysis\" in sample[\"molecule_data\"]:\n",
    "    candidate_analysis = sample[\"molecule_data\"][\"candidate_analysis\"]\n",
    "    print(\"Available analysis methods:\", list(candidate_analysis.keys()))\n",
    "    \n",
    "    # Extract forward synthesis molecules\n",
    "    if \"forward_synthesis\" in candidate_analysis:\n",
    "        if \"molecules\" in candidate_analysis[\"forward_synthesis\"]:\n",
    "            forward_synthesis_molecules = [\n",
    "                mol.get(\"smiles\", \"\") \n",
    "                for mol in candidate_analysis[\"forward_synthesis\"][\"molecules\"] \n",
    "                if \"smiles\" in mol\n",
    "            ]\n",
    "            print(f\"Found {len(forward_synthesis_molecules)} forward synthesis molecules\")\n",
    "    \n",
    "    # Extract mol2mol molecules\n",
    "    if \"mol2mol\" in candidate_analysis:\n",
    "        if \"molecules\" in candidate_analysis[\"mol2mol\"]:\n",
    "            mol2mol_molecules = [\n",
    "                mol.get(\"smiles\", \"\") \n",
    "                for mol in candidate_analysis[\"mol2mol\"][\"molecules\"] \n",
    "                if \"smiles\" in mol\n",
    "            ]\n",
    "            print(f\"Found {len(mol2mol_molecules)} mol2mol molecules\")\n",
    "    \n",
    "    # Extract MMST molecules\n",
    "    if \"mmst\" in candidate_analysis:\n",
    "        if \"molecules\" in candidate_analysis[\"mmst\"]:\n",
    "            mmst_molecules = [\n",
    "                mol.get(\"smiles\", \"\") \n",
    "                for mol in candidate_analysis[\"mmst\"][\"molecules\"] \n",
    "                if \"smiles\" in mol\n",
    "            ]\n",
    "            print(f\"Found {len(mmst_molecules)} MMST molecules\")\n",
    "else:\n",
    "    print(\"No candidate_analysis found in the data\")\n",
    "\n",
    "# Get unique molecules for each method\n",
    "unique_forward_mols, unique_forward_smiles = get_unique_molecules(forward_synthesis_molecules)\n",
    "unique_mol2mol_mols, unique_mol2mol_smiles = get_unique_molecules(mol2mol_molecules)\n",
    "unique_mmst_mols, unique_mmst_smiles = get_unique_molecules(mmst_molecules)\n",
    "\n",
    "print(f\"Unique forward synthesis molecules: {len(unique_forward_mols)}\")\n",
    "print(f\"Unique mol2mol molecules: {len(unique_mol2mol_mols)}\")\n",
    "print(f\"Unique MMST molecules: {len(unique_mmst_mols)}\")\n",
    "\n",
    "# Define a function to create and display the visualization for each method\n",
    "def visualize_molecules(method_name, target_mol, target_smiles, unique_mols, unique_smiles):\n",
    "    if not unique_mols:\n",
    "        print(f\"No unique molecules found for {method_name}\")\n",
    "        return\n",
    "    \n",
    "    # Calculate grid dimensions\n",
    "    n_molecules = len(unique_mols)\n",
    "    n_cols = min(4, n_molecules)  # Maximum 4 columns\n",
    "    n_rows = (n_molecules + n_cols - 1) // n_cols + 1  # +1 for target molecule row\n",
    "    \n",
    "    # Create figure\n",
    "    fig = plt.figure(figsize=(5 * n_cols, 4 * n_rows))\n",
    "    \n",
    "    # Add target molecule at the top spanning all columns\n",
    "    gs = gridspec.GridSpec(n_rows, n_cols, height_ratios=[1] + [1] * (n_rows - 1))\n",
    "    \n",
    "    # Plot target molecule\n",
    "    ax_target = plt.subplot(gs[0, :])\n",
    "    if not target_mol.GetNumConformers():\n",
    "        AllChem.Compute2DCoords(target_mol)\n",
    "    target_img = Draw.MolToImage(target_mol, size=(400, 300))\n",
    "    ax_target.imshow(target_img)\n",
    "    ax_target.set_title(f\"Target: {target_smiles}\", fontsize=12)\n",
    "    ax_target.axis(\"off\")\n",
    "    \n",
    "    # Plot unique molecules\n",
    "    for i, (mol, smi) in enumerate(zip(unique_mols, unique_smiles)):\n",
    "        row = 1 + i // n_cols\n",
    "        col = i % n_cols\n",
    "        \n",
    "        ax = plt.subplot(gs[row, col])\n",
    "        # Generate 2D coordinates if they don't exist\n",
    "        if not mol.GetNumConformers():\n",
    "            AllChem.Compute2DCoords(mol)\n",
    "        mol_img = Draw.MolToImage(mol, size=(400, 300))\n",
    "        \n",
    "        # Truncate long SMILES for display\n",
    "        display_smi = smi if len(smi) < 40 else smi[:37] + \"...\"\n",
    "        ax.set_title(f\"Analogue {i+1}:\\n{display_smi}\", fontsize=10)\n",
    "        ax.imshow(mol_img)\n",
    "        ax.axis(\"off\")\n",
    "    \n",
    "    # Add title\n",
    "    plt.suptitle(f\"{method_name} Analogues for Sample {target_sample_id}\", fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    \n",
    "    # Save the figure\n",
    "    output_filename = f\"{target_sample_id}_{method_name.replace(' ', '_')}_analogues.png\"\n",
    "    plt.savefig(output_filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved figure to {output_filename}\")\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Visualize molecules for each method\n",
    "print(\"\\nGenerating visualizations...\")\n",
    "visualize_molecules(\"Forward Synthesis\", target_mol, target_smiles, unique_forward_mols, unique_forward_smiles)\n",
    "visualize_molecules(\"Mol2Mol\", target_mol, target_smiles, unique_mol2mol_mols, unique_mol2mol_smiles)\n",
    "visualize_molecules(\"MMST\", target_mol, target_smiles, unique_mmst_mols, unique_mmst_smiles)\n",
    "\n",
    "print(\"Visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8594f6-8989-4847-81d7-4e1e3d1f1613",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "### AZ11034953"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86e7378-2f2c-4538-9fbe-bc1807175efe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw, AllChem\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Path to the directory containing the simulated data\n",
    "base_dir = \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/_run_1_sim_finished/\"\n",
    "\n",
    "# Find the target file for AZ11034953\n",
    "target_file = os.path.join(base_dir, \"AZ11034953_intermediate.json\")\n",
    "if not os.path.exists(target_file):\n",
    "    # Try to find it by pattern if exact name doesn't exist\n",
    "    file_pattern = os.path.join(base_dir, \"AZ11034953*.json\")\n",
    "    matching_files = glob.glob(file_pattern)\n",
    "    if matching_files:\n",
    "        target_file = matching_files[0]\n",
    "        print(f\"Found file: {target_file}\")\n",
    "    else:\n",
    "        print(f\"No file found for AZ11034953. Checking for any available files...\")\n",
    "        # List a few files in the directory to help troubleshoot\n",
    "        all_files = glob.glob(os.path.join(base_dir, \"*.json\"))\n",
    "        if all_files:\n",
    "            print(\"Available files (first 5):\")\n",
    "            for i, f in enumerate(all_files[:5]):\n",
    "                print(f\"  {i+1}. {os.path.basename(f)}\")\n",
    "        else:\n",
    "            print(f\"No JSON files found in {base_dir}\")\n",
    "        exit(1)\n",
    "\n",
    "# Function to get unique molecules from SMILES list\n",
    "def get_unique_molecules(smiles_list):\n",
    "    unique_smiles = []\n",
    "    unique_mols = []\n",
    "    \n",
    "    for smi in smiles_list:\n",
    "        try:\n",
    "            mol = Chem.MolFromSmiles(smi)\n",
    "            if mol is None:\n",
    "                continue\n",
    "            # Canonicalize the SMILES\n",
    "            canon_smi = Chem.MolToSmiles(mol, canonical=True)\n",
    "            if canon_smi not in unique_smiles:\n",
    "                unique_smiles.append(canon_smi)\n",
    "                unique_mols.append(mol)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing SMILES {smi}: {e}\")\n",
    "    \n",
    "    return unique_mols, unique_smiles\n",
    "\n",
    "# Load the JSON data\n",
    "try:\n",
    "    with open(target_file, 'r') as f:\n",
    "        sample = json.load(f)\n",
    "    print(f\"Successfully loaded data for AZ11034953\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading JSON file: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Extract the target SMILES\n",
    "target_smiles = sample[\"molecule_data\"][\"smiles\"]\n",
    "target_mol = Chem.MolFromSmiles(target_smiles)\n",
    "print(f\"Target SMILES: {target_smiles}\")\n",
    "\n",
    "# Extract molecules for each method\n",
    "forward_molecules = []\n",
    "mol2mol_molecules = []\n",
    "mmst_molecules = []\n",
    "\n",
    "if \"candidate_analysis\" in sample[\"molecule_data\"]:\n",
    "    candidate_analysis = sample[\"molecule_data\"][\"candidate_analysis\"]\n",
    "    print(\"Available analysis methods:\", list(candidate_analysis.keys()))\n",
    "    \n",
    "    # Extract forward synthesis molecules\n",
    "    if \"forward_synthesis\" in candidate_analysis:\n",
    "        if \"molecules\" in candidate_analysis[\"forward_synthesis\"]:\n",
    "            forward_molecules = [\n",
    "                mol.get(\"smiles\", \"\") \n",
    "                for mol in candidate_analysis[\"forward_synthesis\"][\"molecules\"] \n",
    "                if \"smiles\" in mol\n",
    "            ]\n",
    "            print(f\"Found {len(forward_molecules)} forward synthesis molecules\")\n",
    "    \n",
    "    # Extract mol2mol molecules\n",
    "    if \"mol2mol\" in candidate_analysis:\n",
    "        if \"molecules\" in candidate_analysis[\"mol2mol\"]:\n",
    "            mol2mol_molecules = [\n",
    "                mol.get(\"smiles\", \"\") \n",
    "                for mol in candidate_analysis[\"mol2mol\"][\"molecules\"] \n",
    "                if \"smiles\" in mol\n",
    "            ]\n",
    "            print(f\"Found {len(mol2mol_molecules)} mol2mol molecules\")\n",
    "    \n",
    "    # Extract MMST molecules\n",
    "    if \"mmst\" in candidate_analysis:\n",
    "        if \"molecules\" in candidate_analysis[\"mmst\"]:\n",
    "            mmst_molecules = [\n",
    "                mol.get(\"smiles\", \"\") \n",
    "                for mol in candidate_analysis[\"mmst\"][\"molecules\"] \n",
    "                if \"smiles\" in mol\n",
    "            ]\n",
    "            print(f\"Found {len(mmst_molecules)} MMST molecules\")\n",
    "else:\n",
    "    print(\"No candidate_analysis found\")\n",
    "\n",
    "# Get unique molecules\n",
    "unique_forward_mols, unique_forward_smiles = get_unique_molecules(forward_molecules)\n",
    "unique_mol2mol_mols, unique_mol2mol_smiles = get_unique_molecules(mol2mol_molecules)\n",
    "unique_mmst_mols, unique_mmst_smiles = get_unique_molecules(mmst_molecules)\n",
    "\n",
    "print(f\"Unique forward synthesis molecules: {len(unique_forward_mols)}\")\n",
    "print(f\"Unique mol2mol molecules: {len(unique_mol2mol_mols)}\")\n",
    "print(f\"Unique MMST molecules: {len(unique_mmst_mols)}\")\n",
    "\n",
    "# Visualize molecules for each method\n",
    "def visualize_molecules(method_name, target_mol, target_smiles, unique_mols, unique_smiles):\n",
    "    if not unique_mols:\n",
    "        print(f\"No unique molecules found for {method_name}\")\n",
    "        return\n",
    "    \n",
    "    # For larger sets, split into multiple figures with 30 molecules each\n",
    "    molecules_per_figure = 30\n",
    "    num_figures = (len(unique_mols) + molecules_per_figure - 1) // molecules_per_figure\n",
    "    \n",
    "    for fig_idx in range(num_figures):\n",
    "        start_idx = fig_idx * molecules_per_figure\n",
    "        end_idx = min(start_idx + molecules_per_figure, len(unique_mols))\n",
    "        \n",
    "        display_mols = unique_mols[start_idx:end_idx]\n",
    "        display_smiles = unique_smiles[start_idx:end_idx]\n",
    "        \n",
    "        # Calculate grid dimensions\n",
    "        n_molecules = len(display_mols)\n",
    "        n_cols = min(6, n_molecules)  # Maximum 6 columns\n",
    "        n_rows = (n_molecules + n_cols - 1) // n_cols + 1  # +1 for target molecule row\n",
    "        \n",
    "        # Create figure\n",
    "        fig = plt.figure(figsize=(4 * n_cols, 3 * n_rows))\n",
    "        \n",
    "        # Add target molecule at the top spanning all columns\n",
    "        gs = gridspec.GridSpec(n_rows, n_cols, height_ratios=[1] + [1] * (n_rows - 1))\n",
    "        \n",
    "        # Plot target molecule\n",
    "        ax_target = plt.subplot(gs[0, :])\n",
    "        if not target_mol.GetNumConformers():\n",
    "            AllChem.Compute2DCoords(target_mol)\n",
    "        target_img = Draw.MolToImage(target_mol, size=(300, 250))\n",
    "        ax_target.imshow(target_img)\n",
    "        ax_target.set_title(f\"Target: {target_smiles}\", fontsize=10)\n",
    "        ax_target.axis(\"off\")\n",
    "        \n",
    "        # Plot molecules\n",
    "        for i, (mol, smi) in enumerate(zip(display_mols, display_smiles)):\n",
    "            row = 1 + i // n_cols\n",
    "            col = i % n_cols\n",
    "            \n",
    "            ax = plt.subplot(gs[row, col])\n",
    "            # Generate 2D coordinates if they don't exist\n",
    "            if not mol.GetNumConformers():\n",
    "                AllChem.Compute2DCoords(mol)\n",
    "            mol_img = Draw.MolToImage(mol, size=(300, 250))\n",
    "            \n",
    "            # Check if this molecule matches the target\n",
    "            is_target = (Chem.MolToSmiles(mol, canonical=True) == Chem.MolToSmiles(target_mol, canonical=True))\n",
    "            \n",
    "            # Create title without SMILES\n",
    "            title = f\"Analogue {start_idx + i + 1}\"\n",
    "            if is_target:\n",
    "                title += \" (TARGET MATCH)\"\n",
    "            ax.set_title(title, fontsize=10)\n",
    "            ax.imshow(mol_img)\n",
    "            ax.axis(\"off\")\n",
    "        \n",
    "        # Add title\n",
    "        plt.suptitle(f\"{method_name} Analogues for AZ11034953 (Page {fig_idx+1}/{num_figures})\", fontsize=16)\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        \n",
    "        # Save the figure\n",
    "        output_filename = f\"AZ11034953_{method_name.replace(' ', '_')}_analogues_page{fig_idx+1}.png\"\n",
    "        plt.savefig(output_filename, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Saved figure to {output_filename}\")\n",
    "        \n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "\n",
    "# Also create a file with SMILES and indices for reference\n",
    "def save_smiles_list(method_name, smiles_list):\n",
    "    filename = f\"AZ11034953_{method_name.replace(' ', '_')}_smiles.txt\"\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(f\"Target SMILES: {target_smiles}\\n\\n\")\n",
    "        for i, smi in enumerate(smiles_list):\n",
    "            is_target = (smi == Chem.MolToSmiles(target_mol, canonical=True))\n",
    "            f.write(f\"Analogue {i+1}{' (TARGET MATCH)' if is_target else ''}: {smi}\\n\")\n",
    "    print(f\"Saved SMILES list to {filename}\")\n",
    "\n",
    "# Visualize molecules for each method\n",
    "print(\"\\nGenerating visualizations...\")\n",
    "visualize_molecules(\"Forward Synthesis\", target_mol, target_smiles, unique_forward_mols, unique_forward_smiles)\n",
    "visualize_molecules(\"Mol2Mol\", target_mol, target_smiles, unique_mol2mol_mols, unique_mol2mol_smiles)\n",
    "visualize_molecules(\"MMST\", target_mol, target_smiles, unique_mmst_mols, unique_mmst_smiles)\n",
    "\n",
    "# Save SMILES lists for reference\n",
    "save_smiles_list(\"Forward Synthesis\", unique_forward_smiles)\n",
    "save_smiles_list(\"Mol2Mol\", unique_mol2mol_smiles)\n",
    "save_smiles_list(\"MMST\", unique_mmst_smiles)\n",
    "\n",
    "print(\"Visualization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f6e06f-5513-442e-a686-1bb1d3f90111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6e51ef9-af88-4c7d-bb3c-d40bc94749bc",
   "metadata": {},
   "source": [
    "# Test ACD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331508f5-3b53-48a6-a7b3-5a69ceac47de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %% Import necessary libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "from typing import Dict, List, Any, Optional, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import to_rgba\n",
    "\n",
    "# --- Configuration ---\n",
    "# Set the directory containing the ZINC experiment JSON files\n",
    "ZINC_DATA_DIR = \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/ZINC_large\"\n",
    "# Define where to save the analysis results\n",
    "OUTPUT_DIR = Path(ZINC_DATA_DIR) / \"analysis_results_zinc\"\n",
    "OUTPUT_DIR.mkdir(exist_ok=True) # Create output directory if it doesn't exist\n",
    "\n",
    "# LLM models present in the JSON files (adjust if different for ZINC)\n",
    "LLM_MODELS = [\"claude\", \"claude3-7\", \"o3\", \"kimi\", \"gemini\", \"deepseek\"]\n",
    "# Colors for plotting LLM models\n",
    "LLM_COLORS = {\n",
    "    \"claude\": \"#4169E1\",      # Royal Blue\n",
    "    \"claude3-7\": \"#1E90FF\",   # Dodger Blue\n",
    "    \"o3\": \"#2E8B57\",          # Sea Green\n",
    "    \"kimi\": \"#8B4513\",        # Saddle Brown\n",
    "    \"gemini\": \"#4B0082\",      # Indigo\n",
    "    \"deepseek\": \"#CD853F\",     # Peru\n",
    "    \"HSQC Baseline\": \"#999999\" # Gray for baseline\n",
    "}\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def process_single_json_candidates(json_data: Dict[str, Any]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Process a single JSON file's candidate analysis and combine all molecules.\n",
    "    Extracts SMILES and HSQC scores.\n",
    "\n",
    "    Args:\n",
    "        json_data: Dictionary containing the JSON data with molecule_data.\n",
    "\n",
    "    Returns:\n",
    "        List of dictionaries containing molecule smiles and hsqc_score.\n",
    "    \"\"\"\n",
    "    all_molecules = []\n",
    "    try:\n",
    "        candidate_analysis = json_data[\"molecule_data\"]['candidate_analysis']\n",
    "        analysis_types = ['forward_synthesis', 'mol2mol', 'mmst']\n",
    "\n",
    "        for analysis_type in analysis_types:\n",
    "            if analysis_type in candidate_analysis:\n",
    "                molecules = candidate_analysis[analysis_type].get('molecules', [])\n",
    "                for mol in molecules:\n",
    "                    try:\n",
    "                        hsqc_score = mol.get('nmr_analysis', {}).get('matching_scores', {}).get('by_spectrum', {}).get('HSQC', None)\n",
    "                        # Only include molecules with a valid HSQC score\n",
    "                        if hsqc_score is not None:\n",
    "                            processed_mol = {\n",
    "                                'smiles': mol['smiles'],\n",
    "                                'hsqc_score': hsqc_score\n",
    "                            }\n",
    "                            all_molecules.append(processed_mol)\n",
    "                    except KeyError as e:\n",
    "                        # Log or print a warning if essential keys like 'smiles' are missing\n",
    "                        # print(f\"Warning: Skipping molecule in {analysis_type} due to missing key: {e}\")\n",
    "                        continue\n",
    "    except KeyError as e:\n",
    "        # Log or print if 'candidate_analysis' is missing\n",
    "        # print(f\"Warning: 'candidate_analysis' not found in JSON data: {e}\")\n",
    "        return [] # Return empty list if the structure is unexpected\n",
    "\n",
    "    # Remove duplicates based on SMILES, keeping the one with the best (lowest) HSQC score\n",
    "    unique_molecules = {}\n",
    "    for mol in all_molecules:\n",
    "        smiles = mol['smiles']\n",
    "        if smiles not in unique_molecules or mol['hsqc_score'] < unique_molecules[smiles]['hsqc_score']:\n",
    "             unique_molecules[smiles] = mol\n",
    "\n",
    "    # Sort unique molecules by HSQC score (ascending, None treated as infinity)\n",
    "    sorted_molecules = sorted(\n",
    "        list(unique_molecules.values()),\n",
    "        key=lambda x: x['hsqc_score'] if x['hsqc_score'] is not None else float('inf')\n",
    "    )\n",
    "\n",
    "    return sorted_molecules\n",
    "\n",
    "def find_molecule_rank(sorted_molecules: List[Dict[str, Any]], true_smiles: str) -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Find the rank (1-based index) of the true SMILES in a list sorted by HSQC score.\n",
    "\n",
    "    Args:\n",
    "        sorted_molecules: List of molecule dictionaries sorted by HSQC score.\n",
    "        true_smiles: The ground truth SMILES string.\n",
    "\n",
    "    Returns:\n",
    "        The rank (int) if found, otherwise None.\n",
    "    \"\"\"\n",
    "    for idx, mol in enumerate(sorted_molecules, 1):\n",
    "        if mol['smiles'] == true_smiles:\n",
    "            return idx\n",
    "    return None\n",
    "\n",
    "def analyze_llm_predictions(json_data: Dict, true_smiles: str, llm_name: str) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Analyze predictions from a specific LLM model based on confidence score.\n",
    "\n",
    "    Args:\n",
    "        json_data: Loaded JSON data for a single sample.\n",
    "        true_smiles: True SMILES string to compare against.\n",
    "        llm_name: Name of the LLM model to analyze (e.g., 'claude', 'o3').\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with analysis results for the LLM, or None if analysis fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Navigate to the parsed results for the specific LLM\n",
    "        llm_response_data = json_data.get(\"analysis_results\", {}).get(\"final_analysis\", {}).get(\"llm_responses\", {}).get(llm_name, {})\n",
    "        parsed_results = llm_response_data.get(\"parsed_results\", {})\n",
    "\n",
    "        # Ensure parsed_results is a dictionary and contains 'candidates'\n",
    "        if not isinstance(parsed_results, dict) or \"candidates\" not in parsed_results:\n",
    "             # Try to parse if it's a string that looks like JSON (common issue)\n",
    "            if isinstance(parsed_results, str):\n",
    "                try:\n",
    "                    parsed_results = json.loads(parsed_results)\n",
    "                    if not isinstance(parsed_results, dict) or \"candidates\" not in parsed_results:\n",
    "                         # print(f\"Warning: Parsed string for {llm_name} did not yield expected structure.\")\n",
    "                         return None\n",
    "                except json.JSONDecodeError:\n",
    "                     # print(f\"Warning: Could not parse 'parsed_results' string for {llm_name}.\")\n",
    "                     return None\n",
    "            else:\n",
    "                 # print(f\"Warning: 'parsed_results' for {llm_name} is not a dict or does not contain 'candidates'.\")\n",
    "                 return None\n",
    "\n",
    "        candidates = parsed_results[\"candidates\"]\n",
    "        if not isinstance(candidates, list):\n",
    "            # print(f\"Warning: 'candidates' for {llm_name} is not a list.\")\n",
    "            return None\n",
    "\n",
    "        # Filter out candidates without a valid confidence score and sort\n",
    "        valid_candidates = []\n",
    "        for cand in candidates:\n",
    "            if isinstance(cand, dict) and \"confidence_score\" in cand and isinstance(cand[\"confidence_score\"], (int, float)):\n",
    "                valid_candidates.append(cand)\n",
    "            # else:\n",
    "            #     print(f\"Warning: Skipping invalid candidate for {llm_name}: {cand}\")\n",
    "\n",
    "\n",
    "        if not valid_candidates:\n",
    "            # print(f\"Warning: No valid candidates with confidence scores found for {llm_name}.\")\n",
    "            return None\n",
    "\n",
    "        sorted_candidates = sorted(valid_candidates,\n",
    "                                 key=lambda x: x[\"confidence_score\"],\n",
    "                                 reverse=True)\n",
    "\n",
    "        # Find position of correct molecule\n",
    "        correct_position_llm = None\n",
    "        for i, cand in enumerate(sorted_candidates, 1):\n",
    "            if isinstance(cand, dict) and cand.get(\"smiles\") == true_smiles:\n",
    "                correct_position_llm = i\n",
    "                break\n",
    "\n",
    "        return {\n",
    "            \"llm_model\": llm_name,\n",
    "            \"correct_position_llm\": correct_position_llm,\n",
    "            \"total_candidates_llm\": len(sorted_candidates),\n",
    "            \"is_top_1_llm\": correct_position_llm == 1,\n",
    "            \"is_top_3_llm\": correct_position_llm is not None and correct_position_llm <= 3,\n",
    "            \"is_top_5_llm\": correct_position_llm is not None and correct_position_llm <= 5,\n",
    "        }\n",
    "\n",
    "    except KeyError as e:\n",
    "        # print(f\"Info: LLM '{llm_name}' results not found or key missing: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        # Catch other potential errors during processing\n",
    "        # print(f\"Error analyzing LLM '{llm_name}' predictions: {type(e).__name__} - {e}\")\n",
    "        return None\n",
    "\n",
    "def analyze_single_zinc_json(json_file: str) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Analyze a single ZINC JSON file for HSQC baseline ranking and all LLM rankings.\n",
    "\n",
    "    Args:\n",
    "        json_file: Path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing combined analysis results for the sample, or None if basic info missing.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # --- Extract Basic Info ---\n",
    "        molecule_data = data.get(\"molecule_data\", {})\n",
    "        sample_id = molecule_data.get(\"sample_id\")\n",
    "        true_smiles = molecule_data.get(\"smiles\") # ZINC data should have true SMILES here\n",
    "\n",
    "        if not sample_id or not true_smiles:\n",
    "            print(f\"Warning: Skipping {json_file.name}. Missing 'sample_id' or 'smiles' in 'molecule_data'.\")\n",
    "            return None\n",
    "\n",
    "        # --- HSQC Baseline Analysis ---\n",
    "        hsqc_candidates = process_single_json_candidates(data)\n",
    "        hsqc_rank = find_molecule_rank(hsqc_candidates, true_smiles)\n",
    "\n",
    "        baseline_results = {\n",
    "            \"sample_id\": sample_id,\n",
    "            \"true_smiles\": true_smiles,\n",
    "            \"hsqc_rank\": hsqc_rank,\n",
    "            \"total_candidates_hsqc\": len(hsqc_candidates),\n",
    "            \"is_top_1_hsqc\": hsqc_rank == 1,\n",
    "            \"is_top_3_hsqc\": hsqc_rank is not None and hsqc_rank <= 3,\n",
    "            \"is_top_5_hsqc\": hsqc_rank is not None and hsqc_rank <= 5,\n",
    "        }\n",
    "\n",
    "        # --- LLM Analysis ---\n",
    "        llm_analysis_results = {}\n",
    "        for llm_name in LLM_MODELS:\n",
    "            llm_result = analyze_llm_predictions(data, true_smiles, llm_name)\n",
    "            if llm_result:\n",
    "                 # Prefix keys with llm_name to avoid clashes in the final dict\n",
    "                 # llm_analysis_results.update({f\"{llm_name}_{k}\": v for k, v in llm_result.items() if k != 'llm_model'})\n",
    "                 llm_analysis_results[llm_name] = llm_result # Store results nested under LLM name\n",
    "\n",
    "\n",
    "        # --- Combine Results ---\n",
    "        combined_results = baseline_results\n",
    "        combined_results[\"llm_results\"] = llm_analysis_results # Store LLM results nested\n",
    "\n",
    "        return combined_results\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Could not parse JSON file: {Path(json_file).name}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {Path(json_file).name}: {type(e).__name__} - {e}\")\n",
    "        # import traceback\n",
    "        # print(traceback.format_exc()) # Optional: print full traceback for debugging\n",
    "        return None\n",
    "\n",
    "def analyze_zinc_directory(json_dir: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analyze all JSON files in the ZINC directory.\n",
    "\n",
    "    Args:\n",
    "        json_dir: Directory containing the ZINC JSON files.\n",
    "\n",
    "    Returns:\n",
    "        Pandas DataFrame containing aggregated analysis results.\n",
    "    \"\"\"\n",
    "    json_files = glob.glob(os.path.join(json_dir, \"*.json\"))\n",
    "    print(f\"Found {len(json_files)} JSON files in {json_dir}\")\n",
    "\n",
    "    all_results = []\n",
    "    for file_path in json_files:\n",
    "        result = analyze_single_zinc_json(file_path)\n",
    "        if result:\n",
    "            all_results.append(result)\n",
    "\n",
    "    if not all_results:\n",
    "        print(\"Warning: No files were successfully processed.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Flatten the results for DataFrame creation\n",
    "    flat_results = []\n",
    "    for sample_result in all_results:\n",
    "        row = {k: v for k, v in sample_result.items() if k != 'llm_results'}\n",
    "        for llm_name, llm_data in sample_result.get('llm_results', {}).items():\n",
    "             # Add LLM specific results with prefixed keys\n",
    "             row.update({f\"{llm_name}_{k}\": v for k, v in llm_data.items() if k != 'llm_model'})\n",
    "        flat_results.append(row)\n",
    "\n",
    "\n",
    "    return pd.DataFrame(flat_results)\n",
    "\n",
    "# --- Plotting Functions ---\n",
    "\n",
    "def plot_ranking_histogram(rankings: List[Optional[int]], title: str, color: str, max_rank: int = 5, ax: Optional[plt.Axes] = None) -> plt.Axes:\n",
    "    \"\"\"\n",
    "    Plot a histogram of rankings for a specific method (HSQC or LLM).\n",
    "\n",
    "    Args:\n",
    "        rankings: List of ranks (int or None).\n",
    "        title: Title for the subplot.\n",
    "        color: Color for the histogram bars.\n",
    "        max_rank: Maximum rank to show on the x-axis.\n",
    "        ax: Matplotlib Axes object to plot on. If None, creates a new one.\n",
    "\n",
    "    Returns:\n",
    "        Matplotlib Axes object with the plot.\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(6, 5), facecolor='white')\n",
    "        ax.set_facecolor('white')\n",
    "\n",
    "    valid_rankings = [r for r in rankings if r is not None]\n",
    "    total_analyzed = len(rankings)\n",
    "    total_found = len(valid_rankings)\n",
    "\n",
    "    bins = np.arange(1, max_rank + 2) - 0.5\n",
    "\n",
    "    n, _, _ = ax.hist(\n",
    "        [r for r in valid_rankings if r <= max_rank],\n",
    "        bins=bins,\n",
    "        edgecolor='black',\n",
    "        alpha=0.75,\n",
    "        color=color,\n",
    "    )\n",
    "\n",
    "    ax.set_title(title, fontsize=14, pad=15)\n",
    "    ax.set_xlabel('Rank', fontsize=12)\n",
    "    ax.set_ylabel('Number of Molecules', fontsize=12)\n",
    "    ax.set_xticks(range(1, max_rank + 1))\n",
    "    ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "    ax.grid(True, alpha=0.3, color='gray', linestyle='--')\n",
    "\n",
    "    # Add counts above bars\n",
    "    for i, count in enumerate(n):\n",
    "        if count > 0:\n",
    "            ax.text(i + 1, count + 0.01 * total_analyzed, f'{int(count)}',\n",
    "                   ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "    # Calculate statistics for annotation\n",
    "    if total_analyzed > 0:\n",
    "        in_top_1 = sum(1 for r in valid_rankings if r == 1)\n",
    "        in_top_3 = sum(1 for r in valid_rankings if r <= 3)\n",
    "        in_top_5 = sum(1 for r in valid_rankings if r <= 5)\n",
    "        top_1_percent = (in_top_1 / total_analyzed) * 100\n",
    "        top_3_percent = (in_top_3 / total_analyzed) * 100\n",
    "        top_5_percent = (in_top_5 / total_analyzed) * 100\n",
    "\n",
    "        stats_text = (\n",
    "            #f'Total: {total_analyzed}\\n'\n",
    "            f'Found: {total_found} ({total_found/total_analyzed*100:.1f}%)\\n'\n",
    "            f'Top 1: {in_top_1} ({top_1_percent:.1f}%)\\n'\n",
    "            f'Top 3: {in_top_3} ({top_3_percent:.1f}%)\\n'\n",
    "            f'Top 5: {in_top_5} ({top_5_percent:.1f}%)'\n",
    "        )\n",
    "\n",
    "        ax.text(0.97, 0.97, stats_text,\n",
    "                transform=ax.transAxes,\n",
    "                verticalalignment='top',\n",
    "                horizontalalignment='right',\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
    "                fontsize=9)\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, \"No data\", ha='center', va='center', fontsize=12)\n",
    "\n",
    "    ax.set_ylim(bottom=0) # Ensure y-axis starts at 0\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def create_comparison_plots(results_df: pd.DataFrame, output_dir: Path):\n",
    "    \"\"\"\n",
    "    Creates and saves comparison histogram plots for HSQC baseline and each LLM.\n",
    "\n",
    "    Args:\n",
    "        results_df: DataFrame containing the analysis results.\n",
    "        output_dir: Path object for the directory to save plots.\n",
    "    \"\"\"\n",
    "    num_llms = len(LLM_MODELS)\n",
    "    num_plots = num_llms + 1 # +1 for HSQC baseline\n",
    "    n_cols = 3\n",
    "    n_rows = (num_plots + n_cols - 1) // n_cols\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(6 * n_cols, 5 * n_rows), facecolor='white', squeeze=False)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # 1. Plot HSQC Baseline\n",
    "    hsqc_ranks = results_df['hsqc_rank'].tolist()\n",
    "    plot_ranking_histogram(hsqc_ranks, \"HSQC Score Ranking (Baseline)\", LLM_COLORS[\"HSQC Baseline\"], max_rank=5, ax=axes[0])\n",
    "\n",
    "    # 2. Plot Each LLM\n",
    "    plot_idx = 1\n",
    "    for llm_name in LLM_MODELS:\n",
    "        rank_col = f\"{llm_name}_correct_position_llm\"\n",
    "        if rank_col in results_df.columns:\n",
    "            llm_ranks = results_df[rank_col].tolist()\n",
    "            plot_ranking_histogram(llm_ranks, f\"{llm_name.upper()} Confidence Ranking\", LLM_COLORS[llm_name], max_rank=5, ax=axes[plot_idx])\n",
    "            plot_idx += 1\n",
    "        else:\n",
    "            print(f\"Info: No ranking data found for LLM: {llm_name}\")\n",
    "             # Optionally add a placeholder plot or text\n",
    "            axes[plot_idx].text(0.5, 0.5, f\"No data for\\n{llm_name.upper()}\", ha='center', va='center', fontsize=12)\n",
    "            axes[plot_idx].set_title(f\"{llm_name.upper()} Confidence Ranking\", fontsize=14, pad=15)\n",
    "            axes[plot_idx].set_xticks([])\n",
    "            axes[plot_idx].set_yticks([])\n",
    "            plot_idx += 1\n",
    "\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for i in range(plot_idx, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "\n",
    "    fig.suptitle(f\"Ranking Performance Comparison (ZINC Dataset)\", fontsize=18, y=1.02)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.98]) # Adjust layout\n",
    "    plot_filename = output_dir / \"ranking_comparison_histograms_zinc.png\"\n",
    "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved comparison histogram plot to: {plot_filename}\")\n",
    "    plt.close(fig) # Close the figure to prevent displaying it inline if not desired\n",
    "\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"--- Starting ZINC Data Analysis ---\")\n",
    "    print(f\"Input data directory: {ZINC_DATA_DIR}\")\n",
    "    print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "\n",
    "    # Analyze the directory\n",
    "    analysis_df = analyze_zinc_directory(ZINC_DATA_DIR)\n",
    "\n",
    "    if not analysis_df.empty:\n",
    "        # Save the detailed results DataFrame\n",
    "        detailed_results_file = OUTPUT_DIR / \"detailed_analysis_results_zinc.csv\"\n",
    "        analysis_df.to_csv(detailed_results_file, index=False)\n",
    "        print(f\"\\nSaved detailed analysis results to: {detailed_results_file}\")\n",
    "\n",
    "        # --- Generate Summary Statistics ---\n",
    "        summary = {}\n",
    "        total_samples = len(analysis_df)\n",
    "        summary[\"Total Samples Processed\"] = total_samples\n",
    "\n",
    "        # HSQC Baseline Summary\n",
    "        hsqc_top1 = analysis_df['is_top_1_hsqc'].sum()\n",
    "        hsqc_top3 = analysis_df['is_top_3_hsqc'].sum()\n",
    "        hsqc_top5 = analysis_df['is_top_5_hsqc'].sum()\n",
    "        hsqc_found = analysis_df['hsqc_rank'].notna().sum()\n",
    "        summary[\"HSQC Baseline\"] = {\n",
    "            \"Top-1\": f\"{hsqc_top1} ({hsqc_top1/total_samples*100:.1f}%)\",\n",
    "            \"Top-3\": f\"{hsqc_top3} ({hsqc_top3/total_samples*100:.1f}%)\",\n",
    "            \"Top-5\": f\"{hsqc_top5} ({hsqc_top5/total_samples*100:.1f}%)\",\n",
    "            \"Found\": f\"{hsqc_found} ({hsqc_found/total_samples*100:.1f}%)\"\n",
    "        }\n",
    "\n",
    "        # LLM Summaries\n",
    "        for llm_name in LLM_MODELS:\n",
    "            top1_col = f\"{llm_name}_is_top_1_llm\"\n",
    "            top3_col = f\"{llm_name}_is_top_3_llm\"\n",
    "            top5_col = f\"{llm_name}_is_top_5_llm\"\n",
    "            rank_col = f\"{llm_name}_correct_position_llm\"\n",
    "\n",
    "            if top1_col in analysis_df.columns:\n",
    "                llm_top1 = analysis_df[top1_col].sum()\n",
    "                llm_top3 = analysis_df[top3_col].sum()\n",
    "                llm_top5 = analysis_df[top5_col].sum()\n",
    "                llm_found = analysis_df[rank_col].notna().sum()\n",
    "                summary[f\"{llm_name.upper()} LLM\"] = {\n",
    "                    \"Top-1\": f\"{llm_top1} ({llm_top1/total_samples*100:.1f}%)\",\n",
    "                    \"Top-3\": f\"{llm_top3} ({llm_top3/total_samples*100:.1f}%)\",\n",
    "                    \"Top-5\": f\"{llm_top5} ({llm_top5/total_samples*100:.1f}%)\",\n",
    "                    \"Found\": f\"{llm_found} ({llm_found/total_samples*100:.1f}%)\"\n",
    "                }\n",
    "            else:\n",
    "                 summary[f\"{llm_name.upper()} LLM\"] = {\"Status\": \"No data found\"}\n",
    "\n",
    "\n",
    "        # Save summary statistics\n",
    "        summary_file = OUTPUT_DIR / \"summary_statistics_zinc.json\"\n",
    "        with open(summary_file, 'w') as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "        print(f\"Saved summary statistics to: {summary_file}\")\n",
    "        print(\"\\nSummary Statistics:\")\n",
    "        print(json.dumps(summary, indent=2))\n",
    "\n",
    "\n",
    "        # --- Create Plots ---\n",
    "        print(\"\\nGenerating comparison plots...\")\n",
    "        create_comparison_plots(analysis_df, OUTPUT_DIR)\n",
    "\n",
    "    else:\n",
    "        print(\"\\nAnalysis finished, but no data was generated. Check input files and logs.\")\n",
    "\n",
    "    print(\"\\n--- ZINC Data Analysis Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb190ad-029c-477f-96ca-0835b783b1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Configuration ---\n",
    "# Directory where the analysis results (including summary) are stored\n",
    "ANALYSIS_DIR = Path(\"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/ZINC_large/analysis_results_zinc\")\n",
    "SUMMARY_FILE = ANALYSIS_DIR / \"summary_statistics_zinc.json\"\n",
    "OUTPUT_PLOT_FILE = ANALYSIS_DIR / \"top1_accuracy_improvement_zinc.png\"\n",
    "\n",
    "# --- Load Data ---\n",
    "try:\n",
    "    with open(SUMMARY_FILE, 'r') as f:\n",
    "        summary_data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Summary file not found at {SUMMARY_FILE}\")\n",
    "    exit()\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error: Could not decode JSON from {SUMMARY_FILE}\")\n",
    "    exit()\n",
    "\n",
    "# --- Extract Required Accuracy Data ---\n",
    "# Helper function to parse percentage string like \"31 (12.3%)\" -> 12.3\n",
    "def parse_accuracy_percent(stat_entry: str) -> float:\n",
    "    \"\"\"Extracts the percentage value from a string like 'N (P%)'.\"\"\"\n",
    "    try:\n",
    "        # Find percentage value within parentheses\n",
    "        percent_str = stat_entry.split('(')[1].split('%')[0]\n",
    "        return float(percent_str)\n",
    "    except (IndexError, ValueError, TypeError):\n",
    "        print(f\"Warning: Could not parse accuracy from entry: {stat_entry}. Returning 0.0\")\n",
    "        return 0.0 # Return 0.0 if parsing fails\n",
    "\n",
    "# Extract Top-1 accuracies, providing default value if keys are missing\n",
    "try:\n",
    "    baseline_stats = summary_data.get(\"HSQC Baseline\", {})\n",
    "    deepseek_stats = summary_data.get(\"DEEPSEEK LLM\", {})\n",
    "\n",
    "    baseline_acc_str = baseline_stats.get(\"Top-1\", \"0 (0.0%)\")\n",
    "    deepseek_acc_str = deepseek_stats.get(\"Top-1\", \"0 (0.0%)\") # Default if DeepSeek data missing\n",
    "\n",
    "    if not deepseek_stats:\n",
    "         print(\"Warning: DEEPSEEK LLM data not found in summary. Using 0% accuracy.\")\n",
    "\n",
    "    baseline_acc = parse_accuracy_percent(baseline_acc_str)\n",
    "    deepseek_acc = parse_accuracy_percent(deepseek_acc_str)\n",
    "\n",
    "except KeyError as e:\n",
    "    print(f\"Error: Missing expected key in summary data: {e}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred while processing summary data: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- Plotting ---\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(8, 7)) # Adjusted size for better annotation spacing\n",
    "\n",
    "# Data for plotting\n",
    "methods = ['HSQC Baseline', 'DeepSeek LLM']\n",
    "accuracies = [baseline_acc, deepseek_acc]\n",
    "colors = ['#999999', '#CD853F'] # Consistent colors: Gray for baseline, Peru for DeepSeek\n",
    "\n",
    "# Create bars\n",
    "bars = ax.bar(methods, accuracies, color=colors, alpha=0.85, width=0.6)\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_ylabel('Top-1 Accuracy (%)', fontsize=13, fontweight='bold')\n",
    "ax.set_title('Top-1 Accuracy Improvement: HSQC Baseline vs. DeepSeek LLM\\n(ZINC Dataset)', fontsize=15, fontweight='bold', pad=20)\n",
    "ax.set_ylim(0, max(accuracies) * 1.20 if accuracies else 10) # Dynamic Y limit with more buffer for annotation\n",
    "ax.tick_params(axis='x', labelsize=12, rotation=0) # Keep x-labels horizontal\n",
    "ax.tick_params(axis='y', labelsize=11)\n",
    "\n",
    "# Add percentage values on top of bars\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2.0, yval + 0.8, f'{yval:.1f}%', # Increased vertical offset\n",
    "           va='bottom', ha='center', fontsize=11, fontweight='medium')\n",
    "\n",
    "# Add improvement annotation\n",
    "improvement = deepseek_acc - baseline_acc\n",
    "if deepseek_acc > 0: # Only show annotation if there's LLM data\n",
    "    # Position annotation between the bars, slightly above the highest bar\n",
    "    mid_x = (bars[0].get_x() + bars[0].get_width() / 2 + bars[1].get_x() + bars[1].get_width() / 2) / 2\n",
    "    annotation_y_pos = max(accuracies) * 0.65 # Adjust vertical position\n",
    "\n",
    "    # Arrow pointing from baseline area towards LLM bar\n",
    "    ax.annotate(f'Improvement\\n+{improvement:.1f}% pts',\n",
    "                xy=(bars[1].get_x() + bars[1].get_width() * 0.5, deepseek_acc * 0.95), # Arrow points slightly below top of LLM bar\n",
    "                xytext=(mid_x, annotation_y_pos),\n",
    "                arrowprops=dict(arrowstyle=\"->\", color='black',\n",
    "                                connectionstyle=\"arc3,rad=0.2\", # Curved arrow\n",
    "                                lw=1.5),\n",
    "                ha='center', va='center', fontsize=12, fontweight='bold',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.4\", fc=\"#FFFACD\", ec=\"grey\", lw=1, alpha=0.9)) # Lemon Chiffon background\n",
    "\n",
    "# Add grid\n",
    "ax.yaxis.grid(True, linestyle='--', alpha=0.6)\n",
    "ax.set_axisbelow(True) # Grid behind bars\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "try:\n",
    "    OUTPUT_PLOT_FILE.parent.mkdir(parents=True, exist_ok=True) # Ensure directory exists\n",
    "    plt.savefig(OUTPUT_PLOT_FILE, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\nSaved plot to: {OUTPUT_PLOT_FILE}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving plot: {e}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc9b0dd-b347-4618-a35b-6394820155c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2457d5e6-f630-4f53-a0a5-3d91637939e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "import seaborn as sns # Using seaborn styles\n",
    "\n",
    "# --- Configuration ---\n",
    "# Directory where the analysis results (including summary) are stored\n",
    "ANALYSIS_DIR = Path(\"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/ZINC_large/analysis_results_zinc\")\n",
    "SUMMARY_FILE = ANALYSIS_DIR / \"summary_statistics_zinc.json\"\n",
    "OUTPUT_PLOT_FILE_COMPARE = ANALYSIS_DIR / \"top_n_accuracy_comparison_zinc.png\"\n",
    "\n",
    "# Define colors\n",
    "BASELINE_COLOR = '#999999' # Gray\n",
    "DEEPSEEK_COLOR = '#CD853F' # Peru/Orange\n",
    "\n",
    "# --- Load Data ---\n",
    "try:\n",
    "    with open(SUMMARY_FILE, 'r') as f:\n",
    "        summary_data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Summary file not found at {SUMMARY_FILE}\")\n",
    "    exit()\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error: Could not decode JSON from {SUMMARY_FILE}\")\n",
    "    exit()\n",
    "\n",
    "# --- Extract Required Accuracy Data ---\n",
    "# Helper function to parse percentage string like \"31 (12.3%)\" -> 12.3\n",
    "def parse_accuracy_percent(stat_entry: str) -> float:\n",
    "    \"\"\"Extracts the percentage value from a string like 'N (P%)'.\"\"\"\n",
    "    try:\n",
    "        percent_str = stat_entry.split('(')[1].split('%')[0]\n",
    "        return float(percent_str)\n",
    "    except (IndexError, ValueError, TypeError):\n",
    "        print(f\"Warning: Could not parse accuracy from entry: {stat_entry}. Returning 0.0\")\n",
    "        return 0.0\n",
    "\n",
    "# Extract accuracies for Baseline and DeepSeek\n",
    "baseline_accuracies = {}\n",
    "deepseek_accuracies = {}\n",
    "accuracy_levels = [\"Top-1\", \"Top-3\", \"Top-5\"]\n",
    "\n",
    "try:\n",
    "    baseline_stats = summary_data.get(\"HSQC Baseline\", {})\n",
    "    deepseek_stats = summary_data.get(\"DEEPSEEK LLM\", {})\n",
    "\n",
    "    if not deepseek_stats:\n",
    "         print(\"Warning: DEEPSEEK LLM data not found in summary. Using 0% accuracy.\")\n",
    "\n",
    "    for level in accuracy_levels:\n",
    "        baseline_acc_str = baseline_stats.get(level, \"0 (0.0%)\")\n",
    "        deepseek_acc_str = deepseek_stats.get(level, \"0 (0.0%)\") # Default if missing\n",
    "\n",
    "        baseline_accuracies[level] = parse_accuracy_percent(baseline_acc_str)\n",
    "        deepseek_accuracies[level] = parse_accuracy_percent(deepseek_acc_str)\n",
    "\n",
    "except KeyError as e:\n",
    "    print(f\"Error: Missing expected key in summary data: {e}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred while processing summary data: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- Plotting ---\n",
    "plt.style.use('seaborn-v0_8-whitegrid') # Use a clean seaborn style\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharey=True) # 1 row, 2 columns, shared Y-axis\n",
    "\n",
    "# --- Plot 1: HSQC Baseline ---\n",
    "ax1 = axes[0]\n",
    "categories = list(baseline_accuracies.keys())\n",
    "values_baseline = list(baseline_accuracies.values())\n",
    "\n",
    "bars1 = ax1.bar(categories, values_baseline, color=BASELINE_COLOR, alpha=0.85, width=0.6)\n",
    "\n",
    "ax1.set_ylabel('Accuracy (%)', fontsize=13, fontweight='bold')\n",
    "ax1.set_title('HSQC Score Ranking Accuracy (Baseline)', fontsize=14, fontweight='bold', pad=15)\n",
    "ax1.set_ylim(0, 100) # Y-axis from 0 to 100%\n",
    "ax1.tick_params(axis='x', labelsize=12)\n",
    "ax1.tick_params(axis='y', labelsize=11)\n",
    "ax1.yaxis.grid(True, linestyle='--', alpha=0.6)\n",
    "ax1.set_axisbelow(True)\n",
    "\n",
    "# Add percentage values on top of baseline bars\n",
    "for bar in bars1:\n",
    "    yval = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2.0, yval + 1.5, f'{yval:.1f}%',\n",
    "           va='bottom', ha='center', fontsize=11, fontweight='medium')\n",
    "\n",
    "# --- Plot 2: DeepSeek LLM ---\n",
    "ax2 = axes[1]\n",
    "values_deepseek = list(deepseek_accuracies.values())\n",
    "\n",
    "bars2 = ax2.bar(categories, values_deepseek, color=DEEPSEEK_COLOR, alpha=0.85, width=0.6)\n",
    "\n",
    "ax2.set_title('DeepSeek LLM Confidence Ranking Accuracy', fontsize=14, fontweight='bold', pad=15)\n",
    "# ax2.set_ylabel('Accuracy (%)', fontsize=13, fontweight='bold') # Y label is shared\n",
    "ax2.set_ylim(0, 100) # Ensure consistent Y-axis limit\n",
    "ax2.tick_params(axis='x', labelsize=12)\n",
    "ax2.tick_params(axis='y', labelsize=11)\n",
    "ax2.yaxis.grid(True, linestyle='--', alpha=0.6)\n",
    "ax2.set_axisbelow(True)\n",
    "\n",
    "\n",
    "# Add percentage values on top of DeepSeek bars\n",
    "for bar in bars2:\n",
    "    yval = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2.0, yval + 1.5, f'{yval:.1f}%',\n",
    "           va='bottom', ha='center', fontsize=11, fontweight='medium')\n",
    "\n",
    "\n",
    "# Add overall title\n",
    "fig.suptitle('Top-N Accuracy Comparison: Baseline vs. DeepSeek LLM (ZINC Dataset)', fontsize=16, fontweight='bold', y=1.03)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.97]) # Adjust layout slightly for suptitle\n",
    "\n",
    "# Save the figure\n",
    "try:\n",
    "    OUTPUT_PLOT_FILE_COMPARE.parent.mkdir(parents=True, exist_ok=True) # Ensure directory exists\n",
    "    plt.savefig(OUTPUT_PLOT_FILE_COMPARE, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\nSaved comparison plot to: {OUTPUT_PLOT_FILE_COMPARE}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving plot: {e}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb979151-3493-4ff7-973c-2243a4ae974c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2897a9b-4af2-4854-9f57-86ff6cda2a76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedb616b-bd2f-4529-bbb3-4211dbdeba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import seaborn as sns # Using seaborn styles\n",
    "\n",
    "# --- Configuration ---\n",
    "# Directory where the analysis results are stored\n",
    "ANALYSIS_DIR = Path(\"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/ZINC_large/analysis_results_zinc\")\n",
    "DETAILED_RESULTS_FILE = ANALYSIS_DIR / \"detailed_analysis_results_zinc.csv\"\n",
    "OUTPUT_PLOT_FILE_HSQC_COUNTS_CENTERED = ANALYSIS_DIR / \"hsqc_top10_counts_centered_accuracy_zinc.png\"\n",
    "\n",
    "# Define color for baseline\n",
    "BASELINE_COLOR = '#999999' # Gray\n",
    "TEXT_COLOR_INSIDE = 'white' # Color for text inside bars\n",
    "\n",
    "# --- Load Data ---\n",
    "try:\n",
    "    results_df = pd.read_csv(DETAILED_RESULTS_FILE)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Detailed results file not found at {DETAILED_RESULTS_FILE}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading detailed results: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- Validate Data ---\n",
    "if 'hsqc_rank' not in results_df.columns:\n",
    "    print(f\"Error: Column 'hsqc_rank' not found in {DETAILED_RESULTS_FILE}\")\n",
    "    exit()\n",
    "\n",
    "if results_df.empty:\n",
    "    print(\"Error: The detailed results file is empty.\")\n",
    "    exit()\n",
    "\n",
    "# --- Calculate Cumulative Accuracies and Counts for HSQC Baseline ---\n",
    "total_samples = len(results_df)\n",
    "print(f\"Total samples analyzed: {total_samples}\")\n",
    "\n",
    "top_n_accuracies = {}\n",
    "top_n_counts = {} # Dictionary to store absolute counts\n",
    "max_n = 10 # Calculate up to Top-10\n",
    "\n",
    "# Ensure hsqc_rank is numeric, coerce errors, drop rows where rank is unknown for calculation\n",
    "results_df['hsqc_rank'] = pd.to_numeric(results_df['hsqc_rank'], errors='coerce')\n",
    "valid_ranks_df = results_df.dropna(subset=['hsqc_rank'])\n",
    "count_found_any_rank = len(valid_ranks_df)\n",
    "print(f\"Samples with valid HSQC rank (molecule found): {count_found_any_rank}\")\n",
    "\n",
    "\n",
    "# Calculate Top-N cumulative accuracies and counts\n",
    "for n in range(1, max_n + 1):\n",
    "    category_name = f\"Top-{n}\"\n",
    "    count_at_n_or_better = valid_ranks_df[valid_ranks_df['hsqc_rank'] <= n].shape[0]\n",
    "    accuracy_percent = (count_at_n_or_better / total_samples) * 100 if total_samples > 0 else 0\n",
    "    top_n_accuracies[category_name] = accuracy_percent\n",
    "    top_n_counts[category_name] = count_at_n_or_better # Store the count\n",
    "\n",
    "# Calculate overall 'Found' percentage and count\n",
    "category_name_found = \"Found (Any Rank)\"\n",
    "accuracy_found_any_rank = (count_found_any_rank / total_samples) * 100 if total_samples > 0 else 0\n",
    "top_n_accuracies[category_name_found] = accuracy_found_any_rank\n",
    "top_n_counts[category_name_found] = count_found_any_rank # Store the count\n",
    "\n",
    "print(\"\\nCalculated Cumulative Accuracies and Counts (HSQC Baseline):\")\n",
    "for level, acc in top_n_accuracies.items():\n",
    "    count = top_n_counts[level]\n",
    "    print(f\"  {level}: {acc:.1f}% ({count}/{total_samples})\")\n",
    "\n",
    "\n",
    "# --- Plotting ---\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "categories = list(top_n_accuracies.keys())\n",
    "values = list(top_n_accuracies.values())\n",
    "\n",
    "plot_colors = [BASELINE_COLOR] * len(categories)\n",
    "bars = ax.bar(categories, values, color=plot_colors, alpha=0.85, width=0.7)\n",
    "\n",
    "# Customize plot\n",
    "ax.set_ylabel('Cumulative Accuracy (%)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Rank Cutoff', fontsize=14, fontweight='bold')\n",
    "ax.set_title('HSQC Baseline Cumulative Top-N Accuracy', fontsize=16, fontweight='bold', pad=20)\n",
    "ax.set_ylim(0, 105)\n",
    "ax.tick_params(axis='x', labelsize=12)\n",
    "ax.tick_params(axis='y', labelsize=12)\n",
    "ax.yaxis.grid(True, linestyle='--', alpha=0.6)\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "# Add percentage values ABOVE bars and counts INSIDE bars (vertically centered)\n",
    "MIN_HEIGHT_FOR_INSIDE_LABEL = 10 # Minimum bar height (%) to add inside label (increased slightly)\n",
    "\n",
    "for i, bar in enumerate(bars):\n",
    "    yval = bar.get_height()\n",
    "    category_name = categories[i]\n",
    "    count = top_n_counts[category_name]\n",
    "\n",
    "    # Add percentage label ABOVE the bar\n",
    "    ax.text(bar.get_x() + bar.get_width()/2.0, yval + 1.5, f'{yval:.1f}%',\n",
    "           va='bottom', ha='center', fontsize=10, fontweight='medium')\n",
    "\n",
    "    # Add count label INSIDE the bar (if bar is tall enough)\n",
    "    if yval > MIN_HEIGHT_FOR_INSIDE_LABEL:\n",
    "        # Position the count label vertically centered within the bar\n",
    "        inside_y_pos = yval / 2\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2.0, inside_y_pos, str(count),\n",
    "                va='center', ha='center', # Use 'center' for vertical alignment\n",
    "                color=TEXT_COLOR_INSIDE, fontsize=10, fontweight='bold')\n",
    "\n",
    "\n",
    "# Add total samples info text box\n",
    "ax.text(0.02, 0.95, f'Total Samples Analyzed: {total_samples}',\n",
    "        transform=ax.transAxes, ha='left', va='top',\n",
    "        fontsize=11, style='italic', bbox=dict(boxstyle='round,pad=0.3', fc='white', ec='grey', lw=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "try:\n",
    "    OUTPUT_PLOT_FILE_HSQC_COUNTS_CENTERED.parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(OUTPUT_PLOT_FILE_HSQC_COUNTS_CENTERED, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\nSaved HSQC plot with centered counts inside bars to: {OUTPUT_PLOT_FILE_HSQC_COUNTS_CENTERED}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving plot: {e}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31d0488-9b87-4567-be95-ba182f6e1a64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958b0fa1-229b-4cd8-81cc-9b2a03de2181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276cb8c5-1d8f-4397-ab41-03880c27da09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35efe108-af7f-411b-8e07-4e985c970665",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Combine json Files for rerunning parts of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b032941d-50a8-4a56-baca-8e5bd0260524",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "def combine_json_files(input_folder, output_file):\n",
    "    \"\"\"\n",
    "    Combines multiple JSON files from a folder into a single JSON file.\n",
    "    Uses sample_id as the parent key, with all data (including sample_id and SMILES)\n",
    "    at the same hierarchical level within each entry.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_folder : str\n",
    "        Path to the folder containing JSON files\n",
    "    output_file : str\n",
    "        Path where the combined JSON file should be saved\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert input paths to Path objects\n",
    "    input_path = Path(input_folder)\n",
    "    output_path = Path(output_file)\n",
    "    \n",
    "    # Initialize the combined data dictionary\n",
    "    combined_data = {}\n",
    "    \n",
    "    # Count processed files for reporting\n",
    "    processed_files = 0\n",
    "    skipped_files = 0\n",
    "    files =  input_path.glob('*.json')\n",
    "    # Iterate through all JSON files in the folder\n",
    "    for json_file in  input_path.glob('*.json'):\n",
    "        try:\n",
    "            # Read the JSON file\n",
    "            with open(json_file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            # Check for required fields\n",
    "            if 'sample_id' not in data[\"molecule_data\"]:\n",
    "                print(f\"Warning: {json_file.name} does not contain 'sample_id'. Skipping...\")\n",
    "                skipped_files += 1\n",
    "                continue\n",
    "                \n",
    "            sample_id = data[\"molecule_data\"]['sample_id']\n",
    "            \n",
    "            # Initialize or update the entry\n",
    "            if sample_id not in combined_data:\n",
    "                combined_data[sample_id] = {\n",
    "                    'sample_id': sample_id,\n",
    "                    'SMILES': None  # Initialize SMILES as None\n",
    "                }\n",
    "            \n",
    "            # Update SMILES if present in the data\n",
    "            if 'smiles' in data[\"molecule_data\"]:\n",
    "                combined_data[sample_id]['smiles'] = data[\"molecule_data\"]['smiles']\n",
    "            \n",
    "            # Update all other data\n",
    "            for key, value in data.items():\n",
    "                #if key != 'sample_id':  # Don't overwrite sample_id\n",
    "                    combined_data[sample_id][key] = value\n",
    "            \n",
    "            processed_files += 1\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error: Could not parse JSON file: {json_file.name}\")\n",
    "            skipped_files += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {json_file.name}: {str(e)}\")\n",
    "            skipped_files += 1\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Write the combined data to the output file\n",
    "    try:\n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(combined_data, f, indent=2)\n",
    "        print(f\"Successfully combined {processed_files} files into {len(combined_data)} entries in {output_path}\")\n",
    "        if skipped_files > 0:\n",
    "            print(f\"Skipped {skipped_files} files due to errors or missing required fields\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing output file: {str(e)}\")\n",
    "\n",
    "\n",
    "    return combined_data\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/do_json\"\n",
    "    output_file = \"/projects/cc/se_users/knlr326/1_NMR_project/2_Notebooks/MMT_explainability/LLM_Structure_Elucidator/_temp_folder/intermediate_results/molecular_data.json\"\n",
    "    \n",
    "    # Combine the files\n",
    "    combined_data = combine_json_files(input_folder, output_file)\n",
    "    \n",
    "    # Print first entry structure (for verification)\n",
    "    if combined_data:\n",
    "        first_key = next(iter(combined_data))\n",
    "        print(\"\\nStructure of first entry:\")\n",
    "        print(json.dumps({first_key: combined_data[first_key]}, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3c9e1c-2f12-479a-b83a-cabe407f0c9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe66f4fd-c69e-445c-940a-2112b607e9f6",
   "metadata": {},
   "source": [
    "# Test MCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bde418-4769-4dd7-88fc-a8824f8d1807",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install mcp[cli]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce0cdb5-5480-44fb-8723-3aa6bb2e7d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mcp dev simple_mcp_server.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cda1bfb-472c-4735-9144-842a27fe24d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from anthropic import Anthropic\n",
    "from mcp import ClientSession\n",
    "from mcp.client.http import http_client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951a6a80-75d8-4b38-8bf4-d1bdf7feb701",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debb1222-2096-47f9-9c3b-9336c9cb8cab",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d457d0c7-d393-4a80-ab44-10a2940bad80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[\"analysis_results\"][\"final_analysis\"][\"llm_responses\"][\"kimi\"][\"parsed_results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c454c635-3961-4e34-bfe7-f39dec3b3ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8570c5-8374-4f56-b338-1626b03c4ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"analysis_results\"][\"final_analysis\"][\"llm_responses\"][\"kimi\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f502bdda-a0af-4e2c-845c-3afcee31d29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"analysis_results\"][\"final_analysis\"][\"llm_responses\"][\"kimi\"][\"parsed_results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbbc891-e3d3-4ea4-a188-011a1802e547",
   "metadata": {},
   "outputs": [],
   "source": [
    "          \"thinking\": \"Alright, let's dive into this intriguing puzzle of determining the most likely molecular structure among the given candidates based on the spectral and analytical evidence. This is going to be a meticulous process, dissecting each piece of information to ensure we arrive at the correct conclusion.\\n\\n**Understanding the Task:**\\n\\nWe have a target molecule with a specific molecular weight (259.168462292) but an unknown formula. Five candidate structures are provided, each with their SMILES notation, molecular weight, and formula. Importantly, four of these candidates share the same molecular weight and formula (C15H21N3O), while the fifth has a slightly different molecular weight and formula (C14H20N4O). Our goal is to analyze all available spectral data, particularly the HSQC data, to determine which candidate best matches the experimental evidence.\\n\\n**Approach:**\\n\\n1. **Initial Screening:** First, I'll perform a quick comparison of the molecular weights and formulas. This will immediately help in shortlisting the candidates that match the target's molecular weight.\\n\\n2. **Detailed Spectral Analysis:** For each candidate, I'll analyze the available HSQC data, comparing the predicted and experimental chemical shifts. I'll pay close attention to the nature and magnitude of any deviations.\\n\\n3. **Structural Feature Evaluation:** I'll examine the structural features of each candidate, considering how well they align with the observed spectral data. This includes the types of functional groups present, their expected chemical shifts, and any characteristic spectral patterns they might produce.\\n\\n4. **Data Quality Assessment:** It's crucial to evaluate the quality of the spectral data itself. Any inconsistencies or potential errors in the data could impact our conclusions.\\n\\n5. **Comparative Analysis and Final Recommendation:** After analyzing each candidate, I'll compare the findings to identify the candidate with the strongest overall support from the data. I'll then provide a final recommendation, including a confidence score and a detailed explanation of the reasoning.\\n\\n**Step 1: Initial Screening Based on Molecular Weight and Formula**\\n\\nLet's first compare the molecular weights and formulas of the candidates with the target:\\n\\n- **Target:** Molecular Weight = 259.168462292, Formula = Unknown\\n- **Candidate 1:** Molecular Weight = 259.168462292, Formula = C15H21N3O\\n- **Candidate 2:** Molecular Weight = 259.168462292, Formula = C15H21N3O\\n- **Candidate 3:** Molecular Weight = 259.168462292, Formula = C15H21N3O\\n- **Candidate 4:** Molecular Weight = 260.16371126, Formula = C14H20N4O\\n- **Candidate 5:** Molecular Weight = 259.168462292, Formula = C15H21N3O\\n\\n**Observation:** Candidates 1, 2, 3, and 5 perfectly match the target's molecular weight and likely its formula as well. Candidate 4 has a slightly different molecular weight and formula, making it an outlier at this stage. Unless there's a compelling reason from the spectral data to consider Candidate 4, our primary focus will be on the other four. However, I won't completely disregard Candidate 4 yet, as there might be a justification for the discrepancy, such as a different isotopic composition or a measurement error.\\n\\n**Step 2: Detailed Spectral Analysis (HSQC) for Each Candidate**\\n\\nNow, let's delve into the HSQC data for each candidate. I'll analyze the predicted vs. experimental chemical shifts, focusing on the nature and magnitude of any deviations.\\n\\n**Candidate 1: COc1ccnc2cccc(NC(C)CCCN)c12**\\n\\n- **HSQC Error:** 2.1222373347931835\\n- **Detailed Analysis:**\\n  - **Aliphatic Region (Atoms 0-6):** Errors are minimal (0.011-0.079), indicating a strong match. This suggests that the pentane-1,4-diamine chain is correctly positioned and substituted.\\n  - **Methoxy Group (Atom 5):** Error of 0.029, which is acceptable. This confirms the presence and likely position of the methoxy group.\\n  - **Aromatic Protons (Atoms 7-11):** Most show good correlation with errors below 0.1, except for atoms 8 and 10, which have significant deviations (0.900 and 0.701, respectively). This could indicate differences in the electronic environment of these carbons, possibly due to tautomerism or solvent effects.\\n  - **Amine-Adjacent Methylene (Atom 6):** Error of 0.114, which is moderate.\\n\\n**Conclusion for Candidate 1:** The overall structure is largely supported, especially the aliphatic chain and methoxy substitution. However, the significant deviations in the aromatic region require further investigation. It's possible that these deviations are due to electronic effects rather than a fundamental structural error.\\n\\n**Candidate 2: COc1ccc(NC(C)CCCN)c2cccnc12**\\n\\n- **HSQC Error:** 2.3838264192736895\\n- **Detailed Analysis:**\\n  - **Aliphatic Region:** Excellent matches with errors ranging from 0.001 to 0.043. This strongly supports the structure of the aminopentyl chain.\\n  - **Methoxy Group:** Good agreement, although the specific error isn't mentioned here.\\n  - **Aromatic Region:** Significant deviations are observed, particularly at atom 8 (error of 1.510). This suggests a mismatch in the electronic environment of this carbon, which could be due to the position of the methoxy group or other factors like tautomerism.\\n  - **Other Aromatic Atoms:** Moderate deviations (e.g., atom 10 with an error of 0.267) are also noted.\\n\\n**Conclusion for Candidate 2:** Similar to Candidate 1, the aliphatic portions show excellent agreement, providing confidence in that part of the structure. The aromatic region, however, has substantial deviations that need to be resolved. The position of the methoxy group might be a factor here.\\n\\n**Candidate 3: COc1ccc(NC(C)CCCN)c2ncccc12**\\n\\n- **HSQC Error:** 2.614620683844665\\n- **Detailed Analysis:**\\n  - **Aliphatic Region:** Very good matches with errors between 0.028 and 0.071. This confirms the structure of the aliphatic chain.\\n  - **Aromatic Protons:** Atom 9 shows a good match (error 0.099), but atom 8 has a large deviation (1.718). This indicates a significant difference in the chemical environment of this carbon.\\n  - **N-CH Proton (Atom 6):** Excellent match (error 0.028), supporting the connectivity at this point.\\n  - **Quinoline CH (Atom 10):** Moderate deviation (0.292).\\n\\n**Conclusion for Candidate 3:** The aliphatic chain is well-supported by the data. The large deviation in the aromatic region (atom 8) is concerning and suggests a possible misassignment or electronic effect that isn't accounted for in the prediction.\\n\\n**Candidate 4: COc1cc(NC(C)CCCN)c2ncccc2n1**\\n\\n- **HSQC Error:** 2.64268761259165\\n- **Detailed Analysis:** No detailed HSQC analysis is provided for Candidate 4. However, its molecular weight (260.16371126) and formula (C14H20N4O) differ from the target. Unless there's a specific reason to consider it (e.g., a possible isotopic variant or a measurement error), it's less likely to be the correct structure based on the molecular weight alone.\\n\\n**Candidate 5: COc1ccnc2c(NC(C)CCCN)cccc12**\\n\\n- **HSQC Error:** 2.7837488088212536\\n- **Detailed Analysis:** No detailed HSQC analysis is provided for Candidate 5. Therefore, it's challenging to assess its suitability based solely on the given information.\\n\\n**Step 3: Evaluating Structural Features and Compatibility with Data**\\n\\nLet's now consider the structural features of each candidate and how well they align with the available data:\\n\\n- **Candidates 1, 2, and 3:** All feature a quinoline core with a methoxy substituent and an aminopentyl chain. The primary differences lie in the position of the methoxy group and the specific connectivity of the aminopentyl chain.\\n  - **Methoxy Group:** The presence of a methoxy group is confirmed by the HSQC data in all three candidates, with reasonable errors.\\n  - **Aminopentyl Chain:** The aliphatic regions show excellent agreement, indicating that the chain's structure is likely correct in all candidates.\\n  - **Aromatic System:** The discrepancies in the aromatic region could be due to the position of the methoxy group affecting the electron density, leading to shifts in the chemical shifts of the adjacent carbons.\\n\\n- **Candidate 4:** Features a 1,5-naphthyridine core instead of a quinoline. The different core structure could explain the discrepancy in molecular weight and formula. However, without detailed spectral analysis, it's hard to justify its selection over the other candidates that perfectly match the molecular weight.\\n\\n- **Candidate 5:** Similar to Candidate 1, but with a different connectivity of the aminopentyl chain. The lack of detailed spectral analysis prevents a thorough evaluation.\\n\\n**Step 4: Assessing Data Quality and Potential Issues**\\n\\nFrom the provided information, the primary data quality issue is the lack of detailed HSQC analysis for Candidates 4 and 5. This makes it challenging to fully evaluate their suitability. For Candidates 1-3, the HSQC data is available, but there are deviations in the aromatic region that need to be addressed. These deviations could be due to:\\n\\n- **Electronic Effects:** The position of the methoxy group and the nitrogen atoms in the quinoline ring can significantly influence the electron density, leading to shifts in chemical shifts.\\n- **Tautomerism:** The presence of multiple nitrogen atoms could lead to tautomeric forms, resulting in different chemical environments for some atoms.\\n- **Solvent Effects:** The solvent used in the NMR experiment can impact chemical shifts, particularly in aromatic systems.\\n- **Prediction Model Limitations:** The errors could also result from limitations in the prediction model used to generate the theoretical chemical shifts.\\n\\n**Step 5: Comparative Analysis and Final Recommendation**\\n\\nBased on the analysis so far, let's compare the candidates:\\n\\n- **Molecular Weight Match:** Candidates 1, 2, 3, and 5 perfectly match the target's molecular weight. Candidate 4 does not, making it less likely unless there's a specific justification.\\n- **Spectral Data Availability:** Candidates 1-3 have detailed HSQC analyses, while 4 and 5 do not. This makes it easier to evaluate Candidates 1-3.\\n- **Aliphatic Region Agreement:** All three candidates show excellent agreement in the aliphatic region, confirming the structure of the aminopentyl chain.\\n- **Aromatic Region Discrepancies:** All three candidates exhibit deviations in the aromatic region. However, these deviations are not deal-breakers and can be attributed to electronic effects or other factors mentioned earlier.\\n\\n**Decisive Factors:**\\n\\n- **Molecular Weight:** Perfect match with Candidates 1, 2, 3, and 5.\\n- **Aliphatic Region:** Excellent agreement in all evaluated candidates.\\n- **Aromatic Region:** Deviations are present but are consistent with electronic effects due to substitution.\\n\\n**Addressing Uncertainties:**\\n\\nThe main uncertainty lies in the aromatic region's chemical shifts. To resolve this, additional 2D NMR experiments (such as COSY, HSQC, and HMBC) would be beneficial. These experiments can provide more detailed information about the connectivity and electronic environment of the atoms in the aromatic system, helping to confirm the exact position of the methoxy group and the overall structure.\\n\\n**Final Recommendation:**\\n\\nBased on the available data, **Candidate 1** appears to be the most likely correct structure. It has the highest overall agreement in the aliphatic region and a reasonable explanation for the deviations observed in the aromatic region. However, it's crucial to conduct further NMR experiments to resolve the uncertainties in the aromatic system.\\n\\n**JSON Result:**\\n\\n```json\\nJSON_RESULT = {\\n    \\\"candidates\\\": [\\n        {\\n            \\\"smiles\\\": \\\"COc1ccnc2cccc(NC(C)CCCN)c12\\\",\\n            \\\"confidence_score\\\": 0.8,\\n            \\\"molecular_weight\\\": 259.168462292,\\n            \\\"reasoning\\\": \\\"The aliphatic region shows excellent agreement with minimal errors (0.011-0.079), confirming the aminopentyl chain structure. The methoxy group also matches well with an error of 0.029. Deviations in the aromatic region (errors up to 0.900) are noted but can be attributed to electronic effects due to substitution. The overall structure is largely supported, with high confidence in the aliphatic portions.\\\",\\n            \\\"data_quality_issues\\\": {\\n                \\\"title\\\": \\\"Aromatic Region Deviations\\\",\\n                \\\"description\\\": \\\"Significant deviations in the chemical shifts of some aromatic carbons (atoms 8 and 10) are observed. These deviations likely result from electronic effects due to the position of the methoxy group and the nitrogen atoms in the quinoline ring.\\\",\\n                \\\"impact\\\": \\\"medium\\\",\\n                \\\"atom_index\\\": 8\\n            }\\n        },\\n        {\\n            \\\"smiles\\\": \\\"COc1ccc(NC(C)CCCN)c2cccnc12\\\",\\n            \\\"confidence_score\\\": 0.75,\\n            \\\"molecular_weight\\\": 259.168462292,\\n            \\\"reasoning\\\": \\\"The aliphatic chain shows excellent correlation with errors ranging from 0.001 to 0.043, strongly supporting that part of the structure. The methoxy group is present and matches reasonably. However, significant deviations in the aromatic region, particularly at atom 8 (error 1.510), indicate potential issues with the electronic environment that need further investigation.\\\",\\n            \\\"data_quality_issues\\\": {\\n                \\\"title\\\": \\\"Aromatic Region Mismatch\\\",\\n                \\\"description\\\": \\\"Large deviation in the chemical shift of atom 8 suggests a mismatch in the electronic environment, possibly due to the position of the methoxy group or tautomerism.\\\",\\n                \\\"impact\\\": \\\"medium\\\",\\n                \\\"atom_index\\\": 8\\n            }\\n        },\\n        {\\n            \\\"smiles\\\": \\\"COc1ccc(NC(C)CCCN)c2ncccc12\\\",\\n            \\\"confidence_score\\\": 0.7,\\n            \\\"molecular_weight\\\": 259.168462292,\\n            \\\"reasoning\\\": \\\"The aliphatic chain protons and carbons show excellent correlation, confirming that part of the structure. The N-CH proton matches perfectly. However, significant deviations in the aromatic region, particularly at atom 8 (error 1.718), suggest potential issues with the electronic environment or connectivity.\\\",\\n            \\\"data_quality_issues\\\": {\\n                \\\"title\\\": \\\"Large Aromatic Deviation\\\",\\n                \\\"description\\\": \\\"Atom 8 shows a large deviation in both 1H and 13C chemical shifts, indicating a significant mismatch in the electronic environment that needs to be resolved.\\\",\\n                \\\"impact\\\": \\\"high\\\",\\n                \\\"atom_index\\\": 8\\n            }\\n        },\\n        {\\n            \\\"smiles\\\": \\\"COc1cc(NC(C)CCCN)c2ncccc2n1\\\",\\n            \\\"confidence_score\\\": 0.5,\\n            \\\"molecular_weight\\\": 260.16371126,\\n            \\\"reasoning\\\": \\\"The molecular weight and formula differ from the target, making it less likely unless there's a specific justification (e.g., isotopic variant). No detailed HSQC analysis is available to support or refute the structure.\\\",\\n            \\\"data_quality_issues\\\": {\\n                \\\"title\\\": \\\"Molecular Weight Discrepancy\\\",\\n                \\\"description\\\": \\\"The molecular weight and formula do not match the target, which is a significant concern unless there's a valid explanation.\\\",\\n                \\\"impact\\\": \\\"high\\\",\\n                \\\"atom_index\\\": 0\\n            }\\n        },\\n        {\\n            \\\"smiles\\\": \\\"COc1ccnc2c(NC(C)CCCN)cccc12\\\",\\n            \\\"confidence_score\\\": 0.6,\\n            \\\"molecular_weight\\\": 259.168462292,\\n            \\\"reasoning\\\": \\\"No detailed HSQC analysis is provided, making it difficult to fully evaluate the structure. The molecular weight matches, but without spectral data, the confidence is lower compared to other candidates.\\\",\\n            \\\"data_quality_issues\\\": {\\n                \\\"title\\\": \\\"Lack of Spectral Data\\\",\\n                \\\"description\\\": \\\"No detailed HSQC analysis is available, preventing a thorough evaluation of the structure's compatibility with the experimental data.\\\",\\n                \\\"impact\\\": \\\"medium\\\",\\n                \\\"atom_index\\\": 0\\n            }\\n        }\\n    ],\\n    \\\"final_recommendation\\\": {\\n        \\\"best_smiles\\\": \\\"COc1ccnc2cccc(NC(C)CCCN)c12\\\",\\n        \\\"overall_confidence\\\": 0.8,\\n        \\\"molecular_weight_match\\\": true,\\n        \\\"explanation\\\": \\\"Candidate 1 is recommended as the most likely correct structure based on the strong agreement in the aliphatic region and a reasonable explanation for the deviations observed in the aromatic region. The molecular weight perfectly matches the target. While Candidates 2 and 3 also show promise, Candidate 1 has the highest overall agreement. Further 2D NMR experiments are recommended to resolve the uncertainties in the aromatic system and confirm the exact position of the methoxy group.\\\"\\n    }\\n}\\n```\",\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:LLM_312]",
   "language": "python",
   "name": "conda-env-LLM_312-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
