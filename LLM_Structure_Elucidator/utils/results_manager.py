# """Unified manager for storing and retrieving all calculation and conversation results."""
# import pandas as pd
# from pathlib import Path
# import json
# from datetime import datetime
# import hashlib
# from typing import Dict, Any, Optional, List, Union, Tuple
# import logging
# from dataclasses import dataclass, asdict
# from enum import Enum

# class ResultType(Enum):
#     """Types of results that can be stored.
    
#     Types:
#         TARGET_MOLECULES: Input molecules (single or batch) with their properties
#         STARTING_MATERIALS: Starting materials (provided or from retrosynthesis)
#         FORWARD_PREDICTIONS: Forward synthesis predictions from starting materials
#         MORPHOMER_MOLECULES: Molecules generated by Morphomer
#         MMST_MOLECULES: Molecules generated by MMST
#         NMR_SIMULATION: Simulated NMR spectra for molecules
#         EXPERIMENTAL_DATA: Experimental NMR data
#         THRESHOLD_CALCULATION: Error thresholds for spectral matching
#         PEAK_MATCHING: Peak matching results per spectrum type
#         RETROSYNTHESIS: Retrosynthesis predictions and pathways
#         CONVERSATION_FULL: Complete conversation history with agents
#         CONVERSATION_SUMMARY: Condensed summary of key conversation points
#         WORKFLOW_STATE: Current state of the workflow
#         ERROR_LOG: Any errors or warnings during processing
#         PERFORMANCE_METRICS: Timing and resource usage metrics
#     """
#     # Molecule Types and Generation
#     TARGET_MOLECULES = "target_molecules"  # Input molecules with properties
#     STARTING_MATERIALS = "starting_materials"  # Either provided or from retrosynthesis
#     FORWARD_PREDICTIONS = "forward_predictions"  # Forward synthesis from starting materials
#     MORPHOMER_MOLECULES = "morphomer_molecules"  # Generated by Morphomer
#     MMST_MOLECULES = "mmst_molecules"  # Generated by MMST
    
#     # Spectral and Analysis Data
#     NMR_SIMULATION = "nmr_simulation"  # Per spectrum type (1H, 13C, HSQC, COSY)
#     EXPERIMENTAL_DATA = "experimental_data"  # Experimental NMR data
#     THRESHOLD_CALCULATION = "threshold_calculation"  # Error thresholds
#     PEAK_MATCHING = "peak_matching"  # Per spectrum type matching results
    
#     # Synthesis and Predictions
#     RETROSYNTHESIS = "retrosynthesis"  # Retrosynthesis paths and predictions
    
#     # Conversation and Workflow
#     CONVERSATION_FULL = "conversation_full"  # Complete conversation logs
#     CONVERSATION_SUMMARY = "conversation_summary"  # Condensed key points
#     WORKFLOW_STATE = "workflow_state"  # Current workflow state
    
#     # Monitoring and Performance
#     ERROR_LOG = "error_log"  # Error tracking
#     PERFORMANCE_METRICS = "performance_metrics"  # Timing and resources

# @dataclass
# class NMRMetadata:
#     """Common metadata for all NMR experiments."""
#     frequency: float  # Spectrometer frequency in MHz
#     solvent: str
#     temperature: float  # Temperature in K
#     experiment_type: str  # Pulse sequence details
#     acquisition_time: Optional[float] = None
#     number_of_scans: Optional[int] = None
#     relaxation_delay: Optional[float] = None
#     pulse_width: Optional[float] = None
#     digital_resolution: Optional[float] = None  # Hz/point

# @dataclass
# class ProtonNMRData:
#     """Structure for 1H NMR data."""
#     shifts: List[float]  # Chemical shifts in ppm
#     intensities: List[float]  # Peak intensities/integrals
#     multiplicities: Optional[List[str]] = None  # s, d, t, q, m, etc.
#     j_couplings: Optional[List[float]] = None  # J coupling constants in Hz
#     metadata: Optional[NMRMetadata] = None

# @dataclass
# class CarbonNMRData:
#     """Structure for 13C NMR data."""
#     shifts: List[float]  # Chemical shifts in ppm
#     peak_types: Optional[List[str]] = None  # CH3, CH2, CH, C
#     metadata: Optional[NMRMetadata] = None

# @dataclass
# class HSQCData:
#     """Structure for HSQC 2D NMR data."""
#     f1_shifts: List[float]  # 13C dimension shifts
#     f2_shifts: List[float]  # 1H dimension shifts
#     correlation_indices: List[Tuple[int, int]]  # Indices connecting F1 and F2 peaks
#     peak_types: Optional[List[str]] = None  # CH3, CH2, CH
#     metadata: Optional[NMRMetadata] = None

# @dataclass
# class COSYData:
#     """Structure for COSY 2D NMR data."""
#     f1_shifts: List[float]  # 1H dimension shifts
#     f2_shifts: List[float]  # 1H dimension shifts
#     correlation_indices: List[Tuple[int, int]]  # Indices connecting F1 and F2 peaks
#     correlation_types: Optional[List[str]] = None  # Strong, medium, weak
#     metadata: Optional[NMRMetadata] = None

# @dataclass
# class NMRData:
#     """Container for all types of NMR data."""
#     spectrum_type: str  # '1H', '13C', 'HSQC', 'COSY'
#     data: Union[ProtonNMRData, CarbonNMRData, HSQCData, COSYData]
    
#     @classmethod
#     def create_proton_nmr(cls, shifts: List[float], intensities: List[float], **kwargs) -> 'NMRData':
#         """Create a 1H NMR data instance."""
#         return cls(
#             spectrum_type='1H',
#             data=ProtonNMRData(shifts=shifts, intensities=intensities, **kwargs)
#         )
    
#     @classmethod
#     def create_carbon_nmr(cls, shifts: List[float], **kwargs) -> 'NMRData':
#         """Create a 13C NMR data instance."""
#         return cls(
#             spectrum_type='13C',
#             data=CarbonNMRData(shifts=shifts, **kwargs)
#         )
    
#     @classmethod
#     def create_hsqc(cls, f1_shifts: List[float], f2_shifts: List[float], 
#                    correlation_indices: List[Tuple[int, int]], **kwargs) -> 'NMRData':
#         """Create an HSQC data instance."""
#         return cls(
#             spectrum_type='HSQC',
#             data=HSQCData(
#                 f1_shifts=f1_shifts,
#                 f2_shifts=f2_shifts,
#                 correlation_indices=correlation_indices,
#                 **kwargs
#             )
#         )
    
#     @classmethod
#     def create_cosy(cls, f1_shifts: List[float], f2_shifts: List[float],
#                    correlation_indices: List[Tuple[int, int]], **kwargs) -> 'NMRData':
#         """Create a COSY data instance."""
#         return cls(
#             spectrum_type='COSY',
#             data=COSYData(
#                 f1_shifts=f1_shifts,
#                 f2_shifts=f2_shifts,
#                 correlation_indices=correlation_indices,
#                 **kwargs
#             )
#         )

# @dataclass
# class SpectrumThreshold:
#     """Threshold information for a specific spectrum type."""
#     value: float  # The calculated threshold value
#     confidence: Optional[float] = None  # Confidence score (0-1)
#     method: Optional[str] = None  # Method used to calculate threshold
#     parameters: Optional[Dict[str, Any]] = None  # Parameters used in calculation
#     statistics: Optional[Dict[str, float]] = None  # Statistical metrics (mean, std, etc.)

# @dataclass
# class ThresholdData:
#     """Complete threshold information for all spectrum types."""
#     proton: Optional[SpectrumThreshold] = None  # 1H NMR thresholds
#     carbon: Optional[SpectrumThreshold] = None  # 13C NMR thresholds
#     hsqc: Optional[SpectrumThreshold] = None    # HSQC thresholds
#     cosy: Optional[SpectrumThreshold] = None    # COSY thresholds
#     overall: Optional[float] = None             # Combined threshold
#     weights: Optional[Dict[str, float]] = None  # Weights used for overall calculation
    
#     def to_dict(self) -> Dict[str, float]:
#         """Convert to simple dictionary format for backward compatibility."""
#         return {
#             '1H': self.proton.value if self.proton else None,
#             '13C': self.carbon.value if self.carbon else None,
#             'HSQC': self.hsqc.value if self.hsqc else None,
#             'COSY': self.cosy.value if self.cosy else None
#         }
    
#     @classmethod
#     def from_dict(cls, data: Dict[str, float], **kwargs) -> 'ThresholdData':
#         """Create ThresholdData from simple dictionary format."""
#         return cls(
#             proton=SpectrumThreshold(value=data['1H']) if '1H' in data else None,
#             carbon=SpectrumThreshold(value=data['13C']) if '13C' in data else None,
#             hsqc=SpectrumThreshold(value=data['HSQC']) if 'HSQC' in data else None,
#             cosy=SpectrumThreshold(value=data['COSY']) if 'COSY' in data else None,
#             **kwargs
#         )

# @dataclass
# class MoleculeResult:
#     """Complete result set for a molecule."""
#     # Core Identifiers
#     molecule_id: str
#     smiles: str
#     sample_id: Optional[str] = None  # Sample identifier from experimental data
#     inchi: Optional[str] = None
#     inchi_key: Optional[str] = None
    
#     # Target Molecule Information
#     is_batch: bool = False  # Whether this is part of a batch
#     batch_id: Optional[str] = None  # ID of the batch this molecule belongs to
#     molecular_properties: Optional[Dict[str, Any]] = None  # Properties like MW, logP, etc.
    
#     # Starting Materials
#     starting_materials: Optional[List[str]] = None  # SMILES of starting materials
#     starting_materials_source: Optional[str] = None  # 'provided' or 'retrosynthesis'
    
#     # NMR Data (per spectrum type)
#     predicted_nmr: Optional[Dict[str, NMRData]] = None  # Simulated spectra
#     experimental_nmr: Optional[Dict[str, NMRData]] = None  # Experimental spectra
    
#     # Threshold Data
#     thresholds: Optional[ThresholdData] = None  # Structured threshold data
#     threshold_calculation_params: Optional[Dict[str, Any]] = None
    
#     # Peak Matching (per spectrum type)
#     peak_matches: Optional[Dict[str, List[Dict[str, float]]]] = None
#     match_scores: Optional[Dict[str, float]] = None
#     peak_matching_params: Optional[Dict[str, Any]] = None
    
#     # Retrosynthesis Data
#     retrosynthesis_predictions: Optional[List[Dict[str, Any]]] = None
#     retrosynthesis_params: Optional[Dict[str, Any]] = None
    
#     # Conversation History
#     conversation_history: Optional[List[Dict[str, Any]]] = None  # Full conversation
#     conversation_summary: Optional[str] = None  # Condensed summary
#     last_conversation_timestamp: Optional[str] = None
    
#     # Workflow State
#     workflow_state: Optional[str] = None  # Current state in the pipeline
#     completed_steps: Optional[List[str]] = None  # Steps completed so far
#     next_steps: Optional[List[str]] = None  # Upcoming steps
    
#     # Error Tracking
#     errors: Optional[List[Dict[str, Any]]] = None  # List of errors encountered
#     warnings: Optional[List[Dict[str, Any]]] = None  # List of warnings
    
#     # Performance Metrics
#     calculation_times: Optional[Dict[str, float]] = None  # Timing per operation
#     resource_usage: Optional[Dict[str, Any]] = None  # Memory, CPU usage etc.
    
#     # Metadata
#     timestamp: str = None  # Creation timestamp
#     last_modified: str = None  # Last modification
#     calculation_params: Optional[Dict[str, Any]] = None  # Global calculation parameters
#     status: str = "pending"  # Overall status
#     version: str = "1.0"  # Schema version
    
#     def __post_init__(self):
#         """Initialize timestamps if not provided."""
#         if not self.timestamp:
#             self.timestamp = datetime.now().isoformat()
#         if not self.last_modified:
#             self.last_modified = self.timestamp
            
#     def update_conversation(self, message: Dict[str, Any], generate_summary: bool = True):
#         """Add a conversation message and optionally update the summary."""
#         if not self.conversation_history:
#             self.conversation_history = []
        
#         self.conversation_history.append(message)
#         self.last_conversation_timestamp = datetime.now().isoformat()
        
#         if generate_summary:
#             # Here we would call an LLM to generate a summary
#             # For now, just take the last message
#             self.conversation_summary = f"Last action: {message.get('content', '')[:100]}..."
            
#     def add_error(self, error_type: str, message: str, details: Optional[Dict] = None):
#         """Add an error to the error log."""
#         if not self.errors:
#             self.errors = []
            
#         self.errors.append({
#             'type': error_type,
#             'message': message,
#             'details': details,
#             'timestamp': datetime.now().isoformat()
#         })
        
#     def update_workflow_state(self, new_state: str, completed_step: Optional[str] = None):
#         """Update the workflow state and completed steps."""
#         self.workflow_state = new_state
#         if completed_step:
#             if not self.completed_steps:
#                 self.completed_steps = []
#             self.completed_steps.append(completed_step)
#         self.last_modified = datetime.now().isoformat()

# class ResultsManager:
#     """Manages storage and retrieval of all calculation and conversation results."""
    
#     def __init__(self, base_dir: Optional[Path] = None):
#         """Initialize the results manager."""
#         self.base_dir = base_dir or Path(__file__).parent.parent / "data"
#         self.results_dir = self.base_dir / "results"
#         self.index_file = self.base_dir / "results_index.json"
        
#         # Create directories
#         self.results_dir.mkdir(parents=True, exist_ok=True)
        
#         # Initialize or load index
#         self.index = self._load_index()
#         self.logger = logging.getLogger(__name__)
    
#     def _serialize_dataclass(self, obj: Any) -> Dict[str, Any]:
#         """Serialize dataclass objects with proper type handling."""
#         if hasattr(obj, '__dataclass_fields__'):
#             result = {}
#             for field in obj.__dataclass_fields__:
#                 value = getattr(obj, field)
#                 if value is not None:
#                     if hasattr(value, '__dataclass_fields__'):
#                         result[field] = self._serialize_dataclass(value)
#                     elif isinstance(value, dict):
#                         result[field] = {k: self._serialize_dataclass(v) if hasattr(v, '__dataclass_fields__') else v
#                                        for k, v in value.items()}
#                     elif isinstance(value, (list, tuple)):
#                         result[field] = [self._serialize_dataclass(item) if hasattr(item, '__dataclass_fields__') else item
#                                        for item in value]
#                     else:
#                         result[field] = value
#             return result
#         return obj
    
#     def _deserialize_dataclass(self, data: Dict[str, Any], cls: Any) -> Any:
#         """Deserialize dictionary into appropriate dataclass."""
#         if not data:
#             return None
            
#         field_types = {field.name: field.type for field in cls.__dataclass_fields__.values()}
#         kwargs = {}
        
#         for key, value in data.items():
#             if key in field_types:
#                 field_type = field_types[key]
#                 if hasattr(field_type, '__dataclass_fields__'):
#                     kwargs[key] = self._deserialize_dataclass(value, field_type)
#                 elif hasattr(field_type, '__origin__') and field_type.__origin__ is dict:
#                     if value is None:
#                         kwargs[key] = None
#                     else:
#                         key_type, val_type = field_type.__args__
#                         if hasattr(val_type, '__dataclass_fields__'):
#                             kwargs[key] = {k: self._deserialize_dataclass(v, val_type) for k, v in value.items()}
#                         else:
#                             kwargs[key] = value
#                 else:
#                     kwargs[key] = value
                    
#         return cls(**kwargs)
    
#     def _load_index(self) -> Dict[str, Any]:
#         """Load or create the index file with proper deserialization."""
#         if self.index_file.exists():
#             with open(self.index_file, 'r') as f:
#                 raw_data = json.load(f)
#                 return {
#                     'molecules': {
#                         k: self._deserialize_dataclass(v, MoleculeResult)
#                         for k, v in raw_data.get('molecules', {}).items()
#                     },
#                     'calculations': raw_data.get('calculations', {}),
#                     'metadata': raw_data.get('metadata', {
#                         'last_updated': datetime.now().isoformat(),
#                         'version': '1.0'
#                     })
#                 }
#         return {
#             'molecules': {},
#             'calculations': {},
#             'metadata': {
#                 'last_updated': datetime.now().isoformat(),
#                 'version': '1.0'
#             }
#         }
    
#     def _save_index(self):
#         """Save the current index with proper serialization."""
#         save_data = {
#             'molecules': {
#                 k: self._serialize_dataclass(v)
#                 for k, v in self.index['molecules'].items()
#             },
#             'calculations': self.index['calculations'],
#             'metadata': {
#                 'last_updated': datetime.now().isoformat(),
#                 'version': '1.0'
#             }
#         }
#         with open(self.index_file, 'w') as f:
#             json.dump(save_data, f, indent=2)
    
#     def store_result(
#         self,
#         result_type: ResultType,
#         smiles: str,
#         data: Dict[str, Any],
#         context: Optional[Dict[str, Any]] = None
#     ) -> str:
#         """Store calculation or conversation results."""
#         try:
#             molecule_id = self._generate_molecule_id(smiles, context or {})
            
#             # Create or get existing molecule result
#             if molecule_id not in self.index['molecules']:
#                 molecule_result = MoleculeResult(
#                     molecule_id=molecule_id,
#                     smiles=smiles
#                 )
#             else:
#                 molecule_result = self.index['molecules'][molecule_id]
            
#             # Start performance tracking
#             start_time = datetime.now()
            
#             # Update based on result type
#             self._update_result(molecule_result, result_type, data, context)
            
#             # Track performance
#             end_time = datetime.now()
#             if not molecule_result.calculation_times:
#                 molecule_result.calculation_times = {}
#             molecule_result.calculation_times[result_type.value] = (end_time - start_time).total_seconds()
            
#             # Update metadata
#             molecule_result.last_modified = datetime.now().isoformat()
#             molecule_result.status = "completed"
            
#             # Save to index
#             self.index['molecules'][molecule_id] = molecule_result
#             self._save_index()
            
#             return molecule_id
            
#         except Exception as e:
#             self.logger.error(f"Error storing results: {str(e)}")
#             raise
    
#     def _update_result(
#         self,
#         molecule_result: MoleculeResult,
#         result_type: ResultType,
#         data: Dict[str, Any],
#         context: Optional[Dict[str, Any]]
#     ):
#         """Update molecule result based on result type."""
#         try:
#             if result_type == ResultType.TARGET_MOLECULES:
#                 molecule_result.molecular_properties = data.get('properties')
#                 molecule_result.is_batch = data.get('is_batch', False)
#                 molecule_result.batch_id = data.get('batch_id')
#                 if context and 'sample_id' in context:
#                     molecule_result.sample_id = context['sample_id']
                
#             elif result_type == ResultType.NMR_SIMULATION:
#                 if not molecule_result.predicted_nmr:
#                     molecule_result.predicted_nmr = {}
#                 spectrum_type = data['spectrum_type']
#                 nmr_data = self._create_nmr_data(spectrum_type, data['data'])
#                 molecule_result.predicted_nmr[spectrum_type] = nmr_data
                
#             elif result_type == ResultType.EXPERIMENTAL_DATA:
#                 if not molecule_result.experimental_nmr:
#                     molecule_result.experimental_nmr = {}
#                 spectrum_type = data['spectrum_type']
#                 nmr_data = self._create_nmr_data(spectrum_type, data['data'])
#                 molecule_result.experimental_nmr[spectrum_type] = nmr_data
                
#             elif result_type == ResultType.THRESHOLD_CALCULATION:
#                 molecule_result.thresholds = ThresholdData.from_dict(
#                     data.get('individual_thresholds'),
#                     overall=data.get('overall_threshold'),
#                     weights=data.get('weights')
#                 )
#                 molecule_result.threshold_calculation_params = context
                
#             elif result_type == ResultType.PEAK_MATCHING:
#                 molecule_result.peak_matches = data.get('matches')
#                 molecule_result.match_scores = data.get('scores')
#                 molecule_result.peak_matching_params = context
                
#             elif result_type == ResultType.RETROSYNTHESIS:
#                 molecule_result.starting_materials = data.get('starting_materials')
#                 molecule_result.starting_materials_source = 'retrosynthesis'
#                 molecule_result.retrosynthesis_predictions = data.get('predictions')
#                 molecule_result.retrosynthesis_params = context
                
#             elif result_type == ResultType.FORWARD_PREDICTIONS:
#                 if not hasattr(molecule_result, 'forward_predictions'):
#                     molecule_result.forward_predictions = []
#                 molecule_result.forward_predictions.append({
#                     'predictions': data.get('predictions'),
#                     'parameters': context,
#                     'timestamp': datetime.now().isoformat()
#                 })
                
#             elif result_type == ResultType.MORPHOMER_MOLECULES:
#                 if not hasattr(molecule_result, 'morphomer_results'):
#                     molecule_result.morphomer_results = []
#                 molecule_result.morphomer_results.append({
#                     'molecules': data.get('molecules'),
#                     'parameters': context,
#                     'timestamp': datetime.now().isoformat()
#                 })
                
#             elif result_type == ResultType.MMST_MOLECULES:
#                 if not hasattr(molecule_result, 'mmst_results'):
#                     molecule_result.mmst_results = []
#                 molecule_result.mmst_results.append({
#                     'molecules': data.get('molecules'),
#                     'parameters': context,
#                     'timestamp': datetime.now().isoformat()
#                 })
                
#             elif result_type == ResultType.CONVERSATION_FULL:
#                 molecule_result.update_conversation(data, generate_summary=True)
                
#             elif result_type == ResultType.ERROR_LOG:
#                 molecule_result.add_error(
#                     error_type=data.get('type'),
#                     message=data.get('message'),
#                     details=data.get('details')
#                 )
                
#             elif result_type == ResultType.WORKFLOW_STATE:
#                 molecule_result.update_workflow_state(
#                     new_state=data.get('state'),
#                     completed_step=data.get('completed_step')
#                 )
                
#         except Exception as e:
#             self.logger.error(f"Error updating result type {result_type}: {str(e)}")
#             raise
    
#     def _create_nmr_data(self, spectrum_type: str, data: Dict[str, Any]) -> NMRData:
#         """Create appropriate NMR data instance based on spectrum type."""
#         if spectrum_type == '1H':
#             return NMRData.create_proton_nmr(**data)
#         elif spectrum_type == '13C':
#             return NMRData.create_carbon_nmr(**data)
#         elif spectrum_type == 'HSQC':
#             return NMRData.create_hsqc(**data)
#         elif spectrum_type == 'COSY':
#             return NMRData.create_cosy(**data)
#         else:
#             raise ValueError(f"Unknown spectrum type: {spectrum_type}")
    
#     def delete_result(self, molecule_id: str):
#         """Delete a result from the database."""
#         if molecule_id in self.index['molecules']:
#             del self.index['molecules'][molecule_id]
#             self._save_index()
    
#     def export_database(self, output_file: Path):
#         """Export the entire database to a file."""
#         with open(output_file, 'w') as f:
#             json.dump(self._serialize_dataclass(self.index), f, indent=2)
    
#     def import_database(self, input_file: Path):
#         """Import database from a file."""
#         with open(input_file, 'r') as f:
#             raw_data = json.load(f)
#             self.index = self._deserialize_dataclass(raw_data, dict)
#             self._save_index()

#     def get_molecules_by_timestamp(self, start_time: datetime = None, end_time: datetime = None) -> List[MoleculeResult]:
#         """Get molecules filtered by timestamp range.
        
#         Args:
#             start_time: Optional start time to filter from
#             end_time: Optional end time to filter to
            
#         Returns:
#             List of MoleculeResult objects within the time range
#         """
#         results = []
#         for molecule in self.index['molecules'].values():
#             timestamp = datetime.fromisoformat(molecule.timestamp)
#             if start_time and timestamp < start_time:
#                 continue
#             if end_time and timestamp > end_time:
#                 continue
#             results.append(molecule)
#         return results
    
#     def get_molecules_by_source(self, source: str) -> List[MoleculeResult]:
#         """Get molecules filtered by source.
        
#         Args:
#             source: Source identifier (e.g., 'csv_upload')
            
#         Returns:
#             List of MoleculeResult objects from the specified source
#         """
#         results = []
#         for molecule in self.index['molecules'].values():
#             context = molecule.calculation_params or {}
#             if context.get('source') == source:
#                 results.append(molecule)
#         return results
    
#     def get_latest_upload_results(self) -> List[MoleculeResult]:
#         """Get molecules from the most recent CSV upload.
        
#         Returns:
#             List of MoleculeResult objects from the latest upload
#         """
#         # Find the latest upload timestamp
#         latest_time = None
#         latest_molecules = []
        
#         for molecule in self.index['molecules'].values():
#             context = molecule.calculation_params or {}
#             if context.get('source') == 'csv_upload':
#                 timestamp = datetime.fromisoformat(context.get('timestamp', '1970-01-01T00:00:00'))
#                 if not latest_time or timestamp > latest_time:
#                     latest_time = timestamp
#                     latest_molecules = [molecule]
#                 elif timestamp == latest_time:
#                     latest_molecules.append(molecule)
        
#         return latest_molecules
